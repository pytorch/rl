


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.envs.transforms.transforms &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../versions.html"><span style="font-size:110%">main (0.0.0+unknown) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.envs.transforms.transforms</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.envs.transforms.transforms</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Plobs_dictnc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.util</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">weakref</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">copy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">IntEnum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">wraps</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">textwrap</span><span class="w"> </span><span class="kn">import</span> <span class="n">indent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">overload</span><span class="p">,</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">is_tensor_collection</span><span class="p">,</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">NonTensorData</span><span class="p">,</span>
    <span class="n">NonTensorStack</span><span class="p">,</span>
    <span class="n">set_lazy_legacy</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
    <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">unravel_key</span><span class="p">,</span>
    <span class="n">unravel_key_list</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">_is_leaf_nontensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">dispatch</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_unravel_key_to_tuple</span><span class="p">,</span>
    <span class="n">_zip_strict</span><span class="p">,</span>
    <span class="n">expand_as_right</span><span class="p">,</span>
    <span class="n">expand_right</span><span class="p">,</span>
    <span class="n">NestedKey</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils._pytree</span><span class="w"> </span><span class="kn">import</span> <span class="n">tree_map</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_append_last</span><span class="p">,</span>
    <span class="n">_ends_with</span><span class="p">,</span>
    <span class="n">_make_ordinal_device</span><span class="p">,</span>
    <span class="n">_replace_last</span><span class="p">,</span>
    <span class="n">auto_unwrap_transformed_env</span><span class="p">,</span>
    <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.tensor_specs</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Binary</span><span class="p">,</span>
    <span class="n">Bounded</span><span class="p">,</span>
    <span class="n">BoundedContinuous</span><span class="p">,</span>
    <span class="n">Categorical</span><span class="p">,</span>
    <span class="n">Composite</span><span class="p">,</span>
    <span class="n">ContinuousBox</span><span class="p">,</span>
    <span class="n">MultiCategorical</span><span class="p">,</span>
    <span class="n">MultiOneHot</span><span class="p">,</span>
    <span class="n">OneHot</span><span class="p">,</span>
    <span class="n">TensorSpec</span><span class="p">,</span>
    <span class="n">Unbounded</span><span class="p">,</span>
    <span class="n">UnboundedContinuous</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.common</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_do_nothing</span><span class="p">,</span>
    <span class="n">_EnvPostInit</span><span class="p">,</span>
    <span class="n">_maybe_unlock</span><span class="p">,</span>
    <span class="n">EnvBase</span><span class="p">,</span>
    <span class="n">make_tensordict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.transforms.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_get_reset</span><span class="p">,</span>
    <span class="n">_set_missing_tolerance</span><span class="p">,</span>
    <span class="n">check_finite</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_sort_keys</span><span class="p">,</span>
    <span class="n">_terminated_or_truncated</span><span class="p">,</span>
    <span class="n">_update_during_reset</span><span class="p">,</span>
    <span class="n">make_composite_from_td</span><span class="p">,</span>
    <span class="n">step_mdp</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>


<span class="n">_has_tv</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

<span class="n">IMAGE_KEYS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]</span>
<span class="n">_MAX_NOOPS_TRIALS</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">FORWARD_NOT_IMPLEMENTED</span> <span class="o">=</span> <span class="s2">&quot;class </span><span class="si">{}</span><span class="s2"> cannot be executed without a parent environment.&quot;</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s2">&quot;Transform&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Self</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">Self</span> <span class="o">=</span> <span class="n">Any</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_apply_to_composite</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
    <span class="nd">@wraps</span><span class="p">(</span><span class="n">function</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">new_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">_specs</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">_specs</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="n">_specs</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">Composite</span><span class="p">(</span>
                <span class="n">_specs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_fun</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_apply_to_composite_inv</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
    <span class="c1"># Changes the input_spec following a transform function.</span>
    <span class="c1"># The usage is: if an env expects a certain input (e.g. a double tensor)</span>
    <span class="c1"># but the input has to be transformed (e.g. it is float), this function will</span>
    <span class="c1"># modify the spec to get a spec that from the outside matches what is given</span>
    <span class="c1"># (ie a float).</span>
    <span class="c1"># Now since EnvBase.step ignores new inputs (ie the root level of the</span>
    <span class="c1"># tensor is not updated) an out_key that does not match the in_key has</span>
    <span class="c1"># no effect on the spec.</span>
    <span class="nd">@wraps</span><span class="p">(</span><span class="n">function</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">new_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;full_action_spec&quot;</span> <span class="ow">in</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">action_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">state_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">state_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">state_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">state_spec</span> <span class="o">=</span> <span class="n">state_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="c1"># In case we pass full_action_spec or full_state_spec directly</span>
            <span class="n">action_spec</span> <span class="o">=</span> <span class="n">state_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">()</span>
        <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span>
        <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">in_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="n">out_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
            <span class="c1"># if in_key != out_key:</span>
            <span class="c1">#     # we only change the input spec if the key is the same</span>
            <span class="c1">#     continue</span>
            <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">action_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">in_key</span> <span class="o">!=</span> <span class="n">out_key</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">action_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">state_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">in_key</span> <span class="o">!=</span> <span class="n">out_key</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">state_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">input_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">in_key</span> <span class="o">!=</span> <span class="n">out_key</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">input_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">skip</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">input_spec</span>
        <span class="k">return</span> <span class="n">Composite</span><span class="p">(</span>
            <span class="n">full_state_spec</span><span class="o">=</span><span class="n">state_spec</span><span class="p">,</span>
            <span class="n">full_action_spec</span><span class="o">=</span><span class="n">action_spec</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">new_fun</span>


<div class="viewcode-block" id="Transform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Transform</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for environment transforms, which modify or create new data in a tensordict.</span>

<span class="sd">    Transforms are used to manipulate the input and output data of an environment. They can be used to preprocess</span>
<span class="sd">    observations, modify rewards, or transform actions. Transforms can be composed together to create more complex</span>
<span class="sd">    transformations.</span>

<span class="sd">    A transform receives a tensordict as input and returns (the same or another) tensordict as output, where a series</span>
<span class="sd">    of values have been modified or created with a new key.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        parent: The parent environment of the transform.</span>
<span class="sd">        container: The container that holds the transform.</span>
<span class="sd">        in_keys: The keys of the input tensordict that the transform will read from.</span>
<span class="sd">        out_keys: The keys of the output tensordict that the transform will write to.</span>

<span class="sd">    .. seealso:: :ref:`TorchRL transforms &lt;transforms&gt;`.</span>

<span class="sd">    Subclassing `Transform`:</span>

<span class="sd">        There are various ways of subclassing a transform. The things to take into considerations are:</span>

<span class="sd">        - Is the transform identical for each tensor / item being transformed? Use</span>
<span class="sd">          :meth:`~torchrl.envs.Transform._apply_transform` and :meth:`~torchrl.envs.Transform._inv_apply_transform`.</span>
<span class="sd">        - The transform needs access to the input data to env.step as well as output? Rewrite</span>
<span class="sd">          :meth:`~torchrl.envs.Transform._step`.</span>
<span class="sd">          Otherwise, rewrite :meth:`~torchrl.envs.Transform._call` (or :meth:`~torchrl.envs.Transform._inv_call`).</span>
<span class="sd">        - Is the transform to be used within a replay buffer? Overwrite :meth:`~torchrl.envs.Transform.forward`,</span>
<span class="sd">          :meth:`~torchrl.envs.Transform.inv`, :meth:`~torchrl.envs.Transform._apply_transform` or</span>
<span class="sd">          :meth:`~torchrl.envs.Transform._inv_apply_transform`.</span>
<span class="sd">        - Within a transform, you can access (and make calls to) the parent environment using</span>
<span class="sd">          :attr:`~torchrl.envs.Transform.parent` (the base env + all transforms till this one) or</span>
<span class="sd">          :meth:`~torchrl.envs.Transform.container` (The object that encapsulates the transform).</span>
<span class="sd">        - Don&#39;t forget to edits the specs if needed: top level: :meth:`~torchrl.envs.Transform.transform_output_spec`,</span>
<span class="sd">          :meth:`~torchrl.envs.Transform.transform_input_spec`.</span>
<span class="sd">          Leaf level: :meth:`~torchrl.envs.Transform.transform_observation_spec`,</span>
<span class="sd">          :meth:`~torchrl.envs.Transform.transform_action_spec`, :meth:`~torchrl.envs.Transform.transform_state_spec`,</span>
<span class="sd">          :meth:`~torchrl.envs.Transform.transform_reward_spec` and</span>
<span class="sd">          :meth:`~torchrl.envs.Transform.transform_reward_spec`.</span>

<span class="sd">        For practical examples, see the methods listed above.</span>

<span class="sd">    Methods:</span>
<span class="sd">        clone: creates a copy of the tensordict, without parent (a transform object can only have one parent).</span>
<span class="sd">        set_container: Sets the container for the transform, and in turn the parent if the container is or has one</span>
<span class="sd">            an environment within.</span>
<span class="sd">        reset_parent: resets the parent and container caches.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">enable_inv_on_reset</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span> <span class="o">=</span> <span class="n">in_keys_inv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">out_keys_inv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># we use __dict__ to avoid having nn.Module placing these objects in the module list</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_parent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Used to block ray until the actor is ready, see RayTransform</span>
        <span class="k">return</span> <span class="kc">True</span>

<div class="viewcode-block" id="Transform.close"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.close">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close the transform.&quot;&quot;&quot;</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_in_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">in_keys</span>

    <span class="nd">@in_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">out_keys</span>

    <span class="nd">@out_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_in_keys_inv&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">in_keys_inv</span>

    <span class="nd">@in_keys_inv</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys_inv</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys_inv&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">out_keys_inv</span>

    <span class="nd">@out_keys_inv</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys_inv</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">collector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataCollectorBase</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># noqa: F821 # type: ignore</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the collector associated with the container, if it exists.</span>

<span class="sd">        This can be used whenever the transform needs to be made aware of the collector or the policy associated with it.</span>

<span class="sd">        Make sure to call this property only on transforms that are not nested in sub-processes.</span>
<span class="sd">        The collector reference will not be passed to the workers of a :class:`~torchrl.envs.ParallelEnv` or</span>
<span class="sd">        similar batched environments.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="o">.</span><span class="n">collector</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets a transform if it is stateful.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_env_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverts the input to :meth:`TransformedEnv._reset`, if needed.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_inv_on_reset</span> <span class="ow">and</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="Transform.init"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.init">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs init steps for the transform.&quot;&quot;&quot;</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set attribute on the remote actor or locally.&quot;&quot;&quot;</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies the transform to a tensor or a leaf.</span>

<span class="sd">        This operation can be called multiple times (if multiples keys of the</span>
<span class="sd">        tensordict match the keys of the transform) for each entry in ``self.in_keys``</span>
<span class="sd">        after the `TransformedEnv().base_env.step` is undertaken.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; class AddOneToObs(Transform):</span>
<span class="sd">            ...     &#39;&#39;&#39;A transform that adds 1 to the observation tensor.&#39;&#39;&#39;</span>
<span class="sd">            ...     def __init__(self):</span>
<span class="sd">            ...         super().__init__(in_keys=[&quot;observation&quot;], out_keys=[&quot;observation&quot;])</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def _apply_transform(self, obs: torch.Tensor) -&gt; torch.Tensor:</span>
<span class="sd">            ...         return obs + 1</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">._apply_transform is not coded. If the transform is coded in &quot;</span>
            <span class="s2">&quot;transform._call, make sure that this method is called instead of&quot;</span>
            <span class="s2">&quot;transform.forward, which is reserved for usage inside nn.Modules&quot;</span>
            <span class="s2">&quot;or appended to a replay buffer.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The parent method of a transform during the ``env.step`` execution.</span>

<span class="sd">        This method should be overwritten whenever the :meth:`_step` needs to be</span>
<span class="sd">        adapted. Unlike :meth:`_call`, it is assumed that :meth:`_step`</span>
<span class="sd">        will execute some operation with the parent env or that it requires</span>
<span class="sd">        access to the content of the tensordict at time ``t`` and not only</span>
<span class="sd">        ``t+1`` (the ``&quot;next&quot;`` entry in the input tensordict).</span>

<span class="sd">        :meth:`_step` will only be called by :meth:`TransformedEnv.step` and</span>
<span class="sd">        not by :meth:`TransformedEnv.reset`.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensordict (TensorDictBase): data at time t</span>
<span class="sd">            next_tensordict (TensorDictBase): data at time t+1</span>

<span class="sd">        Returns: the data at t+1</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; class AddActionToObservation(Transform):</span>
<span class="sd">            ...     &#39;&#39;&#39;A transform that adds the action to the observation tensor.&#39;&#39;&#39;</span>
<span class="sd">            ...     def _step(</span>
<span class="sd">            ...         self, tensordict: TensorDictBase, next_tensordict: TensorDictBase</span>
<span class="sd">            ...     ) -&gt; TensorDictBase:</span>
<span class="sd">            ...         # This can only be done if we have access to the &#39;root&#39; tensordict</span>
<span class="sd">            ...         next_tensordict[&quot;observation&quot;] += tensordict[&quot;action&quot;]</span>
<span class="sd">            ...         return next_tensordict</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">next_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reads the input tensordict, and for the selected keys, applies the transform.</span>

<span class="sd">        ``_call`` can be re-written whenever a modification of the output of env.step needs to be modified independently</span>
<span class="sd">        of the data collected in the previous step (including actions and states).</span>

<span class="sd">        For any operation that relates exclusively to the parent env (e.g. ``FrameSkip``),</span>
<span class="sd">        modify the :meth:`~torchrl.envs.Transform._step` method instead.</span>
<span class="sd">        :meth:`_call` should only be overwritten if a modification of the input tensordict is needed.</span>

<span class="sd">        :meth:`_call` will be called by :meth:`~torchrl.envs.TransformedEnv.step` and</span>
<span class="sd">        :meth:`~torchrl.envs.TransformedEnv.reset` but not during :meth:`~torchrl.envs.Transform.forward`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">observation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">out_key</span><span class="p">,</span>
                    <span class="n">observation</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">: &#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">next_tensordict</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="Transform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;in_keys&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;out_keys&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reads the input tensordict, and for the selected keys, applies the transform.</span>

<span class="sd">        By default, this method:</span>

<span class="sd">        - calls directly :meth:`~torchrl.envs.Transform._apply_transform`.</span>
<span class="sd">        - does not call :meth:`~torchrl.envs.Transform._step` or :meth:`~torchrl.envs.Transform._call`.</span>

<span class="sd">        This method is not called within `env.step` at any point. However, is is called within</span>
<span class="sd">        :meth:`~torchrl.data.ReplayBuffer.sample`.</span>

<span class="sd">        .. note:: ``forward`` also works with regular keyword arguments using :class:`~tensordict.nn.dispatch` to cast the args</span>
<span class="sd">            names to the keys.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; class TransformThatMeasuresBytes(Transform):</span>
<span class="sd">            ...     &#39;&#39;&#39;Measures the number of bytes in the tensordict, and writes it under `&quot;bytes&quot;`.&#39;&#39;&#39;</span>
<span class="sd">            ...     def __init__(self):</span>
<span class="sd">            ...         super().__init__(in_keys=[], out_keys=[&quot;bytes&quot;])</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def forward(self, tensordict: TensorDictBase) -&gt; TensorDictBase:</span>
<span class="sd">            ...         bytes_in_td = tensordict.bytes()</span>
<span class="sd">            ...         tensordict[&quot;bytes&quot;] = bytes</span>
<span class="sd">            ...         return tensordict</span>
<span class="sd">            &gt;&gt;&gt; t = TransformThatMeasuresBytes()</span>
<span class="sd">            &gt;&gt;&gt; env = env.append_transform(t) # works within envs</span>
<span class="sd">            &gt;&gt;&gt; t(TensorDict(a=0))  # Works offline too.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies the inverse transform to a tensor or a leaf.</span>

<span class="sd">        This operation can be called multiple times (if multiples keys of the</span>
<span class="sd">        tensordict match the keys of the transform) for each entry in ``self.in_keys_inv``</span>
<span class="sd">        before the `TransformedEnv().base_env.step` is undertaken.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; class AddOneToAction(Transform):</span>
<span class="sd">            ...     &#39;&#39;&#39;A transform that adds 1 to the action tensor.&#39;&#39;&#39;</span>
<span class="sd">            ...     def __init__(self):</span>
<span class="sd">            ...         super().__init__(in_keys=[], out_keys=[], in_keys_inv=[&quot;action&quot;], out_keys_inv=[&quot;action&quot;])</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def _inv_apply_transform(self, action: torch.Tensor) -&gt; torch.Tensor:</span>
<span class="sd">            ...         return action + 1</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">invertible</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reads and possibly modify the input tensordict before it is passed to :meth:`~torchrl.envs.EnvBase.step`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; class AddOneToAllTensorDictBeforeStep(Transform):</span>
<span class="sd">            ...     &#39;&#39;&#39;Adds 1 to the whole content of the input to the env before the step is taken.&#39;&#39;&#39;</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def _inv_call(self, tensordict: TensorDictBase) -&gt; TensorDictBase:</span>
<span class="sd">            ...         return tensordict + 1</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_apply_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">out_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="Transform.inv"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.inv">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;in_keys_inv&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;out_keys_inv&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reads the input tensordict, and for the selected keys, applies the inverse transform.</span>

<span class="sd">        By default, this method:</span>

<span class="sd">        - calls directly :meth:`~torchrl.envs.Transform._inv_apply_transform`.</span>
<span class="sd">        - does not call :meth:`~torchrl.envs.Transform._inv_call`.</span>

<span class="sd">        .. note:: ``inv`` also works with regular keyword arguments using :class:`~tensordict.nn.dispatch` to cast the args</span>
<span class="sd">            names to the keys.</span>

<span class="sd">        .. note:: ``inv`` is called by :meth:`~torchrl.data.ReplayBuffer.extend`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">clone</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># we privilege speed for tensordicts</span>
                <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">clone</span><span class="p">(</span><span class="n">tensordict</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span></div>

<div class="viewcode-block" id="Transform.transform_env_device"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_env_device">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_env_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the device of the parent env.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">device</span></div>

<div class="viewcode-block" id="Transform.transform_env_batch_size"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_env_batch_size">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_env_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the batch-size of the parent env.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">batch_size</span></div>

<div class="viewcode-block" id="Transform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the output spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        This method should generally be left untouched. Changes should be implemented using</span>
<span class="sd">        :meth:`transform_observation_spec`, :meth:`transform_reward_spec` and :meth:`transform_full_done_spec`.</span>
<span class="sd">        Args:</span>
<span class="sd">            output_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;full_reward_spec&quot;</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_reward_spec</span><span class="p">(</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;full_done_spec&quot;</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_done_spec</span><span class="p">(</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="n">output_spec_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">unravel_key</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">}</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_keys</span> <span class="o">-</span> <span class="n">in_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_spec_keys</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The key &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; is unaccounted for by the transform (expected keys </span><span class="si">{</span><span class="n">output_spec_keys</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Every new entry in the tensordict resulting from a call to a transform must be &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;registered in the specs for torchrl rollouts to be consistently built. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Make sure transform_output_spec/transform_observation_spec/... is coded correctly. &quot;</span>
                    <span class="s2">&quot;This warning will trigger a KeyError in v0.9, make sure to adapt your code accordingly.&quot;</span><span class="p">,</span>
                    <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

<div class="viewcode-block" id="Transform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the input spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_state_spec</span><span class="p">(</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_action_spec</span><span class="p">(</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="Transform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the observation spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            observation_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="Transform.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the reward spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            reward_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">reward_spec</span></div>

<div class="viewcode-block" id="Transform.transform_done_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_done_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_done_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the done spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            done_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">done_spec</span></div>

<div class="viewcode-block" id="Transform.transform_action_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_action_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the action spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            action_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">action_spec</span></div>

<div class="viewcode-block" id="Transform.transform_state_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.transform_state_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the state spec such that the resulting spec matches transform mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            state_spec (TensorSpec): spec before the transform</span>

<span class="sd">        Returns:</span>
<span class="sd">            expected spec after the transform</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">state_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">)&quot;</span>

<div class="viewcode-block" id="Transform.set_container"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.set_container">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">container</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">EnvBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;parent of transform </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> already set. &quot;</span>
                <span class="s2">&quot;Call `transform.clone()` to get a similar transform with no parent set.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">container</span><span class="p">)</span> <span class="k">if</span> <span class="n">container</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_parent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Transform.reset_parent"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.reset_parent">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_parent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Transform.clone"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.clone">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
        <span class="n">self_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="c1"># modules, params, buffers</span>
        <span class="n">buffers</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_buffers&quot;</span><span class="p">)</span>
        <span class="n">modules</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_modules&quot;</span><span class="p">)</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_parameters&quot;</span><span class="p">)</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_parameters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_modules&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_buffers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span>

        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_parent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">self_copy</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self_copy</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">container</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EnvBase</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the env containing the transform.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import TransformedEnv, Compose, RewardSum, StepCounter</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; env = TransformedEnv(GymEnv(&quot;Pendulum-v1&quot;), Compose(RewardSum(), StepCounter()))</span>
<span class="sd">            &gt;&gt;&gt; env.transform[0].container is env</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;_container&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;transform parent uninitialized&quot;</span><span class="p">)</span>
        <span class="n">container_weakref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">container_weakref</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span>
        <span class="k">if</span> <span class="n">container</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">container</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
            <span class="c1"># if it&#39;s not an env, it should be a Compose transform</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">Compose</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;A transform parent must be either another Compose transform or an environment object.&quot;</span>
                <span class="p">)</span>
            <span class="n">compose</span> <span class="o">=</span> <span class="n">container</span>
            <span class="n">container_weakref</span> <span class="o">=</span> <span class="n">compose</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_container&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">container_weakref</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># container is a weakref</span>
                <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span>
        <span class="k">return</span> <span class="n">container</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">container</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">container</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container</span><span class="p">()</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">container</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">parent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the parent env of the transform.</span>

<span class="sd">        The parent env is the env that contains all the transforms up until the current one.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import TransformedEnv, Compose, RewardSum, StepCounter</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; env = TransformedEnv(GymEnv(&quot;Pendulum-v1&quot;), Compose(RewardSum(), StepCounter()))</span>
<span class="sd">            &gt;&gt;&gt; env.transform[1].parent</span>
<span class="sd">            TransformedEnv(</span>
<span class="sd">                env=GymEnv(env=Pendulum-v1, batch_size=torch.Size([]), device=cpu),</span>
<span class="sd">                transform=Compose(</span>
<span class="sd">                        RewardSum(keys=[&#39;reward&#39;])))</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: ideally parent should be a weakref, like container, to avoid keeping track of a parent that</span>
        <span class="c1">#  is de facto out of scope.</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_parent&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;_container&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;transform parent uninitialized&quot;</span><span class="p">)</span>
            <span class="n">container_weakref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">container_weakref</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">container_weakref</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">container</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="s2">&quot;transform container out of scope. Returning None for parent.&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">container</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
                <span class="c1"># if it&#39;s not an env, it should be a Compose transform</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">Compose</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;A transform parent must be either another Compose transform or an environment object.&quot;</span>
                    <span class="p">)</span>
                <span class="n">parent</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">container</span><span class="o">.</span><span class="n">_rebuild_up_to</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">TransformedEnv</span><span class="p">):</span>
                <span class="n">parent</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">container</span><span class="o">.</span><span class="n">base_env</span><span class="p">,</span> <span class="n">auto_unwrap</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;container is of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">container</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_parent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">parent</span>
        <span class="k">return</span> <span class="n">parent</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">empty_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_parent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span> <span class="o">=</span> <span class="n">mode</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span>

<div class="viewcode-block" id="Transform.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform.to">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Transform</span><span class="p">:</span>
        <span class="c1"># remove the parent, because it could have the wrong device associated</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_TEnvPostInit</span><span class="p">(</span><span class="n">_EnvPostInit</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">instance</span><span class="p">:</span> <span class="n">EnvBase</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">_EnvPostInit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># we skip the materialization of the specs, because this can&#39;t be done with lazy</span>
        <span class="c1"># transforms such as ObservationNorm.</span>
        <span class="k">return</span> <span class="n">instance</span>


<div class="viewcode-block" id="TransformedEnv"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TransformedEnv</span><span class="p">(</span><span class="n">EnvBase</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">_TEnvPostInit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transformed environment.</span>

<span class="sd">    Args:</span>
<span class="sd">        base_env (EnvBase): original environment to be transformed.</span>
<span class="sd">        transform (Transform or callable, optional): transform to apply to the tensordict resulting</span>
<span class="sd">            from :obj:`base_env.step(td)`. If none is provided, an empty Compose</span>
<span class="sd">            placeholder in an eval mode is used.</span>

<span class="sd">            .. note:: If ``transform`` is a callable, it must receive as input a single tensordict</span>
<span class="sd">              and output a tensordict as well. The callable will be called at ``step``</span>
<span class="sd">              and ``reset`` time: if it acts on the reward (which is absent at</span>
<span class="sd">              reset time), a check needs to be implemented to ensure that</span>
<span class="sd">              the transform will run smoothly:</span>

<span class="sd">                &gt;&gt;&gt; def add_1(data):</span>
<span class="sd">                ...     if &quot;reward&quot; in data.keys():</span>
<span class="sd">                ...         return data.set(&quot;reward&quot;, data.get(&quot;reward&quot;) + 1)</span>
<span class="sd">                ...     return data</span>
<span class="sd">                &gt;&gt;&gt; env = TransformedEnv(base_env, add_1)</span>

<span class="sd">        cache_specs (bool, optional): if ``True``, the specs will be cached once</span>
<span class="sd">            and for all after the first call (i.e. the specs will be</span>
<span class="sd">            transformed only once). If the transform changes during</span>
<span class="sd">            training, the original spec transform may not be valid anymore,</span>
<span class="sd">            in which case this value should be set  to `False`. Default is</span>
<span class="sd">            `True`.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        auto_unwrap (bool, optional): if ``True``, wrapping a transformed env in  transformed env</span>
<span class="sd">            unwraps the transforms of the inner TransformedEnv in the outer one (the new instance).</span>
<span class="sd">            Defaults to ``True``.</span>

<span class="sd">            .. note:: This behavior will switch to ``False`` in v0.9.</span>

<span class="sd">            .. seealso:: :class:`~torchrl.set_auto_unwrap_transformed_env`</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v0&quot;)</span>
<span class="sd">        &gt;&gt;&gt; transform = RewardScaling(0.0, 1.0)</span>
<span class="sd">        &gt;&gt;&gt; transformed_env = TransformedEnv(env, transform)</span>
<span class="sd">        &gt;&gt;&gt; # check auto-unwrap</span>
<span class="sd">        &gt;&gt;&gt; transformed_env = TransformedEnv(transformed_env, StepCounter())</span>
<span class="sd">        &gt;&gt;&gt; # The inner env has been unwrapped</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(transformed_env.base_env, GymEnv)</span>

<span class="sd">    .. note::</span>
<span class="sd">        The first argument was renamed from ``env`` to ``base_env`` for clarity.</span>
<span class="sd">        The old ``env`` argument is still supported for backward compatibility</span>
<span class="sd">        but will be removed in v0.12. A deprecation warning will be shown when</span>
<span class="sd">        using the old argument name.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">base_env</span><span class="p">:</span> <span class="n">EnvBase</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_specs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">auto_unwrap</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">base_env</span><span class="p">:</span> <span class="n">EnvBase</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_specs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">auto_unwrap</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span><span class="p">,</span>  <span class="c1"># type: ignore[misc]  # deprecated</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_specs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">auto_unwrap</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="o">...</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Backward compatibility: handle both old and new syntax</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># New syntax: TransformedEnv(base_env, transform, ...)</span>
            <span class="n">base_env</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">cache_specs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_specs&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">auto_unwrap</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;auto_unwrap&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;env&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="c1"># Old syntax: TransformedEnv(env=..., transform=...)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The &#39;env&#39; argument is deprecated and will be removed in v0.12. &quot;</span>
                <span class="s2">&quot;Use &#39;base_env&#39; instead.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">base_env</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;env&quot;</span><span class="p">)</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">cache_specs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_specs&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">auto_unwrap</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;auto_unwrap&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;base_env&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="c1"># New syntax with keyword arguments: TransformedEnv(base_env=..., transform=...)</span>
            <span class="n">base_env</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;base_env&quot;</span><span class="p">)</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">cache_specs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_specs&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">auto_unwrap</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;auto_unwrap&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;TransformedEnv requires a base_env argument&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">base_env</span> <span class="o">=</span> <span class="n">base_env</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">base_env</span><span class="o">.</span><span class="n">device</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_done_after_reset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Type matching must be exact here, because subtyping could introduce differences in behavior that must</span>
        <span class="c1"># be contained within the subclass.</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">base_env</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TransformedEnv</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TransformedEnv</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">auto_unwrap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">auto_unwrap</span> <span class="o">=</span> <span class="n">auto_unwrap_transformed_env</span><span class="p">(</span><span class="n">allow_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">auto_unwrap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s2">&quot;The default behavior of TransformedEnv will change in version 0.9. &quot;</span>
                        <span class="s2">&quot;Nested TransformedEnvs will no longer be automatically unwrapped by default. &quot;</span>
                        <span class="s2">&quot;To prepare for this change, use set_auto_unwrap_transformed_env(val: bool) &quot;</span>
                        <span class="s2">&quot;as a decorator or context manager, or set the environment variable &quot;</span>
                        <span class="s2">&quot;AUTO_UNWRAP_TRANSFORMED_ENV to &#39;False&#39;.&quot;</span><span class="p">,</span>
                        <span class="ne">FutureWarning</span><span class="p">,</span>
                        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">auto_unwrap</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">auto_unwrap</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">auto_unwrap</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_env</span><span class="p">(</span><span class="n">base_env</span><span class="o">.</span><span class="n">base_env</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">Compose</span><span class="p">:</span>
                <span class="c1"># we don&#39;t use isinstance as some transforms may be subclassed from</span>
                <span class="c1"># Compose but with other features that we don&#39;t want to lose.</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">transform</span><span class="p">):</span>
                        <span class="n">transform</span> <span class="o">=</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;Invalid transform type, expected a Transform instance or a callable &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;but got an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>
                <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">transform</span> <span class="o">=</span> <span class="p">[</span><span class="n">transform</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">transform</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">transform</span><span class="p">:</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
            <span class="n">env_transform</span> <span class="o">=</span> <span class="n">base_env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">env_transform</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">Compose</span><span class="p">:</span>
                <span class="n">env_transform</span> <span class="o">=</span> <span class="p">[</span><span class="n">env_transform</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">env_transform</span><span class="p">:</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="o">*</span><span class="n">env_transform</span><span class="p">,</span> <span class="o">*</span><span class="n">transform</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_env</span><span class="p">(</span><span class="n">base_env</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_last_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_specs</span> <span class="o">=</span> <span class="n">cache_specs</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_input_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_output_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">transform_env_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="c1"># during init, the base_env is not yet defined</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([])</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot modify the batch-size of a transformed env. Change the batch size of the base_env instead.&quot;</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TransformedEnv.add_truncated_keys"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.add_truncated_keys">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">add_truncated_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">add_truncated_keys</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="c1"># def _post_step_mdp_hooks(self, tensordict: TensorDictBase) -&gt; TensorDictBase:</span>
    <span class="c1"># &quot;&quot;&quot;Allows modification of the tensordict after the step_mdp.&quot;&quot;&quot;</span>
    <span class="c1"># if type(self.base_env)._post_step_mdp_hooks is not None:</span>
    <span class="c1"># If the base env has a _post_step_mdp_hooks, we call it</span>
    <span class="c1"># tensordict = self.base_env._post_step_mdp_hooks(tensordict)</span>
    <span class="c1"># return tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_env</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="n">env</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="c1"># updates need not be inplace, as transforms may modify values out-place</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_inplace_update</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Transform</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="nd">@transform</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">transform</span><span class="p">):</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Expected a transform of type torchrl.envs.transforms.Transform or a callable,</span>
<span class="s2">but got an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;&quot;&quot;</span>
                <span class="p">)</span>
        <span class="n">prev_transform</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prev_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prev_transform</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="n">prev_transform</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="o">=</span> <span class="n">transform</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># during init, the device is checked</span>
            <span class="k">return</span> <span class="n">device</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">transform_env_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;device is a read-only property&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_locked</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">batch_locked</span>

    <span class="nd">@batch_locked</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_locked</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;batch_locked is a read-only property&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_type_checks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">run_type_checks</span>

    <span class="nd">@run_type_checks</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_type_checks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;run_type_checks is a read-only property for TransformedEnvs&quot;</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_allow_done_after_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_allow_done_after_reset</span>

    <span class="nd">@_allow_done_after_reset</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_allow_done_after_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;_allow_done_after_reset is a read-only property for TransformedEnvs&quot;</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inplace_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_inplace_update</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Observation spec of the transformed environment.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_specs</span><span class="p">:</span>
            <span class="n">output_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_output_spec&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">output_spec</span>
        <span class="n">output_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_output_spec</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output_spec</span>

    <span class="nd">@_maybe_unlock</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_make_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">output_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">output_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># remove cached key values, but not _input_spec</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">output_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">transform_output_spec</span><span class="p">(</span><span class="n">output_spec</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_specs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_output_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_spec</span>
        <span class="k">return</span> <span class="n">output_spec</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Observation spec of the transformed environment.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_specs</span><span class="p">:</span>
            <span class="n">input_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_input_spec&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">input_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">input_spec</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_input_spec</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">input_spec</span>

    <span class="nd">@_maybe_unlock</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_make_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">input_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># remove cached key values, but not _input_spec</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">transform_input_spec</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_specs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_input_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_spec</span>
        <span class="k">return</span> <span class="n">input_spec</span>

<div class="viewcode-block" id="TransformedEnv.rand_action"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.rand_action">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">rand_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="p">)</span><span class="o">.</span><span class="n">rand_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">EnvBase</span><span class="o">.</span><span class="n">rand_action</span><span class="p">:</span>
            <span class="c1"># TODO: this will fail if the transform modifies the input.</span>
            <span class="c1">#  For instance, if an env overrides rand_action and we build a</span>
            <span class="c1">#  env = PendulumEnv().append_transform(ActionDiscretizer(num_intervals=4))</span>
            <span class="c1">#  env.rand_action will NOT have a discrete action!</span>
            <span class="c1">#  Getting a discrete action would require coding the inverse transform of an action within</span>
            <span class="c1">#  ActionDiscretizer (ie, float-&gt;int, not int-&gt;float).</span>
            <span class="c1">#  We can loosely check that the action_spec isn&#39;t altered - that doesn&#39;t mean the action is</span>
            <span class="c1">#  intact but it covers part of these alterations.</span>
            <span class="c1">#</span>
            <span class="c1"># The following check may be expensive to run and could be cached.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_action_spec</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">full_action_spec</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The rand_action method from the base env </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;has been overwritten, but the transforms appended to the environment modify &quot;</span>
                    <span class="s2">&quot;the action. To call the base env rand_action method, we should then invert the &quot;</span>
                    <span class="s2">&quot;action transform, which is (in general) not doable. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;The full action spec of the base env is: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">full_action_spec</span><span class="si">}</span><span class="s2">, </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;the full action spec of the transformed env is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">full_action_spec</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">rand_action</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">rand_action</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># No need to clone here because inv does it already</span>
        <span class="c1"># tensordict = tensordict.clone(False)</span>
        <span class="n">next_preset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">tensordict_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

        <span class="c1"># It could be that the step must be skipped</span>
        <span class="n">partial_steps</span> <span class="o">=</span> <span class="n">tensordict_in</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">next_tensordict</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tensordict_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">partial_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_locked</span><span class="p">:</span>
                <span class="c1"># Batched envs have their own way of dealing with this - batched envs that are not batched-locked may fail here</span>
                <span class="k">if</span> <span class="n">partial_steps</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="n">partial_steps</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tensordict_batch_size</span> <span class="o">=</span> <span class="n">tensordict_in</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="n">partial_steps</span> <span class="o">=</span> <span class="n">partial_steps</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">tensordict_batch_size</span><span class="p">)</span>
                    <span class="n">tensordict_in_save</span> <span class="o">=</span> <span class="n">tensordict_in</span><span class="p">[</span><span class="o">~</span><span class="n">partial_steps</span><span class="p">]</span>
                    <span class="n">tensordict_in</span> <span class="o">=</span> <span class="n">tensordict_in</span><span class="p">[</span><span class="n">partial_steps</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">partial_steps</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="n">next_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_skip_tensordict</span><span class="p">(</span><span class="n">tensordict_in</span><span class="p">)</span>
                    <span class="c1"># No need to copy anything</span>
                    <span class="n">partial_steps</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="n">partial_steps</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="c1"># trust that the _step can handle this!</span>
                    <span class="n">tensordict_in</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="n">partial_steps</span><span class="p">)</span>
                    <span class="c1"># The filling should be handled by the sub-env</span>
                    <span class="n">partial_steps</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">partial_steps</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">tensordict_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tensordict_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

        <span class="k">if</span> <span class="n">next_tensordict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">tensordict_in</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># tensordict could already have a &quot;next&quot; key</span>
                <span class="c1"># this could be done more efficiently by not excluding but just passing</span>
                <span class="c1"># the necessary keys</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">next_preset</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_complete_done</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">)</span>
            <span class="c1"># we want the input entries to remain unchanged</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">tensordict_in</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">partial_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">tensordict_batch_size</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">select_and_clone</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">partial_steps</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                <span class="n">result</span><span class="p">[</span><span class="o">~</span><span class="n">partial_steps</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensordict_in_save</span><span class="o">.</span><span class="n">_fast_apply</span><span class="p">(</span>
                    <span class="n">select_and_clone</span><span class="p">,</span>
                    <span class="n">tensordict_in_save</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">is_leaf</span><span class="o">=</span><span class="n">_is_leaf_nontensor</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">partial_steps</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">result</span><span class="p">[</span><span class="n">partial_steps</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_tensordict</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="TransformedEnv.set_seed"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the seeds of the environment.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="o">=</span><span class="n">static_seed</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This method is not used in transformed envs.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We must avoid modifying the original tensordict so a shallow copy is necessary.</span>
            <span class="c1"># We just select the input data and reset signal, which is all we need.</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="c1"># We always call _reset_env_preprocess, even if tensordict is None - that way one can augment that</span>
        <span class="c1"># method to do any pre-reset operation.</span>
        <span class="c1"># By default, within _reset_env_preprocess we will skip the inv call when tensordict is None.</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">_reset_env_preprocess</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make sure all transforms see a source tensordict</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_complete_done</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_proc_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">):</span>
        <span class="c1"># self._complete_done(self.full_done_spec, reset)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_check_done</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">_update_during_reset</span><span class="p">(</span>
                <span class="n">tensordict_reset</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_keys</span>
            <span class="p">)</span>
        <span class="c1"># # we need to call `_call` as some transforms don&#39;t do the work in reset</span>
        <span class="c1"># # eg: CatTensor has only a _call method, no need for a reset since reset</span>
        <span class="c1"># # doesn&#39;t do anything special</span>
        <span class="c1"># mt_mode = self.transform.missing_tolerance</span>
        <span class="c1"># self.set_missing_tolerance(True)</span>
        <span class="c1"># reset = self.transform._call(reset)</span>
        <span class="c1"># self.set_missing_tolerance(mt_mode)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_complete_done</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">done_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># This step has already been completed. We assume the transform module do their job correctly.</span>
        <span class="k">return</span> <span class="n">data</span>

<div class="viewcode-block" id="TransformedEnv.state_dict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state_dict</span></div>

<div class="viewcode-block" id="TransformedEnv.load_state_dict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformedEnv.eval"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.eval">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;transform&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">():</span>
            <span class="c1"># when calling __init__, eval() is called but transforms are not set</span>
            <span class="c1"># yet.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TransformedEnv.train"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.train">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_closed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">is_closed</span>

    <span class="nd">@is_closed</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_closed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">is_closed</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">raise_if_closed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">raise_if_closed</span><span class="o">=</span><span class="n">raise_if_closed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_closed</span> <span class="o">=</span> <span class="kc">True</span>

<div class="viewcode-block" id="TransformedEnv.empty_cache"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.empty_cache">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">empty_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_output_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_input_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span></div>

<div class="viewcode-block" id="TransformedEnv.append_transform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.append_transform">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">append_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Appends a transform to the env.</span>

<span class="sd">        :class:`~torchrl.envs.transforms.Transform` or callable are accepted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">transform</span><span class="p">):</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;TransformedEnv.append_transform expected a transform or a callable, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but received an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">,</span> <span class="n">Compose</span><span class="p">):</span>
            <span class="n">prev_transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span>
            <span class="n">prev_transform</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_transform</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TransformedEnv.insert_transform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.insert_transform">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">insert_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inserts a transform to the env at the desired index.</span>

<span class="sd">        :class:`~torchrl.envs.transforms.Transform` or callable are accepted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">transform</span><span class="p">):</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;TransformedEnv.insert_transform expected a transform or a callable, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but received an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">,</span> <span class="n">Compose</span><span class="p">):</span>
            <span class="n">compose</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">compose</span>  <span class="c1"># parent set automatically</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span>
                <span class="n">attr</span>
            <span class="p">)</span>  <span class="c1"># make sure that appropriate exceptions are raised</span>
        <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="s2">&quot;action_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;done_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;full_action_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;full_done_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;full_observation_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;full_reward_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;full_state_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;input_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;observation_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;output_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;reward_spec&quot;</span><span class="p">,</span>
                <span class="s2">&quot;state_spec&quot;</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not get </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2"> because an internal error was raised. To find what this error &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;is, call env.transform.transform_&lt;placeholder&gt;_spec(env.base_env.spec).&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">attr</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                    <span class="s2">&quot;passing built-in private methods is &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;not permitted with type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got attribute </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="s2">&quot;base_env&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">():</span>
                <span class="n">base_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="s2">&quot;base_env&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">base_env</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;env not set in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, cannot access </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">env_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;env=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">t_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;transform=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;TransformedEnv(</span><span class="se">\n</span><span class="si">{</span><span class="n">env_str</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">t_str</span><span class="si">}</span><span class="s2">)&quot;</span>

<div class="viewcode-block" id="TransformedEnv.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.to">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedEnv</span><span class="p">:</span>
        <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="n">convert_to_format</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_nn</span><span class="o">.</span><span class="n">_parse_to</span><span class="p">(</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">propobj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">propobj</span><span class="p">,</span> <span class="nb">property</span><span class="p">):</span>
            <span class="n">ancestors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__mro__</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">propobj</span><span class="p">,</span> <span class="nb">property</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">propobj</span><span class="o">.</span><span class="n">fset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">propobj</span><span class="o">.</span><span class="n">fset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
                <span class="n">propobj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ancestors</span><span class="o">.</span><span class="n">pop</span><span class="p">(),</span> <span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;can&#39;t set attribute </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># we may delete a TransformedEnv that contains an env contained by another</span>
        <span class="c1"># transformed env and that we don&#39;t want to close</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="TransformedEnv.set_missing_tolerance"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv.set_missing_tolerance">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Indicates if an KeyError should be raised whenever an in_key is missing from the input tensordict.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">set_missing_tolerance</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ObservationTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ObservationTransform.html#torchrl.envs.transforms.ObservationTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ObservationTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract class for transformations of the observations.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;observation&quot;</span><span class="p">,</span>
                <span class="s2">&quot;pixels&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Compose"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Compose</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Composes a chain of transforms.</span>

<span class="sd">    :class:`~torchrl.envs.transforms.Transform` or ``callable``s are accepted.</span>

<span class="sd">    The class can be instantiated in several ways:</span>

<span class="sd">    Args:</span>
<span class="sd">        *transforms (Transform): Variable number of transforms to compose.</span>
<span class="sd">        transforms (list[Transform], optional): A list of transforms to compose.</span>
<span class="sd">            This can be passed as a keyword argument.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v0&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Method 1: Using positional arguments</span>
<span class="sd">        &gt;&gt;&gt; transforms = Compose(RewardScaling(1.0, 1.0), RewardClipping(-2.0, 2.0))</span>
<span class="sd">        &gt;&gt;&gt; transformed_env = TransformedEnv(env, transforms)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Method 2: Using a list with positional argument</span>
<span class="sd">        &gt;&gt;&gt; transform_list = [RewardScaling(1.0, 1.0), RewardClipping(-2.0, 2.0)]</span>
<span class="sd">        &gt;&gt;&gt; transforms = Compose(transform_list)</span>
<span class="sd">        &gt;&gt;&gt; transformed_env = TransformedEnv(env, transforms)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Method 3: Using keyword argument</span>
<span class="sd">        &gt;&gt;&gt; transforms = Compose(transforms=[RewardScaling(1.0, 1.0), RewardClipping(-2.0, 2.0)])</span>
<span class="sd">        &gt;&gt;&gt; transformed_env = TransformedEnv(env, transforms)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Transform</span><span class="p">]):</span>
        <span class="o">...</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">trsfs</span><span class="p">:</span> <span class="n">Transform</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">trsfs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="s2">&quot;transforms&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">transforms</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;transforms&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">trsfs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trsfs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">transforms</span> <span class="o">=</span> <span class="n">trsfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transforms</span> <span class="o">=</span> <span class="n">trsfs</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keyword arguments: </span><span class="si">{</span><span class="n">kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">map_transform</span><span class="p">(</span><span class="n">trsf</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trsf</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">trsf</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">trsf</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">trsf</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Transform list must contain only transforms or &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;callable. Got a element of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">trsf</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">map_transform</span><span class="p">(</span><span class="n">trsf</span><span class="p">)</span> <span class="k">for</span> <span class="n">trsf</span> <span class="ow">in</span> <span class="n">transforms</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

<div class="viewcode-block" id="Compose.pop"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.pop">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">pop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Transform</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pop a transform from the chain.</span>

<span class="sd">        Args:</span>
<span class="sd">            index (int, optional): The index of the transform to pop. If None, the last transform is popped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The popped transform.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">slice</span> <span class="o">|</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Delete a transform in the chain.</span>

<span class="sd">        :class:`~torchrl.envs.transforms.Transform` or callable are accepted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__setitem__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">slice</span> <span class="o">|</span> <span class="nb">list</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set a transform in the chain.</span>

<span class="sd">        :class:`~torchrl.envs.transforms.Transform` or callable are accepted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

<div class="viewcode-block" id="Compose.close"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.close">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close the transform.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="Compose.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.to">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># because Module.to(...) does not call to(...) on sub-modules, we have</span>
        <span class="c1"># manually call it:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="Compose.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">):</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="Compose.transform_env_device"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_env_device">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_env_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_env_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">device</span></div>

<div class="viewcode-block" id="Compose.transform_env_batch_size"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_env_batch_size">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_env_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_env_batch_size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">batch_size</span></div>

<div class="viewcode-block" id="Compose.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="c1"># Input, action and state specs do NOT need to be reversed</span>
        <span class="c1"># although applying these specs requires them to be called backward.</span>
        <span class="c1"># To prove this, imagine we have 2 action transforms: t0 is an ActionDiscretizer, it maps float actions</span>
        <span class="c1"># from the env to int actions for the policy. We add one more transform t1 that, if a == a_action_max,</span>
        <span class="c1"># reduces its value by 1 (ie, the policy can sample actions from 0 to N + 1, and ActionDiscretizer</span>
        <span class="c1"># has top N values).</span>
        <span class="c1"># To apply this transform given an int action from the policy, we first call t1 to clamp the action to</span>
        <span class="c1"># N (from N+1), then call t0 to map it to a float.</span>
        <span class="c1"># We build this from TEnv(env, Compose(ActionDiscretizer, ActionClamp)) and call them starting with the</span>
        <span class="c1"># last then the first.</span>
        <span class="c1"># To know what the action spec is to the &#39;outside world&#39; (ie, to the policy) we must take</span>
        <span class="c1"># the action spec from the env, map it using t0 then t1 (going from in to out).</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">input_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_input_spec</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected Compose but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> with transform </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="Compose.transform_action_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_action_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="c1"># To understand why we don&#39;t invert, look up at transform_input_spec</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">action_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_action_spec</span><span class="p">(</span><span class="n">action_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected TensorSpec but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">action_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> with transform </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">action_spec</span></div>

<div class="viewcode-block" id="Compose.transform_state_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_state_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="c1"># To understand why we don&#39;t invert, look up at transform_input_spec</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">state_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_state_spec</span><span class="p">(</span><span class="n">state_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected Compose but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">state_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> with transform </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">state_spec</span></div>

<div class="viewcode-block" id="Compose.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected TensorSpec but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> with transform </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="Compose.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">output_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_output_spec</span><span class="p">(</span><span class="n">output_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected Compose but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">output_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> with transform </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

<div class="viewcode-block" id="Compose.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">reward_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_reward_spec</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected TensorSpec but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> with transform </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">reward_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">slice</span> <span class="o">|</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">[</span><span class="n">item</span><span class="p">]))</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">transform</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_env_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">):</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">_reset_env_preprocess</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="Compose.init"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.init">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span></div>

<div class="viewcode-block" id="Compose.append"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.append">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">append</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Appends a transform in the chain.</span>

<span class="sd">        :class:`~torchrl.envs.transforms.Transform` or callable are accepted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">transform</span><span class="p">):</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Compose.append expected a transform or a callable, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but received an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span> <span class="ow">is</span> <span class="n">Compose</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">transform</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">container</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">EnvBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="n">container</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

<div class="viewcode-block" id="Compose.insert"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose.insert">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">insert</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inserts a transform in the chain at the desired index.</span>

<span class="sd">        :class:`~torchrl.envs.transforms.Transform` or callable are accepted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">Transform</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">transform</span><span class="p">):</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">_CallableTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Compose.append expected a transform or a callable, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but received an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Index expected to be between [-</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">)</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">)</span><span class="si">}</span><span class="s2">] got index=</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># empty cache of all transforms to reset parents and specs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">index</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">)</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Transform</span><span class="p">]:</span>
        <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">):</span>
            <span class="n">layers_str</span> <span class="o">=</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="p">[</span><span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">trsf</span><span class="p">),</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">trsf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">layers_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">indent</span><span class="p">(</span><span class="n">layers_str</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="s1">&#39; &#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">layers_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">layers_str</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">empty_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
        <span class="n">transforms</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">Compose</span><span class="p">(</span><span class="o">*</span><span class="n">transforms</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">set_missing_tolerance</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_missing_tolerance</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_rebuild_up_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_transform</span><span class="p">):</span>
        <span class="n">container_weakref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_container&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">container_weakref</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">container</span> <span class="o">=</span> <span class="n">container_weakref</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">Compose</span><span class="p">):</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">parent_compose</span> <span class="o">=</span> <span class="n">container</span><span class="o">.</span><span class="n">_rebuild_up_to</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># returns None if there is no parent env</span>
                <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">TransformedEnv</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">container</span><span class="o">.</span><span class="n">base_env</span><span class="p">,</span> <span class="n">auto_unwrap</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">container</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># returns None if there is no parent env</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Container of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">container</span><span class="p">)</span><span class="si">}</span><span class="s2"> isn&#39;t supported.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">final_transform</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot rebuild with transform </span><span class="si">{</span><span class="n">final_transform</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="n">list_of_transforms</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">orig_trans</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">orig_trans</span> <span class="ow">is</span> <span class="n">final_transform</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">orig_trans</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">transform</span><span class="o">.</span><span class="n">reset_parent</span><span class="p">()</span>
            <span class="n">list_of_transforms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">Compose</span><span class="p">):</span>
            <span class="n">parent_compose</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Compose</span><span class="p">(</span><span class="o">*</span><span class="n">list_of_transforms</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">parent_compose</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">TransformedEnv</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">list_of_transforms</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">transform</span></div>


<div class="viewcode-block" id="ToTensorImage"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ToTensorImage.html#torchrl.envs.transforms.ToTensorImage">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ToTensorImage</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms a numpy-like image (W x H x C) to a pytorch image (C x W x H).</span>

<span class="sd">    Transforms an observation image from a (... x W x H x C) tensor to a</span>
<span class="sd">    (... x C x W x H) tensor. Optionally, scales the input tensor from the range</span>
<span class="sd">    [0, 255] to the range [0.0, 1.0] (see ``from_int`` for more details).</span>

<span class="sd">    In the other cases, tensors are returned without scaling.</span>

<span class="sd">    Args:</span>
<span class="sd">        from_int (bool, optional): if ``True``, the tensor will be scaled from</span>
<span class="sd">            the range [0, 255] to the range [0.0, 1.0]. if `False``, the tensor</span>
<span class="sd">            will not be scaled. if `None`, the tensor will be scaled if</span>
<span class="sd">            it&#39;s not a floating-point tensor. default=None.</span>
<span class="sd">        unsqueeze (bool): if ``True``, the observation tensor is unsqueezed</span>
<span class="sd">            along the first dimension. default=False.</span>
<span class="sd">        dtype (torch.dtype, optional): dtype to use for the resulting</span>
<span class="sd">            observations.</span>

<span class="sd">    Keyword arguments:</span>
<span class="sd">        in_keys (list of NestedKeys): keys to process.</span>
<span class="sd">        out_keys (list of NestedKeys): keys to write.</span>
<span class="sd">        shape_tolerant (bool, optional): if ``True``, the shape of the input</span>
<span class="sd">            images will be check. If the last channel is not `3`, the permutation</span>
<span class="sd">            will be ignored. Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; transform = ToTensorImage(in_keys=[&quot;pixels&quot;])</span>
<span class="sd">        &gt;&gt;&gt; ri = torch.randint(0, 255, (1 , 1, 10, 11, 3), dtype=torch.uint8)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&quot;pixels&quot;: ri},</span>
<span class="sd">        ...     [1, 1])</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; obs = td.get(&quot;pixels&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(obs.shape, obs.dtype)</span>
<span class="sd">        torch.Size([1, 1, 3, 10, 11]) torch.float32</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">from_int</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">unsqueeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shape_tolerant</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">from_int</span> <span class="o">=</span> <span class="n">from_int</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze</span> <span class="o">=</span> <span class="n">unsqueeze</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape_tolerant</span> <span class="o">=</span> <span class="n">shape_tolerant</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_tolerant</span> <span class="ow">or</span> <span class="n">observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                <span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">observation</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">from_int</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">from_int</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_unsqueeze</span><span class="p">(</span><span class="n">observation</span><span class="p">):</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

<div class="viewcode-block" id="ToTensorImage.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ToTensorImage.html#torchrl.envs.transforms.ToTensorImage.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">observation_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pixel_observation</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_unsqueeze</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_tolerant</span> <span class="ow">or</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="o">*</span><span class="n">dim</span><span class="p">,</span>
                    <span class="o">*</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span>
                    <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span>
                    <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="n">observation_spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_should_unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_like</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="o">|</span> <span class="n">TensorSpec</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_like</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">):</span>
            <span class="n">has_3_dimensions</span> <span class="o">=</span> <span class="n">observation_like</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">has_3_dimensions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">observation_like</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">return</span> <span class="n">has_3_dimensions</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_pixel_observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec</span></div>


<div class="viewcode-block" id="ClipTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ClipTransform.html#torchrl.envs.transforms.ClipTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ClipTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform to clip input (state, action) or output (observation, reward) values.</span>

<span class="sd">    This transform can take multiple input or output keys but only one value per</span>
<span class="sd">    transform. If multiple clipping values are needed, several transforms should</span>
<span class="sd">    be appended one after the other.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (list of NestedKeys): input entries (read)</span>
<span class="sd">        out_keys (list of NestedKeys): input entries (write)</span>
<span class="sd">        in_keys_inv (list of NestedKeys): input entries (read) during :meth:`inv` calls.</span>
<span class="sd">        out_keys_inv (list of NestedKeys): input entries (write) during :meth:`inv` calls.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        low (scalar, optional): the lower bound of the clipped space.</span>
<span class="sd">        high (scalar, optional): the higher bound of the clipped space.</span>

<span class="sd">    .. note:: Providing just one of the arguments ``low`` or ``high`` is permitted,</span>
<span class="sd">        but at least one must be provided.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, ClipTransform(in_keys=[&#39;observation&#39;], low=-1, high=0.1))</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(100)</span>
<span class="sd">        &gt;&gt;&gt; assert (r[&quot;observation&quot;] &lt;= 0.1).all()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">low</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">high</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">,</span> <span class="n">in_keys_inv</span><span class="p">,</span> <span class="n">out_keys_inv</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Either one or both of `high` and `low` must be provided.&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">check_val</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;low and high must be scalars or None. Got low=</span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2"> and high=</span><span class="si">{</span><span class="n">high</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">())</span><span class="o">.</span><span class="n">max</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span>
            <span class="n">ext</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
            <span class="k">return</span> <span class="n">val</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">ext</span>

        <span class="n">low</span><span class="p">,</span> <span class="n">low_eps</span><span class="p">,</span> <span class="n">low_min</span> <span class="o">=</span> <span class="n">check_val</span><span class="p">(</span><span class="n">low</span><span class="p">)</span>
        <span class="n">high</span><span class="p">,</span> <span class="n">high_eps</span><span class="p">,</span> <span class="n">high_max</span> <span class="o">=</span> <span class="n">check_val</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">low</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">high</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">low</span> <span class="o">&gt;=</span> <span class="n">high</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`low` must be strictly lower than `high`.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;low&quot;</span><span class="p">,</span> <span class="n">low</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">low_eps</span> <span class="o">=</span> <span class="n">low_eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">low_min</span> <span class="o">=</span> <span class="o">-</span><span class="n">low_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;high&quot;</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">high_eps</span> <span class="o">=</span> <span class="n">high_eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">high_max</span> <span class="o">=</span> <span class="n">high_max</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>

<div class="viewcode-block" id="ClipTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ClipTransform.html#torchrl.envs.transforms.ClipTransform.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Bounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_eps</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_max</span><span class="p">,</span>
            <span class="n">low</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_eps</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_min</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ClipTransform.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ClipTransform.html#torchrl.envs.transforms.ClipTransform.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">:</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                    <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_eps</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_max</span><span class="p">,</span>
                    <span class="n">low</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_eps</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">low</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_min</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>

    <span class="c1"># No need to transform the input spec since the outside world won&#39;t see the difference</span>
    <span class="c1"># def transform_input_spec(self, input_spec: TensorSpec) -&gt; TensorSpec:</span>
    <span class="c1">#     ...</span>


<div class="viewcode-block" id="TargetReturn"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TargetReturn.html#torchrl.envs.transforms.TargetReturn">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TargetReturn</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sets a target return for the agent to achieve in the environment.</span>

<span class="sd">    In goal-conditioned RL, the :class:`~.TargetReturn` is defined as the</span>
<span class="sd">    expected cumulative reward obtained from the current state to the goal state</span>
<span class="sd">    or the end of the episode. It is used as input for the policy to guide its behavior.</span>
<span class="sd">    For a trained policy typically the maximum return in the environment is</span>
<span class="sd">    chosen as the target return.</span>
<span class="sd">    However, as it is used as input to the policy module, it should be scaled</span>
<span class="sd">    accordingly.</span>
<span class="sd">    With the :class:`~.TargetReturn` transform, the tensordict can be updated</span>
<span class="sd">    to include the user-specified target return.</span>
<span class="sd">    The ``mode`` parameter can be used to specify</span>
<span class="sd">    whether the target return gets updated at every step by subtracting the</span>
<span class="sd">    reward achieved at each step or remains constant.</span>

<span class="sd">    Args:</span>
<span class="sd">        target_return (:obj:`float`): target return to be achieved by the agent.</span>
<span class="sd">        mode (str): mode to be used to update the target return. Can be either &quot;reduce&quot; or &quot;constant&quot;. Default: &quot;reduce&quot;.</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): keys pointing to the reward</span>
<span class="sd">            entries. Defaults to the reward keys of the parent env.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): keys pointing to the</span>
<span class="sd">            target keys. Defaults to a copy of in_keys where the last element</span>
<span class="sd">            has been substituted by ``&quot;target_return&quot;``, and raises an exception</span>
<span class="sd">            if these keys aren&#39;t unique.</span>
<span class="sd">        reset_key (NestedKey, optional): the reset key to be used as partial</span>
<span class="sd">            reset indicator. Must be unique. If not provided, defaults to the</span>
<span class="sd">            only reset key of the parent environment (if it has only one)</span>
<span class="sd">            and raises an exception otherwise.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     GymEnv(&quot;CartPole-v1&quot;),</span>
<span class="sd">        ...     TargetReturn(10.0, mode=&quot;reduce&quot;))</span>
<span class="sd">        &gt;&gt;&gt; env.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(20)[&#39;target_return&#39;].squeeze()</span>
<span class="sd">        tensor([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  0., -1., -2., -3.])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">MODES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reduce&quot;</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">]</span>
    <span class="n">MODE_ERR</span> <span class="o">=</span> <span class="s2">&quot;Mode can only be &#39;reduce&#39; or &#39;constant&#39;.&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">target_return</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;reduce&quot;</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">MODES</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">MODE_ERR</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_return</span> <span class="o">=</span> <span class="n">target_return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span> <span class="o">=</span> <span class="n">reset_key</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NestedKey</span><span class="p">:</span>
        <span class="n">reset_key</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_reset_key&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reset_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">reset_key</span>
        <span class="n">reset_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reset_keys</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Got more than one reset key in env </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="si">}</span><span class="s2">, cannot infer which one to use. Consider providing the reset key in the </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> constructor.&quot;</span>
            <span class="p">)</span>
        <span class="n">reset_key</span> <span class="o">=</span> <span class="n">reset_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">reset_key</span>
        <span class="k">return</span> <span class="n">reset_key</span>

    <span class="nd">@reset_key</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_in_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">return</span> <span class="n">in_keys</span>

    <span class="nd">@in_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">_replace_last</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="s2">&quot;target_return&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">out_keys</span><span class="p">))</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Could not infer the target_return because multiple rewards are located at the same level.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="k">return</span> <span class="n">out_keys</span>

    <span class="nd">@out_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">):</span>
        <span class="n">_reset</span> <span class="o">=</span> <span class="n">_get_reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
            <span class="n">target_return</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">target_return</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">target_return</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">fill_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_return</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_return</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                    <span class="n">expand_as_right</span><span class="p">(</span><span class="o">~</span><span class="n">_reset</span><span class="p">,</span> <span class="n">target_return</span><span class="p">),</span>
                    <span class="n">target_return</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">target_return</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">out_key</span><span class="p">,</span>
                <span class="n">target_return</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDict</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">val_in</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">val_out</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">val_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">target_return</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span>
                    <span class="n">val_in</span><span class="p">,</span>
                    <span class="n">val_out</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">target_return</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">next_tensordict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target_return</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target_return</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">reward</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The shape of the reward (</span><span class="si">{</span><span class="n">reward</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">) and target return (</span><span class="si">{</span><span class="n">target_return</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">) must match.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;reduce&quot;</span><span class="p">:</span>
            <span class="n">target_return</span> <span class="o">=</span> <span class="n">target_return</span> <span class="o">-</span> <span class="n">reward</span>
            <span class="k">return</span> <span class="n">target_return</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;constant&quot;</span><span class="p">:</span>
            <span class="n">target_return</span> <span class="o">=</span> <span class="n">target_return</span>
            <span class="k">return</span> <span class="n">target_return</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown mode: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="TargetReturn.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TargetReturn.html#torchrl.envs.transforms.TargetReturn.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="TargetReturn.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TargetReturn.html#torchrl.envs.transforms.TargetReturn.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_reward_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_reward_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_done_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="c1"># we account for this for completeness but it should never be the case</span>
                <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;in_key </span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2"> not found in output_spec.&quot;</span><span class="p">)</span>
            <span class="n">target_return_spec</span> <span class="o">=</span> <span class="n">Unbounded</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">target</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">target</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># because all reward keys are discarded from the data during calls</span>
            <span class="c1"># to step_mdp, we must put this in observation_spec</span>
            <span class="n">observation_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_return_spec</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="TargetReturn.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TargetReturn.html#torchrl.envs.transforms.TargetReturn.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="c1"># we must add the target return to the input spec</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div></div>


<div class="viewcode-block" id="RewardClipping"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardClipping.html#torchrl.envs.transforms.RewardClipping">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RewardClipping</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Clips the reward between `clamp_min` and `clamp_max`.</span>

<span class="sd">    Args:</span>
<span class="sd">        clip_min (scalar): minimum value of the resulting reward.</span>
<span class="sd">        clip_max (scalar): maximum value of the resulting reward.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">clamp_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clamp_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="n">clamp_min_tensor</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">clamp_min</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clamp_min</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">clamp_min</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">clamp_max_tensor</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">clamp_max</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clamp_max</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">clamp_max</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;clamp_min&quot;</span><span class="p">,</span> <span class="n">clamp_min_tensor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;clamp_max&quot;</span><span class="p">,</span> <span class="n">clamp_max_tensor</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp_min</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp_min</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reward</span>

<div class="viewcode-block" id="RewardClipping.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardClipping.html#torchrl.envs.transforms.RewardClipping.transform_reward_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">,</span> <span class="n">Unbounded</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Bounded</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.transform_reward_spec not &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;implemented for tensor spec of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;clamp_min=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, clamp_max&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="BinarizeReward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BinarizeReward.html#torchrl.envs.transforms.BinarizeReward">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">BinarizeReward</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Maps the reward to a binary value (0 or 1) if the reward is null or non-null, respectively.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (List[NestedKey]): input keys</span>
<span class="sd">        out_keys (List[NestedKey], optional): output keys. Defaults to value</span>
<span class="sd">            of ``in_keys``.</span>
<span class="sd">        dtype (torch.dtype, optional): the dtype of the binerized reward.</span>
<span class="sd">            Defaults to ``torch.int8``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">reward</span><span class="o">.</span><span class="n">shape</span> <span class="ow">or</span> <span class="n">reward</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Reward shape last dimension must be singleton, got reward of shape </span><span class="si">{</span><span class="n">reward</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">reward</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>

<div class="viewcode-block" id="BinarizeReward.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BinarizeReward.html#torchrl.envs.transforms.BinarizeReward.transform_reward_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Binary</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="Resize"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Resize.html#torchrl.envs.transforms.Resize">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Resize</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Resizes a pixel observation.</span>

<span class="sd">    Args:</span>
<span class="sd">        w (int): resulting width.</span>
<span class="sd">        h (int, optional): resulting height. If not provided, the value of `w`</span>
<span class="sd">            is taken.</span>
<span class="sd">        interpolation (str): interpolation method</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; t = Resize(64, 84)</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;HalfCheetah-v4&quot;, from_pixels=True)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, Compose(ToTensorImage(), t))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">interpolation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># we also allow lists or tuples</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">w</span>
        <span class="k">if</span> <span class="n">h</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">w</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_has_tv</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Torchvision not found. The Resize transform relies on &quot;</span>
                <span class="s2">&quot;torchvision implementation. &quot;</span>
                <span class="s2">&quot;Consider installing this dependency.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">InterpolationMode</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">interpolation_fn</span><span class="p">(</span><span class="n">interpolation</span><span class="p">):</span>  <span class="c1"># noqa: D103</span>
                <span class="k">return</span> <span class="n">InterpolationMode</span><span class="p">(</span><span class="n">interpolation</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">interpolation_fn</span><span class="p">(</span><span class="n">interpolation</span><span class="p">):</span>  <span class="c1"># noqa: D103</span>
                <span class="k">return</span> <span class="n">interpolation</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">interpolation_fn</span><span class="p">(</span><span class="n">interpolation</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># flatten if necessary</span>
        <span class="k">if</span> <span class="n">observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">]):</span>
            <span class="k">return</span> <span class="n">observation</span>
        <span class="n">ndim</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">sizes</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ndim</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">resize</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms.functional_tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">resize</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span>
            <span class="n">observation</span><span class="p">,</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">],</span>
            <span class="n">interpolation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">,</span>
            <span class="n">antialias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">observation</span>

<div class="viewcode-block" id="Resize.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Resize.html#torchrl.envs.transforms.Resize.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;w=</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span><span class="si">}</span><span class="s2">, h=</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;interpolation=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="si">}</span><span class="s2">, keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="Crop"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Crop.html#torchrl.envs.transforms.Crop">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Crop</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Crops the input image at the specified location and output size.</span>

<span class="sd">    Args:</span>
<span class="sd">        w (int): resulting width</span>
<span class="sd">        h (int, optional): resulting height. If None, then w is used (square crop).</span>
<span class="sd">        top (int, optional): top pixel coordinate to start cropping. Default is 0, i.e. top of the image.</span>
<span class="sd">        left (int, optional): left pixel coordinate to start cropping. Default is 0, i.e. left of the image.</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): the entries to crop. If none is provided,</span>
<span class="sd">            ``[&quot;pixels&quot;]`` is assumed.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): the cropped images keys. If none is</span>
<span class="sd">            provided, ``in_keys`` is assumed.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">top</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">left</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h</span> <span class="k">if</span> <span class="n">h</span> <span class="k">else</span> <span class="n">w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top</span> <span class="o">=</span> <span class="n">top</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">left</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">crop</span>

        <span class="n">observation</span> <span class="o">=</span> <span class="n">crop</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">top</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">left</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="Crop.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Crop.html#torchrl.envs.transforms.Crop.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;w=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, h=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, top=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">top</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, left=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">left</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="CenterCrop"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CenterCrop.html#torchrl.envs.transforms.CenterCrop">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CenterCrop</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Crops the center of an image.</span>

<span class="sd">    Args:</span>
<span class="sd">        w (int): resulting width</span>
<span class="sd">        h (int, optional): resulting height. If None, then w is used (square crop).</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): the entries to crop. If none is provided,</span>
<span class="sd">            :obj:`[&quot;pixels&quot;]` is assumed.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): the cropped images keys. If none is</span>
<span class="sd">            provided, :obj:`in_keys` is assumed.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h</span> <span class="k">if</span> <span class="n">h</span> <span class="k">else</span> <span class="n">w</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">center_crop</span>

        <span class="n">observation</span> <span class="o">=</span> <span class="n">center_crop</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">observation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="CenterCrop.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CenterCrop.html#torchrl.envs.transforms.CenterCrop.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;w=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, h=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="FlattenObservation"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.FlattenObservation.html#torchrl.envs.transforms.FlattenObservation">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">FlattenObservation</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Flatten adjacent dimensions of a tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        first_dim (int): first dimension of the dimensions to flatten.</span>
<span class="sd">        last_dim (int): last dimension of the dimensions to flatten.</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): the entries to flatten. If none is provided,</span>
<span class="sd">            :obj:`[&quot;pixels&quot;]` is assumed.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): the flatten observation keys. If none is</span>
<span class="sd">            provided, :obj:`in_keys` is assumed.</span>
<span class="sd">        allow_positive_dim (bool, optional): if ``True``, positive dimensions are accepted.</span>
<span class="sd">            :obj:`FlattenObservation` will map these to the n^th feature dimension</span>
<span class="sd">            (ie n^th dimension after batch size of parent env) of the input tensor.</span>
<span class="sd">            Defaults to False, ie. non-negative dimensions are not permitted.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">first_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">last_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">allow_positive_dim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">allow_positive_dim</span> <span class="ow">and</span> <span class="n">first_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;first_dim should be smaller than 0 to accommodate for &quot;</span>
                <span class="s2">&quot;envs of different batch_sizes.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">allow_positive_dim</span> <span class="ow">and</span> <span class="n">last_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;last_dim should be smaller than 0 to accommodate for &quot;</span>
                <span class="s2">&quot;envs of different batch_sizes.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_first_dim</span> <span class="o">=</span> <span class="n">first_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_dim</span> <span class="o">=</span> <span class="n">last_dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">first_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_first_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_first_dim</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_first_dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">last_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_dim</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_dim</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">ObservationTransform</span><span class="o">.</span><span class="n">_call</span>

<div class="viewcode-block" id="FlattenObservation.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.FlattenObservation.html#torchrl.envs.transforms.FlattenObservation.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;first_dim=</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">first_dim</span><span class="p">)</span><span class="si">}</span><span class="s2">, last_dim=</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_dim</span><span class="p">)</span><span class="si">}</span><span class="s2">, in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, out_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="UnsqueezeTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnsqueezeTransform.html#torchrl.envs.transforms.UnsqueezeTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">UnsqueezeTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Inserts a dimension of size one at the specified position.</span>

<span class="sd">    Args:</span>
<span class="sd">        dim (int): dimension to unsqueeze. Must be negative (or allow_positive_dim</span>
<span class="sd">            must be turned on).</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        allow_positive_dim (bool, optional): if ``True``, positive dimensions are accepted.</span>
<span class="sd">            `UnsqueezeTransform`` will map these to the n^th feature dimension</span>
<span class="sd">            (ie n^th dimension after batch size of parent env) of the input tensor,</span>
<span class="sd">            independently of the tensordict batch size (ie positive dims may be</span>
<span class="sd">            dangerous in contexts where tensordict of different batch dimension</span>
<span class="sd">            are passed).</span>
<span class="sd">            Defaults to False, ie. non-negative dimensions are not permitted.</span>
<span class="sd">        in_keys (list of NestedKeys): input entries (read).</span>
<span class="sd">        out_keys (list of NestedKeys): input entries (write). Defaults to ``in_keys`` if</span>
<span class="sd">            not provided.</span>
<span class="sd">        in_keys_inv (list of NestedKeys): input entries (read) during :meth:`inv` calls.</span>
<span class="sd">        out_keys_inv (list of NestedKeys): input entries (write) during :meth:`~.inv` calls.</span>
<span class="sd">            Defaults to ``in_keys_in`` if not provided.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_dim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">allow_positive_dim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># default</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allow_positive_dim</span> <span class="o">=</span> <span class="n">allow_positive_dim</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">allow_positive_dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;dim should be smaller than 0 to accommodate for &quot;</span>
                <span class="s2">&quot;envs of different batch_sizes. Turn allow_positive_dim to accommodate &quot;</span>
                <span class="s2">&quot;for positive dim.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">unsqueeze_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">):</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">spec</span>

    <span class="c1"># To map the specs, we actually use the forward call, not the inv</span>
    <span class="n">_inv_transform_spec</span> <span class="o">=</span> <span class="n">_transform_spec</span>

<div class="viewcode-block" id="UnsqueezeTransform.transform_action_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnsqueezeTransform.html#torchrl.envs.transforms.UnsqueezeTransform.transform_action_spec">[docs]</a>    <span class="nd">@_apply_to_composite_inv</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_transform_spec</span><span class="p">(</span><span class="n">action_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="UnsqueezeTransform.transform_state_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnsqueezeTransform.html#torchrl.envs.transforms.UnsqueezeTransform.transform_state_spec">[docs]</a>    <span class="nd">@_apply_to_composite_inv</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_transform_spec</span><span class="p">(</span><span class="n">state_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="UnsqueezeTransform.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnsqueezeTransform.html#torchrl.envs.transforms.UnsqueezeTransform.transform_reward_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">reward_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_key</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;reward&quot;</span>
        <span class="k">if</span> <span class="n">reward_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">reward_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reward_spec</span></div>

<div class="viewcode-block" id="UnsqueezeTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnsqueezeTransform.html#torchrl.envs.transforms.UnsqueezeTransform.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(dim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s2">, in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, out_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; in_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="si">}</span><span class="s2">, out_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">s</span></div>


<div class="viewcode-block" id="SqueezeTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.SqueezeTransform.html#torchrl.envs.transforms.SqueezeTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">SqueezeTransform</span><span class="p">(</span><span class="n">UnsqueezeTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Removes a dimension of size one at the specified position.</span>

<span class="sd">    Args:</span>
<span class="sd">        dim (int): dimension to squeeze.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;squeeze_dim&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;squeeze_dim will be deprecated in favor of dim arg in </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
                <span class="n">dim</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;squeeze_dim&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;dim must be passed to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> constructor.&quot;</span>
                <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">dim</span><span class="p">,</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">squeeze_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">dim</span>

    <span class="n">_apply_transform</span> <span class="o">=</span> <span class="n">UnsqueezeTransform</span><span class="o">.</span><span class="n">_inv_apply_transform</span>
    <span class="n">_inv_apply_transform</span> <span class="o">=</span> <span class="n">UnsqueezeTransform</span><span class="o">.</span><span class="n">_apply_transform</span></div>


<div class="viewcode-block" id="PermuteTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.PermuteTransform.html#torchrl.envs.transforms.PermuteTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">PermuteTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Permutation transform.</span>

<span class="sd">    Permutes input tensors along the desired dimensions. The permutations</span>
<span class="sd">    must be provided along the feature dimension (not batch dimension).</span>

<span class="sd">    Args:</span>
<span class="sd">        dims (list of int): the permuted order of the dimensions. Must be a reordering</span>
<span class="sd">            of the dims ``[-(len(dims)), ..., -1]``.</span>
<span class="sd">        in_keys (list of NestedKeys): input entries (read).</span>
<span class="sd">        out_keys (list of NestedKeys): input entries (write). Defaults to ``in_keys`` if</span>
<span class="sd">            not provided.</span>
<span class="sd">        in_keys_inv (list of NestedKeys): input entries (read) during :meth:`~.inv` calls.</span>
<span class="sd">        out_keys_inv (list of NestedKeys): input entries (write) during :meth:`~.inv` calls. Defaults to ``in_keys_in`` if</span>
<span class="sd">            not provided.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;ALE/Pong-v5&quot;)</span>
<span class="sd">        &gt;&gt;&gt; base_env.rollout(2)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([2, 6]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        pixels: Tensor(shape=torch.Size([2, 210, 160, 3]), device=cpu, dtype=torch.uint8, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                pixels: Tensor(shape=torch.Size([2, 210, 160, 3]), device=cpu, dtype=torch.uint8, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, PermuteTransform((-1, -3, -2), in_keys=[&quot;pixels&quot;]))</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(2)  # channels are at the end</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([2, 6]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        pixels: Tensor(shape=torch.Size([2, 3, 210, 160]), device=cpu, dtype=torch.uint8, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                pixels: Tensor(shape=torch.Size([2, 3, 210, 160]), device=cpu, dtype=torch.uint8, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dims</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># check dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dims</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">),</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only tailing dims with negative indices are supported by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Got </span><span class="si">{</span><span class="n">dims</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_invert_permute</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_find_inv</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">_p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">_p</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">inv</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">_p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">_p</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">inv</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">_p</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">inv</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">j</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">j</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># unreachable</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">_find_inv</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">))]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
            <span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">observation</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">))),</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">permuted_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_invert_permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
            <span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">))),</span> <span class="o">*</span><span class="n">permuted_dims</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span>

<div class="viewcode-block" id="PermuteTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.PermuteTransform.html#torchrl.envs.transforms.PermuteTransform.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">observation_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edit_space</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span>
        <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="o">*</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">)],</span>
                <span class="o">*</span><span class="p">[</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="PermuteTransform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.PermuteTransform.html#torchrl.envs.transforms.PermuteTransform.transform_input_spec">[docs]</a>    <span class="nd">@_apply_to_composite_inv</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">permuted_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_invert_permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edit_space_inv</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span>
        <span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="o">*</span><span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">permuted_dims</span><span class="p">)],</span>
                <span class="o">*</span><span class="p">[</span><span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">permuted_dims</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_edit_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_edit_space_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_apply_transform</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_apply_transform</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="GrayScale"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.GrayScale.html#torchrl.envs.transforms.GrayScale">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GrayScale</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Turns a pixel observation to grayscale.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">rgb_to_grayscale</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span>

<div class="viewcode-block" id="GrayScale.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.GrayScale.html#torchrl.envs.transforms.GrayScale.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="ObservationNorm"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ObservationNorm</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Observation affine transformation layer.</span>

<span class="sd">    Normalizes an observation according to</span>

<span class="sd">    .. math::</span>
<span class="sd">        obs = obs * scale + loc</span>

<span class="sd">    Args:</span>
<span class="sd">        loc (number or tensor): location of the affine transform</span>
<span class="sd">        scale (number or tensor): scale of the affine transform</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): entries to be normalized. Defaults to [&quot;observation&quot;, &quot;pixels&quot;].</span>
<span class="sd">            All entries will be normalized with the same values: if a different behavior is desired</span>
<span class="sd">            (e.g. a different normalization for pixels and states) different :obj:`ObservationNorm`</span>
<span class="sd">            objects should be used.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): output entries. Defaults to the value of `in_keys`.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): ObservationNorm also supports inverse transforms. This will</span>
<span class="sd">            only occur if a list of keys is provided to :obj:`in_keys_inv`. If none is provided,</span>
<span class="sd">            only the forward transform will be called.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): output entries for the inverse transform.</span>
<span class="sd">            Defaults to the value of `in_keys_inv`.</span>
<span class="sd">        standard_normal (bool, optional): if ``True``, the transform will be</span>

<span class="sd">            .. math::</span>
<span class="sd">                obs = (obs-loc)/scale</span>

<span class="sd">            as it is done for standardization. Default is `False`.</span>

<span class="sd">        eps (:obj:`float`, optional): epsilon increment for the scale in the ``standard_normal`` case.</span>
<span class="sd">            Defaults to ``1e-6`` if not recoverable directly from the scale dtype.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; torch.set_default_tensor_type(torch.DoubleTensor)</span>
<span class="sd">        &gt;&gt;&gt; r = torch.randn(100, 3)*torch.randn(3) + torch.randn(3)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;obs&#39;: r}, [100])</span>
<span class="sd">        &gt;&gt;&gt; transform = ObservationNorm(</span>
<span class="sd">        ...     loc = td.get(&#39;obs&#39;).mean(0),</span>
<span class="sd">        ...     scale = td.get(&#39;obs&#39;).std(0),</span>
<span class="sd">        ...     in_keys=[&quot;obs&quot;],</span>
<span class="sd">        ...     standard_normal=True)</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(torch.isclose(td.get(&#39;obs&#39;).mean(0),</span>
<span class="sd">        ...     torch.zeros(3)).all())</span>
<span class="sd">        tensor(True)</span>
<span class="sd">        &gt;&gt;&gt; print(torch.isclose(td.get(&#39;next_obs&#39;).std(0),</span>
<span class="sd">        ...     torch.ones(3)).all())</span>
<span class="sd">        tensor(True)</span>

<span class="sd">    The normalization stats can be automatically computed:</span>
<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(env, ObservationNorm(in_keys=[&quot;observation&quot;]))</span>
<span class="sd">        &gt;&gt;&gt; env.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; env.transform.init_stats(100)</span>
<span class="sd">        &gt;&gt;&gt; print(env.transform.loc, env.transform.scale)</span>
<span class="sd">        tensor([-1.3752e+01, -6.5087e-03,  2.9294e-03], dtype=torch.float32) tensor([14.9636,  2.5608,  0.6408], dtype=torch.float32)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_ERR_INIT_MSG</span> <span class="o">=</span> <span class="s2">&quot;Cannot have an mixed initialized and uninitialized loc and scale&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">standard_normal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Not passing in_keys to ObservationNorm is a deprecated behavior.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">standard_normal</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">standard_normal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">standard_normal</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;standard_normal&quot;</span><span class="p">,</span> <span class="n">standard_normal</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">eps</span>
            <span class="k">if</span> <span class="n">eps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">scale</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span>
            <span class="k">else</span> <span class="mf">1e-6</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">loc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">loc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ERR_INIT_MSG</span><span class="p">)</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">())</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># check that loc is None too</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ERR_INIT_MSG</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">()</span>

        <span class="c1"># self.observation_spec_key = observation_spec_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">)</span>

<div class="viewcode-block" id="ObservationNorm.init_stats"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm.init_stats">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">init_stats</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">reduce_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">cat_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_dims</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the loc and scale stats of the parent environment.</span>

<span class="sd">        Normalization constant should ideally make the observation statistics approach</span>
<span class="sd">        those of a standard Gaussian distribution. This method computes a location</span>
<span class="sd">        and scale tensor that will empirically compute the mean and standard</span>
<span class="sd">        deviation of a Gaussian distribution fitted on data generated randomly with</span>
<span class="sd">        the parent environment for a given number of steps.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_iter (int): number of random iterations to run in the environment.</span>
<span class="sd">            reduce_dim (int or tuple of int, optional): dimension to compute the mean and std over.</span>
<span class="sd">                Defaults to 0.</span>
<span class="sd">            cat_dim (int, optional): dimension along which the batches collected will be concatenated.</span>
<span class="sd">                It must be part equal to reduce_dim (if integer) or part of the reduce_dim tuple.</span>
<span class="sd">                Defaults to the same value as reduce_dim.</span>
<span class="sd">            key (NestedKey, optional): if provided, the summary statistics will be</span>
<span class="sd">                retrieved from that key in the resulting tensordicts.</span>
<span class="sd">                Otherwise, the first key in :obj:`ObservationNorm.in_keys` will be used.</span>
<span class="sd">            keep_dims (tuple of int, optional): the dimensions to keep in the loc and scale.</span>
<span class="sd">                For instance, one may want the location and scale to have shape [C, 1, 1]</span>
<span class="sd">                when normalizing a 3D tensor over the last two dimensions, but not the</span>
<span class="sd">                third. Defaults to None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cat_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cat_dim</span> <span class="o">=</span> <span class="n">reduce_dim</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;cat_dim must be specified if reduce_dim is not an integer.&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">reduce_dim</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_dim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">reduce_dim</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">reduce_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_dim</span> <span class="o">!=</span> <span class="n">reduce_dim</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cat_dim must be part of or equal to reduce_dim.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Loc/Scale are already initialized: (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Transform has multiple in_keys but no specific key was passed as an argument&quot;</span>
            <span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">key</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">raise_initialization_exception</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">ObservationNorm</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">module</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;ObservationNorms need to be initialized in the right order.&quot;</span>
                    <span class="s2">&quot;Trying to initialize an ObservationNorm &quot;</span>
                    <span class="s2">&quot;while a parent ObservationNorm transform is still uninitialized&quot;</span>
                <span class="p">)</span>

        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot initialize the transform if parent env is not defined.&quot;</span>
            <span class="p">)</span>
        <span class="n">parent</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">raise_initialization_exception</span><span class="p">)</span>

        <span class="n">collected_frames</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="n">collected_frames</span> <span class="o">&lt;</span> <span class="n">num_iter</span><span class="p">:</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="n">num_iter</span><span class="p">)</span>
            <span class="n">collected_frames</span> <span class="o">+=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cat_dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reduce_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">reduce_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">reduce_dim</span><span class="p">]</span>
        <span class="c1"># make all reduce_dim and keep_dims negative</span>
        <span class="n">reduce_dim</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">reduce_dim</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keep_dims</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">keep_dims</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">k</span> <span class="ow">in</span> <span class="n">reduce_dim</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keep_dims</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;keep_dim elements must be part of reduce_dim list.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">keep_dims</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">reduce_dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">reduce_dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reduce_dim</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">r</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">keep_dims</span><span class="p">:</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">scale</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="o">-</span><span class="n">loc</span> <span class="o">*</span> <span class="n">scale</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non-finite values found in loc&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non-finite values found in scale&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">materialize</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">loc</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">materialize</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">scale</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">scale</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">scale</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Loc/Scale have not been initialized. Either pass in values in the constructor &quot;</span>
                <span class="s2">&quot;or call the init_stats method&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">:</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">obs</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
            <span class="k">return</span> <span class="n">obs</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">loc</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Loc/Scale have not been initialized. Either pass in values in the constructor &quot;</span>
                <span class="s2">&quot;or call the init_stats method&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">:</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">state</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
            <span class="k">return</span> <span class="n">state</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">loc</span>

<div class="viewcode-block" id="ObservationNorm.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="c1"># @_apply_to_composite_inv</span>
    <span class="c1"># def transform_input_spec(self, input_spec: TensorSpec) -&gt; TensorSpec:</span>
    <span class="c1">#     space = input_spec.space</span>
    <span class="c1">#     if isinstance(space, ContinuousBox):</span>
    <span class="c1">#         space.low = self._apply_transform(space.low)</span>
    <span class="c1">#         space.high = self._apply_transform(space.high)</span>
    <span class="c1">#     return input_spec</span>

<div class="viewcode-block" id="ObservationNorm.transform_action_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm.transform_action_spec">[docs]</a>    <span class="nd">@_apply_to_composite_inv</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action_spec</span></div>

<div class="viewcode-block" id="ObservationNorm.transform_state_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm.transform_state_spec">[docs]</a>    <span class="nd">@_apply_to_composite_inv</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">state_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;loc=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, scale&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="CatFrames"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CatFrames</span><span class="p">(</span><span class="n">ObservationTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Concatenates successive observation frames into a single tensor.</span>

<span class="sd">    This transform is useful for creating a sense of movement or velocity in the observed features.</span>
<span class="sd">    It can also be used with models that require access to past observations such as transformers and the like.</span>
<span class="sd">    It was first proposed in &quot;Playing Atari with Deep Reinforcement Learning&quot; (https://arxiv.org/pdf/1312.5602.pdf).</span>

<span class="sd">    When used within a transformed environment,</span>
<span class="sd">    :class:`CatFrames` is a stateful class, and it can be reset to its native state by</span>
<span class="sd">    calling the :meth:`~.reset` method. This method accepts tensordicts with a</span>
<span class="sd">    ``&quot;_reset&quot;`` entry that indicates which buffer to reset.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (int): number of observation to concatenate.</span>
<span class="sd">        dim (int): dimension along which concatenate the</span>
<span class="sd">            observations. Should be negative, to ensure that it is compatible</span>
<span class="sd">            with environments of different batch_size.</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): keys pointing to the frames that have</span>
<span class="sd">            to be concatenated. Defaults to [&quot;pixels&quot;].</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): keys pointing to where the output</span>
<span class="sd">            has to be written. Defaults to the value of `in_keys`.</span>
<span class="sd">        padding (str, optional): the padding method. One of ``&quot;same&quot;`` or ``&quot;constant&quot;``.</span>
<span class="sd">            Defaults to ``&quot;same&quot;``, ie. the first value is used for padding.</span>
<span class="sd">        padding_value (:obj:`float`, optional): the value to use for padding if ``padding=&quot;constant&quot;``.</span>
<span class="sd">            Defaults to 0.</span>
<span class="sd">        as_inverse (bool, optional): if ``True``, the transform is applied as an inverse transform. Defaults to ``False``.</span>
<span class="sd">        reset_key (NestedKey, optional): the reset key to be used as partial</span>
<span class="sd">            reset indicator. Must be unique. If not provided, defaults to the</span>
<span class="sd">            only reset key of the parent environment (if it has only one)</span>
<span class="sd">            and raises an exception otherwise.</span>
<span class="sd">        done_key (NestedKey, optional): the done key to be used as partial</span>
<span class="sd">            done indicator. Must be unique. If not provided, defaults to ``&quot;done&quot;``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(GymEnv(&#39;Pendulum-v1&#39;),</span>
<span class="sd">        ...     Compose(</span>
<span class="sd">        ...         UnsqueezeTransform(-1, in_keys=[&quot;observation&quot;]),</span>
<span class="sd">        ...         CatFrames(N=4, dim=-1, in_keys=[&quot;observation&quot;]),</span>
<span class="sd">        ...     )</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; print(env.rollout(3))</span>

<span class="sd">    The :class:`CatFrames` transform can also be used offline to reproduce the</span>
<span class="sd">    effect of the online frame concatenation at a different scale (or for the</span>
<span class="sd">    purpose of limiting the memory consumption). The following example</span>
<span class="sd">    gives the complete picture, together with the usage of a :class:`torchrl.data.ReplayBuffer`:</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.utils import RandomPolicy        &gt;&gt;&gt; from torchrl.envs import UnsqueezeTransform, CatFrames</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import SyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; # Create a transformed environment with CatFrames: notice the usage of UnsqueezeTransform to create an extra dimension</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     GymEnv(&quot;CartPole-v1&quot;, from_pixels=True),</span>
<span class="sd">        ...     Compose(</span>
<span class="sd">        ...         ToTensorImage(in_keys=[&quot;pixels&quot;], out_keys=[&quot;pixels_trsf&quot;]),</span>
<span class="sd">        ...         Resize(in_keys=[&quot;pixels_trsf&quot;], w=64, h=64),</span>
<span class="sd">        ...         GrayScale(in_keys=[&quot;pixels_trsf&quot;]),</span>
<span class="sd">        ...         UnsqueezeTransform(-4, in_keys=[&quot;pixels_trsf&quot;]),</span>
<span class="sd">        ...         CatFrames(dim=-4, N=4, in_keys=[&quot;pixels_trsf&quot;]),</span>
<span class="sd">        ...     )</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # we design a collector</span>
<span class="sd">        &gt;&gt;&gt; collector = SyncDataCollector(</span>
<span class="sd">        ...     env,</span>
<span class="sd">        ...     RandomPolicy(env.action_spec),</span>
<span class="sd">        ...     frames_per_batch=10,</span>
<span class="sd">        ...     total_frames=1000,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; for data in collector:</span>
<span class="sd">        ...     print(data)</span>
<span class="sd">        ...     break</span>
<span class="sd">        &gt;&gt;&gt; # now let&#39;s create a transform for the replay buffer. We don&#39;t need to unsqueeze the data here.</span>
<span class="sd">        &gt;&gt;&gt; # however, we need to point to both the pixel entry at the root and at the next levels:</span>
<span class="sd">        &gt;&gt;&gt; t = Compose(</span>
<span class="sd">        ...         ToTensorImage(in_keys=[&quot;pixels&quot;, (&quot;next&quot;, &quot;pixels&quot;)], out_keys=[&quot;pixels_trsf&quot;, (&quot;next&quot;, &quot;pixels_trsf&quot;)]),</span>
<span class="sd">        ...         Resize(in_keys=[&quot;pixels_trsf&quot;, (&quot;next&quot;, &quot;pixels_trsf&quot;)], w=64, h=64),</span>
<span class="sd">        ...         GrayScale(in_keys=[&quot;pixels_trsf&quot;, (&quot;next&quot;, &quot;pixels_trsf&quot;)]),</span>
<span class="sd">        ...         CatFrames(dim=-4, N=4, in_keys=[&quot;pixels_trsf&quot;, (&quot;next&quot;, &quot;pixels_trsf&quot;)]),</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage</span>
<span class="sd">        &gt;&gt;&gt; rb = TensorDictReplayBuffer(storage=LazyMemmapStorage(1000), transform=t, batch_size=16)</span>
<span class="sd">        &gt;&gt;&gt; data_exclude = data.exclude(&quot;pixels_trsf&quot;, (&quot;next&quot;, &quot;pixels_trsf&quot;))</span>
<span class="sd">        &gt;&gt;&gt; rb.add(data_exclude)</span>
<span class="sd">        &gt;&gt;&gt; s = rb.sample(1) # the buffer has only one element</span>
<span class="sd">        &gt;&gt;&gt; # let&#39;s check that our sample is the same as the batch collected during inference</span>
<span class="sd">        &gt;&gt;&gt; assert (data.exclude(&quot;collector&quot;)==s.squeeze(0).exclude(&quot;index&quot;, &quot;collector&quot;)).all()</span>

<span class="sd">    .. note:: :class:`~CatFrames` currently only supports ``&quot;done&quot;``</span>
<span class="sd">        signal at the root. Nested ``done``,</span>
<span class="sd">        such as those found in MARL settings, are currently not supported.</span>
<span class="sd">        If this feature is needed, please raise an issue on TorchRL repo.</span>

<span class="sd">    .. note:: Storing stacks of frames in the replay buffer can significantly increase memory consumption (by N times).</span>
<span class="sd">        To mitigate this, you can store trajectories directly in the replay buffer and apply :class:`CatFrames` at sampling time.</span>
<span class="sd">        This approach involves sampling slices of the stored trajectories and then applying the frame stacking transform.</span>
<span class="sd">        For convenience, :class:`CatFrames` provides a :meth:`~.make_rb_transform_and_sampler` method that creates:</span>

<span class="sd">        - A modified version of the transform suitable for use in replay buffers</span>
<span class="sd">        - A corresponding :class:`SliceSampler` to use with the buffer</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">inplace</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_CAT_DIM_ERR</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;dim must be &lt; 0 to accommodate for tensordict of &quot;</span>
        <span class="s2">&quot;different batch-sizes (since negative dims are batch invariant).&quot;</span>
    <span class="p">)</span>
    <span class="n">ACCEPTED_PADDING</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="s2">&quot;zeros&quot;</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
        <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">as_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">reset_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">done_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">IMAGE_KEYS</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_CAT_DIM_ERR</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ACCEPTED_PADDING</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;padding must be one of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ACCEPTED_PADDING</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;zeros&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Padding option &#39;zeros&#39; will is deprecated&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span> <span class="o">=</span> <span class="n">padding_value</span>
        <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">buffer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_cat_buffers_</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="n">buffer_name</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">(</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="c1"># keeps track of calls to _reset since it&#39;s only _call that will populate the buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">as_inverse</span> <span class="o">=</span> <span class="n">as_inverse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span> <span class="o">=</span> <span class="n">reset_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done_key</span> <span class="o">=</span> <span class="n">done_key</span>

<div class="viewcode-block" id="CatFrames.make_rb_transform_and_sampler"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames.make_rb_transform_and_sampler">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">make_rb_transform_and_sampler</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">sampler_kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Transform</span><span class="p">,</span> <span class="n">torchrl</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">replay_buffers</span><span class="o">.</span><span class="n">SliceSampler</span><span class="p">]:</span>  <span class="c1"># noqa: F821</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates a transform and sampler to be used with a replay buffer when storing frame-stacked data.</span>

<span class="sd">        This method helps reduce redundancy in stored data by avoiding the need to</span>
<span class="sd">        store the entire stack of frames in the buffer. Instead, it creates a</span>
<span class="sd">        transform that stacks frames on-the-fly during sampling, and a sampler that</span>
<span class="sd">        ensures the correct sequence length is maintained.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (int): The batch size to use for the sampler.</span>
<span class="sd">            **sampler_kwargs: Additional keyword arguments to pass to the</span>
<span class="sd">                :class:`~torchrl.data.replay_buffers.SliceSampler` constructor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple containing:</span>

<span class="sd">                - transform (Transform): A transform that stacks frames on-the-fly during sampling.</span>
<span class="sd">                - sampler (SliceSampler): A sampler that ensures the correct sequence length is maintained.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; env = TransformedEnv(...)</span>
<span class="sd">            &gt;&gt;&gt; catframes = CatFrames(N=4, ...)</span>
<span class="sd">            &gt;&gt;&gt; transform, sampler = catframes.make_rb_transform_and_sampler(batch_size=32)</span>
<span class="sd">            &gt;&gt;&gt; rb = ReplayBuffer(..., sampler=sampler, transform=transform)</span>

<span class="sd">        .. note:: When working with images, it&#39;s recommended to use distinct ``in_keys`` and ``out_keys`` in the preceding</span>
<span class="sd">            :class:`~torchrl.envs.ToTensorImage` transform. This ensures that the tensors stored in the buffer are separate</span>
<span class="sd">            from their processed counterparts, which we don&#39;t want to store.</span>
<span class="sd">            For non-image data, consider inserting a :class:`~torchrl.envs.RenameTransform` before :class:`CatFrames` to create</span>
<span class="sd">            a copy of the data that will be stored in the buffer.</span>

<span class="sd">        .. note:: When adding the transform to the replay buffer, one should pay attention to also pass the transforms</span>
<span class="sd">            that precede CatFrames, such as :class:`~torchrl.envs.ToTensorImage` or :class:`~torchrl.envs.UnsqueezeTransform`</span>
<span class="sd">            in such a way that the :class:`~torchrl.envs.CatFrames` transforms sees data formatted as it was during data</span>
<span class="sd">            collection.</span>

<span class="sd">        .. note:: For a more complete example, refer to torchrl&#39;s github repo `examples` folder:</span>
<span class="sd">            https://github.com/pytorch/rl/tree/main/examples/replay-buffers/catframes-in-buffer.py</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.replay_buffers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SliceSampler</span>

        <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys</span> <span class="o">+</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">]</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys</span> <span class="o">+</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">]</span>
        <span class="n">catframes</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span>
            <span class="n">N</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
            <span class="n">as_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">reset_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span><span class="p">,</span>
            <span class="n">done_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">done_key</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">sampler</span> <span class="o">=</span> <span class="n">SliceSampler</span><span class="p">(</span><span class="n">slice_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="o">**</span><span class="n">sampler_kwargs</span><span class="p">)</span>
        <span class="n">sampler</span><span class="o">.</span><span class="n">_batch_size_multiplier</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">td</span><span class="p">:</span> <span class="n">td</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">),</span>
            <span class="n">catframes</span><span class="p">,</span>
            <span class="k">lambda</span> <span class="n">td</span><span class="p">:</span> <span class="n">td</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="c1"># We only store &quot;pixels&quot; to the replay buffer to save memory</span>
            <span class="n">ExcludeTransform</span><span class="p">(</span><span class="o">*</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">transform</span><span class="p">,</span> <span class="n">sampler</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">done_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">done_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_done_key&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">done_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">done_key</span> <span class="o">=</span> <span class="s2">&quot;done&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_done_key</span> <span class="o">=</span> <span class="n">done_key</span>
        <span class="k">return</span> <span class="n">done_key</span>

    <span class="nd">@done_key</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">done_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_done_key</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">reset_key</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_reset_key&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reset_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">reset_key</span>
        <span class="n">reset_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reset_keys</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Got more than one reset key in env </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="si">}</span><span class="s2">, cannot infer which one to use. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Consider providing the reset key in the </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> constructor.&quot;</span>
            <span class="p">)</span>
        <span class="n">reset_key</span> <span class="o">=</span> <span class="n">reset_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">reset_key</span>

    <span class="nd">@reset_key</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets _buffers.&quot;&quot;&quot;</span>
        <span class="n">_reset</span> <span class="o">=</span> <span class="n">_get_reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">as_inverse</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;CatFrames as inverse is not supported as a transform for environments, only for replay buffers.&quot;</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">,</span> <span class="n">_reset</span><span class="o">=</span><span class="n">_reset</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_missing_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span>
        <span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span><span class="o">.</span><span class="n">materialize</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
            <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">buffer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">as_inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unfolding</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">_reset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the episode tensordict with max pooled keys.&quot;&quot;&quot;</span>
        <span class="n">_just_reset</span> <span class="o">=</span> <span class="n">_reset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="c1"># Lazy init of buffers</span>
            <span class="n">buffer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_cat_buffers_</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">buffer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">):</span>
                <span class="n">buffer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_missing_buffer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
            <span class="c1"># shift obs 1 position to the right</span>
            <span class="k">if</span> <span class="n">_just_reset</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">_reset</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="n">_all</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">data_reset</span> <span class="o">=</span> <span class="n">data</span>
                    <span class="n">buffer_reset</span> <span class="o">=</span> <span class="n">buffer</span>
                    <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_all</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">data_reset</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span>
                    <span class="n">buffer_reset</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span>
                    <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="n">_reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">buffer_reset</span><span class="o">.</span><span class="n">shape</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">_all</span><span class="p">:</span>
                    <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">_all</span><span class="p">:</span>
                        <span class="n">buffer</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data_reset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">buffer</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_reset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;constant&quot;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">_all</span><span class="p">:</span>
                        <span class="n">buffer</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">buffer</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># make linter happy. An exception has already been raised</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">n</span> <span class="o">=</span> <span class="n">buffer_reset</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_CAT_DIM_ERR</span><span class="p">)</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="kc">None</span><span class="p">)])</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">_all</span><span class="p">:</span>
                    <span class="n">buffer_reset</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span>
                <span class="n">buffer_reset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_reset</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">_all</span><span class="p">:</span>
                    <span class="n">buffer</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer_reset</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">buffer</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=-</span><span class="n">d</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>
                <span class="c1"># add new obs</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">n</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_CAT_DIM_ERR</span><span class="p">)</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="kc">None</span><span class="p">)])</span>
                <span class="n">buffer</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="c1"># add to tensordict</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">buffer</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="CatFrames.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
            <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span>
            <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="CatFrames.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">as_inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unfolding</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_same_padding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">done_mask</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">num_repeats_per_sample</span> <span class="o">=</span> <span class="n">done_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_repeats_per_sample</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">extra_dims</span> <span class="o">=</span> <span class="n">num_repeats_per_sample</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span>
            <span class="n">num_repeats_per_sample</span> <span class="o">=</span> <span class="n">num_repeats_per_sample</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">extra_dims</span><span class="p">)</span>
            <span class="n">res_flat_series</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">extra_dims</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">extra_dims</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">res_flat_series</span> <span class="o">=</span> <span class="n">res</span>

        <span class="k">if</span> <span class="n">d</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&gt;</span> <span class="n">extra_dims</span><span class="p">:</span>
            <span class="n">res_flat_series_flat_batch</span> <span class="o">=</span> <span class="n">res_flat_series</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res_flat_series_flat_batch</span> <span class="o">=</span> <span class="n">res_flat_series</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">sample_idx</span><span class="p">,</span> <span class="n">num_repeats</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_repeats_per_sample</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">num_repeats</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">res_slice</span> <span class="o">=</span> <span class="n">res_flat_series_flat_batch</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span>
                <span class="n">res_slice</span><span class="p">[:,</span> <span class="p">:</span><span class="n">num_repeats</span><span class="p">]</span> <span class="o">=</span> <span class="n">res_slice</span><span class="p">[:,</span> <span class="n">num_repeats</span> <span class="p">:</span> <span class="n">num_repeats</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@set_lazy_legacy</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">unfolding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># it is assumed that the last dimension of the tensordict is the time dimension</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;CatFrames cannot process unbatched tensordict instances. &quot;</span>
                <span class="s2">&quot;Make sure your input has more than one dimension and &quot;</span>
                <span class="s2">&quot;the time dimension is marked as &#39;time&#39;, e.g., &quot;</span>
                <span class="s2">&quot;`tensordict.refine_names(None, &#39;time&#39;, None)`.&quot;</span>
            <span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">names</span><span class="p">):</span>  <span class="c1"># noqa: B007</span>
            <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;time&quot;</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The last dimension of the tensordict should be marked as &#39;time&#39;. &quot;</span>
                <span class="s2">&quot;CatFrames will unfold the data along the time dimension assuming that &quot;</span>
                <span class="s2">&quot;the time dimension is the last dimension of the input tensordict. &quot;</span>
                <span class="s2">&quot;Define a &#39;time&#39; dimension name (e.g., `tensordict.refine_names(..., &#39;time&#39;)`) to skip this warning. &quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">tensordict_orig</span> <span class="o">=</span> <span class="n">tensordict</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="c1"># first sort the in_keys with strings and non-strings</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">keys</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">unfold_done</span><span class="p">(</span><span class="n">done</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">done</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),)]),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">done</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">),)]),</span>
                    <span class="n">done</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),)],</span>
                <span class="p">],</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">reset_unfold</span> <span class="o">=</span> <span class="n">reset</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">reset_unfold_slice</span> <span class="o">=</span> <span class="n">reset_unfold</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">reset_unfold_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reset_unfold_slice</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">reset_unfold</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">reset_unfold_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r</span> <span class="o">|</span> <span class="n">reset_unfold_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="c1"># reset_unfold_slice = reset_unfold_list[-1]</span>
            <span class="n">reset_unfold</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">reset_unfold_list</span><span class="p">))[</span><span class="mi">1</span><span class="p">:],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),)]</span>
            <span class="n">reset</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">reset_unfold</span><span class="p">,</span> <span class="n">reset</span>

        <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_key</span><span class="p">))</span>
        <span class="n">done_mask</span><span class="p">,</span> <span class="n">reset</span> <span class="o">=</span> <span class="n">unfold_done</span><span class="p">(</span><span class="n">done</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="c1"># check if we have an obs in &quot;next&quot; that has already been processed.</span>
            <span class="c1"># If so, we must add an offset</span>
            <span class="n">data_orig</span> <span class="o">=</span> <span class="n">data</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="n">n_feat</span> <span class="o">=</span> <span class="n">data_orig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span>
            <span class="n">first_val</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="n">in_key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;next&quot;</span><span class="p">:</span>
                <span class="c1"># let&#39;s get the out_key we have already processed</span>
                <span class="n">prev_out_key</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">))</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="n">in_key</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="kc">None</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">prev_out_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">prev_val</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">prev_out_key</span><span class="p">)</span>
                    <span class="c1"># n_feat = prev_val.shape[data.ndim + self.dim] // self.N</span>
                    <span class="n">first_val</span> <span class="o">=</span> <span class="n">prev_val</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span>
                        <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">)</span>
                    <span class="p">)</span>

            <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">data0</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">idx</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span>
            <span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">data0</span> <span class="o">+</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Place -1 dim at self.dim place before squashing</span>
            <span class="n">done_mask_expand</span> <span class="o">=</span> <span class="n">done_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="o">*</span><span class="n">done_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span><span class="p">],</span>
                <span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span>
                <span class="n">done_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">done_mask_expand</span> <span class="o">=</span> <span class="n">expand_as_right</span><span class="p">(</span><span class="n">done_mask_expand</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">done_mask_expand</span> <span class="o">=</span> <span class="n">done_mask_expand</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">done_mask_expand</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">done_mask_expand</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">done_mask_expand</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">!=</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">done_mask_expand</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_same_padding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">done_mask</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">first_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Aggregate reset along last dim</span>
                <span class="n">reset_any</span> <span class="o">=</span> <span class="n">reset</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                <span class="n">rexp</span> <span class="o">=</span> <span class="n">expand_right</span><span class="p">(</span>
                    <span class="n">reset_any</span><span class="p">,</span> <span class="p">(</span><span class="o">*</span><span class="n">reset_any</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="p">:])</span>
                <span class="p">)</span>
                <span class="n">rexp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>
                            <span class="n">data0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
                                <span class="nb">len</span><span class="p">(</span><span class="n">data0</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>
                            <span class="p">),</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">rexp</span><span class="p">,</span>
                    <span class="p">],</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">rexp</span> <span class="o">=</span> <span class="n">rexp</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">rexp_orig</span> <span class="o">=</span> <span class="n">rexp</span>
                <span class="n">rexp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">rexp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">rexp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:])],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
                    <span class="n">rexp_orig</span> <span class="o">=</span> <span class="n">rexp_orig</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
                    <span class="n">rexp</span> <span class="o">=</span> <span class="n">rexp</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
                <span class="n">rexp_orig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">rexp_orig</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">rexp_orig</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]],</span> <span class="o">-</span><span class="mi">1</span>
                <span class="p">)</span>
                <span class="n">rexp</span> <span class="o">=</span> <span class="n">rexp</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                    <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">rexp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">rexp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rexp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">rexp_orig</span> <span class="o">=</span> <span class="n">rexp_orig</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                    <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">rexp_orig</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">rexp_orig</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rexp_orig</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">data</span><span class="p">[</span><span class="n">rexp</span><span class="p">]</span> <span class="o">=</span> <span class="n">first_val</span><span class="p">[</span><span class="n">rexp_orig</span><span class="p">]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tensordict_orig</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">tensordict</span><span class="p">:</span>
            <span class="n">tensordict_orig</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_orig</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(N=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="si">}</span><span class="s2">, dim&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s2">, keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="RewardScaling"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardScaling.html#torchrl.envs.transforms.RewardScaling">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RewardScaling</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Affine transform of the reward.</span>

<span class="sd">     The reward is transformed according to:</span>

<span class="sd">    .. math::</span>
<span class="sd">        reward = reward * scale + loc</span>

<span class="sd">    Args:</span>
<span class="sd">        loc (number or torch.Tensor): location of the affine transform</span>
<span class="sd">        scale (number or torch.Tensor): scale of the affine transform</span>
<span class="sd">        standard_normal (bool, optional): if ``True``, the transform will be</span>

<span class="sd">            .. math::</span>
<span class="sd">                reward = (reward-loc)/scale</span>

<span class="sd">            as it is done for standardization. Default is `False`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">standard_normal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">standard_normal</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">standard_normal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">standard_normal</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;standard_normal&quot;</span><span class="p">,</span> <span class="n">standard_normal</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">loc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">:</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="p">(</span><span class="n">reward</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
            <span class="k">return</span> <span class="n">reward</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">loc</span>
            <span class="k">return</span> <span class="n">reward</span>

<div class="viewcode-block" id="RewardScaling.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardScaling.html#torchrl.envs.transforms.RewardScaling.transform_reward_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">,</span> <span class="n">Unbounded</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">reward_spec</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.transform_reward_spec not &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;implemented for tensor spec of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;loc=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, scale=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="FiniteTensorDictCheck"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.html#torchrl.envs.transforms.FiniteTensorDictCheck">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">FiniteTensorDictCheck</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This transform will check that all the items of the tensordict are finite, and raise an exception if they are not.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">next_tensordict</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">check_finite</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span></div>


<div class="viewcode-block" id="DTypeCastTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DTypeCastTransform.html#torchrl.envs.transforms.DTypeCastTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DTypeCastTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Casts one dtype to another for selected keys.</span>

<span class="sd">    Depending on whether the ``in_keys`` or ``in_keys_inv`` are provided</span>
<span class="sd">    during construction, the class behavior will change:</span>

<span class="sd">      * If the keys are provided, those entries and those entries only will be</span>
<span class="sd">        transformed from ``dtype_in`` to ``dtype_out`` entries;</span>
<span class="sd">      * If the keys are not provided and the object is within an environment</span>
<span class="sd">        register of transforms, the input and output specs that have a dtype</span>
<span class="sd">        set to ``dtype_in`` will be used as in_keys_inv / in_keys respectively.</span>
<span class="sd">      * If the keys are not provided and the object is used without an</span>
<span class="sd">        environment, the ``forward`` / ``inverse`` pass will scan through the</span>
<span class="sd">        input tensordict for all ``dtype_in`` values and map them to a ``dtype_out``</span>
<span class="sd">        tensor. For large data structures, this can impact performance as this</span>
<span class="sd">        scanning doesn&#39;t come for free. The keys to be</span>
<span class="sd">        transformed will not be cached.</span>
<span class="sd">        Note that, in this case, the out_keys (resp.</span>
<span class="sd">        out_keys_inv) cannot be passed as the order on which the keys are processed</span>
<span class="sd">        cannot be anticipated precisely.</span>

<span class="sd">    Args:</span>
<span class="sd">        dtype_in (torch.dtype): the input dtype (from the env).</span>
<span class="sd">        dtype_out (torch.dtype): the output dtype (for model training).</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): list of ``dtype_in`` keys to be converted to</span>
<span class="sd">            ``dtype_out`` before being exposed to external objects and functions.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): list of destination keys.</span>
<span class="sd">            Defaults to ``in_keys`` if not provided.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): list of ``dtype_out`` keys to be converted to</span>
<span class="sd">            ``dtype_in`` before being passed to the contained base_env or storage.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): list of destination keys for inverse</span>
<span class="sd">            transform.</span>
<span class="sd">            Defaults to ``in_keys_inv`` if not provided.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&#39;obs&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ...     &#39;not_transformed&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ... }, [])</span>
<span class="sd">        &gt;&gt;&gt; transform = DTypeCastTransform(torch.double, torch.float, in_keys=[&quot;obs&quot;])</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;obs&quot;).dtype)</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;not_transformed&quot;).dtype)</span>
<span class="sd">        torch.float64</span>

<span class="sd">    In &quot;automatic&quot; mode, all float64 entries are transformed:</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&#39;obs&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ...     &#39;not_transformed&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ... }, [])</span>
<span class="sd">        &gt;&gt;&gt; transform = DTypeCastTransform(torch.double, torch.float)</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;obs&quot;).dtype)</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;not_transformed&quot;).dtype)</span>
<span class="sd">        torch.float32</span>

<span class="sd">    The same behavior is the rule when environments are constructed without</span>
<span class="sd">    specifying the transform keys:</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; class MyEnv(EnvBase):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.observation_spec = Composite(obs=Unbounded((), dtype=torch.float64))</span>
<span class="sd">        ...         self.action_spec = Unbounded((), dtype=torch.float64)</span>
<span class="sd">        ...         self.reward_spec = Unbounded((1,), dtype=torch.float64)</span>
<span class="sd">        ...         self.done_spec = Unbounded((1,), dtype=torch.bool)</span>
<span class="sd">        ...     def _reset(self, data=None):</span>
<span class="sd">        ...         return TensorDict({&quot;done&quot;: torch.zeros((1,), dtype=torch.bool), **self.observation_spec.rand()}, [])</span>
<span class="sd">        ...     def _step(self, data):</span>
<span class="sd">        ...         assert data[&quot;action&quot;].dtype == torch.float64</span>
<span class="sd">        ...         reward = self.reward_spec.rand()</span>
<span class="sd">        ...         done = torch.zeros((1,), dtype=torch.bool)</span>
<span class="sd">        ...         obs = self.observation_spec.rand()</span>
<span class="sd">        ...         assert reward.dtype == torch.float64</span>
<span class="sd">        ...         assert obs[&quot;obs&quot;].dtype == torch.float64</span>
<span class="sd">        ...         return obs.empty().set(&quot;next&quot;, obs.update({&quot;reward&quot;: reward, &quot;done&quot;: done}))</span>
<span class="sd">        ...     def _set_seed(self, seed) -&gt; None:</span>
<span class="sd">        ...         pass</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(MyEnv(), DTypeCastTransform(torch.double, torch.float))</span>
<span class="sd">        &gt;&gt;&gt; assert env.action_spec.dtype == torch.float32</span>
<span class="sd">        &gt;&gt;&gt; assert env.observation_spec[&quot;obs&quot;].dtype == torch.float32</span>
<span class="sd">        &gt;&gt;&gt; assert env.reward_spec.dtype == torch.float32, env.reward_spec.dtype</span>
<span class="sd">        &gt;&gt;&gt; print(env.rollout(2))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        obs: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; assert env.transform.in_keys == [&quot;obs&quot;, &quot;reward&quot;]</span>
<span class="sd">        &gt;&gt;&gt; assert env.transform.in_keys_inv == [&quot;action&quot;]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dtype_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">dtype_out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span> <span class="o">=</span> <span class="n">dtype_in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype_out</span> <span class="o">=</span> <span class="n">dtype_out</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_in_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># in_keys=None means all entries of dtype_in will be mapped to dtype_out</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                    <span class="n">in_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">full_reward_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                    <span class="n">in_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">in_keys</span>

    <span class="nd">@in_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out_keys</span>

    <span class="nd">@out_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_in_keys_inv&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># in_keys_inv=None means all entries of dtype_out will be mapped to dtype_in</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">full_action_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                    <span class="n">in_keys_inv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">full_state_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                    <span class="n">in_keys_inv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys_inv</span> <span class="o">=</span> <span class="n">in_keys_inv</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys_inv&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">in_keys_inv</span>

    <span class="nd">@in_keys_inv</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys_inv</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys_inv&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out_keys_inv</span>

    <span class="nd">@out_keys_inv</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys_inv</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="DTypeCastTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DTypeCastTransform.html#torchrl.envs.transforms.DTypeCastTransform.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;in_keys&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;out_keys&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reads the input tensordict, and for the selected keys, applies the transform.&quot;&quot;&quot;</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;in_keys wasn&#39;t provided and couldn&#39;t be retrieved. However, &quot;</span>
                    <span class="s2">&quot;out_keys was passed to the constructor. Since the order of the &quot;</span>
                    <span class="s2">&quot;entries mapped from dtype_in to dtype_out cannot be guaranteed, &quot;</span>
                    <span class="s2">&quot;this functionality is not covered. Consider passing the in_keys &quot;</span>
                    <span class="s2">&quot;or not passing any out_keys.&quot;</span>
                <span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                    <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

            <span class="n">tensordict</span><span class="o">.</span><span class="n">_fast_apply</span><span class="p">(</span>
                <span class="n">func</span><span class="p">,</span> <span class="n">named</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nested_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># we made sure that if in_keys is not None, out_keys is not None either</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">):</span>
                <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">))</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span>
        <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;in_keys_inv wasn&#39;t provided and couldn&#39;t be retrieved. However, &quot;</span>
                    <span class="s2">&quot;out_keys_inv was passed to the constructor. Since the order of the &quot;</span>
                    <span class="s2">&quot;entries mapped from dtype_in to dtype_out cannot be guaranteed, &quot;</span>
                    <span class="s2">&quot;this functionality is not covered. Consider passing the in_keys_inv &quot;</span>
                    <span class="s2">&quot;or not passing any out_keys_inv.&quot;</span>
                <span class="p">)</span>
            <span class="k">for</span> <span class="n">in_key_inv</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_out</span><span class="p">:</span>
                    <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_apply_transform</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key_inv</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_out</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">spec</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_out</span>
            <span class="n">space</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">space</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">ContinuousBox</span><span class="p">):</span>
                <span class="n">space</span><span class="o">.</span><span class="n">low</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_out</span><span class="p">)</span>
                <span class="n">space</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec</span>

<div class="viewcode-block" id="DTypeCastTransform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DTypeCastTransform.html#torchrl.envs.transforms.DTypeCastTransform.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">full_action_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
        <span class="n">full_state_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
        <span class="c1"># if this method is called, then it must have a parent and in_keys_inv will be defined</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Calling transform_input_spec without a parent environment isn&#39;t supported yet for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">in_key_inv</span><span class="p">,</span> <span class="n">out_key_inv</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">in_key_inv</span> <span class="ow">in</span> <span class="n">full_action_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">_spec</span> <span class="o">=</span> <span class="n">full_action_spec</span><span class="p">[</span><span class="n">in_key_inv</span><span class="p">]</span>
                <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span>
            <span class="k">elif</span> <span class="n">in_key_inv</span> <span class="ow">in</span> <span class="n">full_state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">_spec</span> <span class="o">=</span> <span class="n">full_state_spec</span><span class="p">[</span><span class="n">in_key_inv</span><span class="p">]</span>
                <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;state&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Key </span><span class="si">{</span><span class="n">in_key_inv</span><span class="si">}</span><span class="s2"> not found in state_spec and action_spec.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">_spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;input_spec[</span><span class="si">{</span><span class="n">in_key_inv</span><span class="si">}</span><span class="s2">].dtype is not </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">in_key_inv</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">_spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;action&quot;</span><span class="p">:</span>
                <span class="n">full_action_spec</span><span class="p">[</span><span class="n">out_key_inv</span><span class="p">]</span> <span class="o">=</span> <span class="n">_spec</span>
            <span class="k">elif</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;state&quot;</span><span class="p">:</span>
                <span class="n">full_state_spec</span><span class="p">[</span><span class="n">out_key_inv</span><span class="p">]</span> <span class="o">=</span> <span class="n">_spec</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># unreachable</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="DTypeCastTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DTypeCastTransform.html#torchrl.envs.transforms.DTypeCastTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Calling transform_reward_spec without a parent environment isn&#39;t supported yet for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">full_reward_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span>
        <span class="n">full_observation_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">reward_key</span><span class="p">,</span> <span class="n">reward_spec</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_reward_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
            <span class="c1"># find out_key that match the in_key</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">reward_key</span> <span class="o">==</span> <span class="n">in_key</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reward_spec.dtype is not </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">full_reward_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span>
        <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span>
            <span class="n">full_observation_spec</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

<div class="viewcode-block" id="DTypeCastTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DTypeCastTransform.html#torchrl.envs.transforms.DTypeCastTransform.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">):</span>
        <span class="n">full_observation_spec</span> <span class="o">=</span> <span class="n">observation_spec</span>
        <span class="k">for</span> <span class="n">observation_key</span><span class="p">,</span> <span class="n">observation_spec</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">full_observation_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="c1"># find out_key that match the in_key</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">observation_key</span> <span class="o">==</span> <span class="n">in_key</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;observation_spec.dtype is not </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_in</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="n">full_observation_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span>
                        <span class="n">observation_spec</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="n">full_observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, out_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;in_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="si">}</span><span class="s2">, out_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">s</span></div>


<div class="viewcode-block" id="DoubleToFloat"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DoubleToFloat.html#torchrl.envs.transforms.DoubleToFloat">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DoubleToFloat</span><span class="p">(</span><span class="n">DTypeCastTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Casts one dtype to another for selected keys.</span>

<span class="sd">    Depending on whether the ``in_keys`` or ``in_keys_inv`` are provided</span>
<span class="sd">    during construction, the class behavior will change:</span>

<span class="sd">      * If the keys are provided, those entries and those entries only will be</span>
<span class="sd">        transformed from ``float64`` to ``float32`` entries;</span>
<span class="sd">      * If the keys are not provided and the object is within an environment</span>
<span class="sd">        register of transforms, the input and output specs that have a dtype</span>
<span class="sd">        set to ``float64`` will be used as in_keys_inv / in_keys respectively.</span>
<span class="sd">      * If the keys are not provided and the object is used without an</span>
<span class="sd">        environment, the ``forward`` / ``inverse`` pass will scan through the</span>
<span class="sd">        input tensordict for all float64 values and map them to a float32</span>
<span class="sd">        tensor. For large data structures, this can impact performance as this</span>
<span class="sd">        scanning doesn&#39;t come for free. The keys to be</span>
<span class="sd">        transformed will not be cached.</span>
<span class="sd">        Note that, in this case, the out_keys (resp.</span>
<span class="sd">        out_keys_inv) cannot be passed as the order on which the keys are processed</span>
<span class="sd">        cannot be anticipated precisely.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): list of double keys to be converted to</span>
<span class="sd">            float before being exposed to external objects and functions.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): list of destination keys.</span>
<span class="sd">            Defaults to ``in_keys`` if not provided.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): list of float keys to be converted to</span>
<span class="sd">            double before being passed to the contained base_env or storage.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): list of destination keys for inverse</span>
<span class="sd">            transform.</span>
<span class="sd">            Defaults to ``in_keys_inv`` if not provided.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&#39;obs&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ...     &#39;not_transformed&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ... }, [])</span>
<span class="sd">        &gt;&gt;&gt; transform = DoubleToFloat(in_keys=[&quot;obs&quot;])</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;obs&quot;).dtype)</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;not_transformed&quot;).dtype)</span>
<span class="sd">        torch.float64</span>

<span class="sd">    In &quot;automatic&quot; mode, all float64 entries are transformed:</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&#39;obs&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ...     &#39;not_transformed&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ... }, [])</span>
<span class="sd">        &gt;&gt;&gt; transform = DoubleToFloat()</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;obs&quot;).dtype)</span>
<span class="sd">        torch.float32</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;not_transformed&quot;).dtype)</span>
<span class="sd">        torch.float32</span>

<span class="sd">    The same behavior is the rule when environments are constructed without</span>
<span class="sd">    specifying the transform keys:</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; class MyEnv(EnvBase):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.observation_spec = Composite(obs=Unbounded((), dtype=torch.float64))</span>
<span class="sd">        ...         self.action_spec = Unbounded((), dtype=torch.float64)</span>
<span class="sd">        ...         self.reward_spec = Unbounded((1,), dtype=torch.float64)</span>
<span class="sd">        ...         self.done_spec = Unbounded((1,), dtype=torch.bool)</span>
<span class="sd">        ...     def _reset(self, data=None):</span>
<span class="sd">        ...         return TensorDict({&quot;done&quot;: torch.zeros((1,), dtype=torch.bool), **self.observation_spec.rand()}, [])</span>
<span class="sd">        ...     def _step(self, data):</span>
<span class="sd">        ...         assert data[&quot;action&quot;].dtype == torch.float64</span>
<span class="sd">        ...         reward = self.reward_spec.rand()</span>
<span class="sd">        ...         done = torch.zeros((1,), dtype=torch.bool)</span>
<span class="sd">        ...         obs = self.observation_spec.rand()</span>
<span class="sd">        ...         assert reward.dtype == torch.float64</span>
<span class="sd">        ...         assert obs[&quot;obs&quot;].dtype == torch.float64</span>
<span class="sd">        ...         return obs.empty().set(&quot;next&quot;, obs.update({&quot;reward&quot;: reward, &quot;done&quot;: done}))</span>
<span class="sd">        ...     def _set_seed(self, seed) -&gt; None:</span>
<span class="sd">        ...         pass</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(MyEnv(), DoubleToFloat())</span>
<span class="sd">        &gt;&gt;&gt; assert env.action_spec.dtype == torch.float32</span>
<span class="sd">        &gt;&gt;&gt; assert env.observation_spec[&quot;obs&quot;].dtype == torch.float32</span>
<span class="sd">        &gt;&gt;&gt; assert env.reward_spec.dtype == torch.float32, env.reward_spec.dtype</span>
<span class="sd">        &gt;&gt;&gt; print(env.rollout(2))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        obs: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; assert env.transform.in_keys == [&quot;obs&quot;, &quot;reward&quot;]</span>
<span class="sd">        &gt;&gt;&gt; assert env.transform.in_keys_inv == [&quot;action&quot;]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">dtype_in</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
            <span class="n">dtype_out</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DeviceCastTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DeviceCastTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Moves data from one device to another.</span>

<span class="sd">    Args:</span>
<span class="sd">        device (torch.device or equivalent): the destination device (outside the environment or buffer).</span>
<span class="sd">        orig_device (torch.device or equivalent): the origin device (inside the environment or buffer).</span>
<span class="sd">            If not specified and a parent environment exists, it it retrieved from it. In all other cases,</span>
<span class="sd">            it remains unspecified.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        in_keys (list of NestedKey): the list of entries to map to a different device.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        out_keys (list of NestedKey): the output names of the entries mapped onto a device.</span>
<span class="sd">            Defaults to the values of ``in_keys``.</span>
<span class="sd">        in_keys_inv (list of NestedKey): the list of entries to map to a different device.</span>
<span class="sd">            ``in_keys_inv`` are the names expected by the base environment.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        out_keys_inv (list of NestedKey): the output names of the entries mapped onto a device.</span>
<span class="sd">            ``out_keys_inv`` are the names of the keys as seen from outside the transformed env.</span>
<span class="sd">            Defaults to the values of ``in_keys_inv``.</span>


<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&#39;obs&#39;: torch.ones(1, dtype=torch.double),</span>
<span class="sd">        ... }, [], device=&quot;cpu:0&quot;)</span>
<span class="sd">        &gt;&gt;&gt; transform = DeviceCastTransform(device=torch.device(&quot;cpu:2&quot;))</span>
<span class="sd">        &gt;&gt;&gt; td = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.device)</span>
<span class="sd">        cpu:2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">device</span><span class="p">,</span>
        <span class="n">orig_device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">orig_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">orig_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">orig_device</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_rename_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rename_keys_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span>

        <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span> <span class="o">=</span> <span class="n">_do_nothing</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span> <span class="o">=</span> <span class="n">_do_nothing</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">container</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">EnvBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">container</span><span class="o">.</span><span class="n">device</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parent</span> <span class="o">=</span> <span class="n">container</span><span class="o">.</span><span class="n">parent</span>
                <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">device</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">device</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="n">container</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_to_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span>

<div class="viewcode-block" id="DeviceCastTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;in_keys&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;out_keys&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="n">tensordict_t</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">named_apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_to</span><span class="p">,</span> <span class="n">nested_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rename_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">out_key</span> <span class="o">!=</span> <span class="n">in_key</span><span class="p">:</span>
                    <span class="n">tensordict_t</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
                    <span class="n">tensordict_t</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">tensordict_t</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="n">tensordict_t</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">named_apply</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to</span><span class="p">,</span> <span class="n">nested_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rename_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">out_key</span> <span class="o">!=</span> <span class="n">in_key</span><span class="p">:</span>
                    <span class="n">tensordict_t</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
                    <span class="n">tensordict_t</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_device</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">tensordict_t</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span> <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">parent</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="n">tensordict_t</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">named_apply</span><span class="p">(</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_to_inv</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
            <span class="n">nested_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rename_keys_inv</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">out_key</span> <span class="o">!=</span> <span class="n">in_key</span><span class="p">:</span>
                    <span class="n">tensordict_t</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
                    <span class="n">tensordict_t</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">tensordict_t</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_sync_orig_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">sync_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_sync_orig_device_val&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sync_func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span> <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">parent</span><span class="o">.</span><span class="n">device</span>
            <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
                <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
                <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device_val</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device_val</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sync_orig_device</span>
        <span class="k">return</span> <span class="n">sync_func</span>

<div class="viewcode-block" id="DeviceCastTransform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transform_input_spec</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_action_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_action_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_action_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">full_action_spec</span> <span class="o">=</span> <span class="n">full_action_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">local_action_spec</span> <span class="o">=</span> <span class="n">full_action_spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">local_action_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">full_action_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_action_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">full_action_spec</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_state_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_state_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_state_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">full_state_spec</span> <span class="o">=</span> <span class="n">full_state_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">local_state_spec</span> <span class="o">=</span> <span class="n">full_state_spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">local_state_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">full_state_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_state_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">full_state_spec</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transform_output_spec</span><span class="p">(</span><span class="n">output_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">local_obs_spec</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">local_obs_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">observation_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_obs_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_done_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_done_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_done_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">local_done_spec</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">local_done_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">full_done_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_done_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">full_done_spec</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_reward_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">full_reward_spec</span> <span class="o">=</span> <span class="n">full_reward_spec</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">local_reward_spec</span> <span class="o">=</span> <span class="n">full_reward_spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">local_reward_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">full_reward_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_reward_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">full_reward_spec</span></div>

<div class="viewcode-block" id="DeviceCastTransform.transform_env_device"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform.transform_env_device">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_env_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="c1"># In all other cases the device is not defined</span>
        <span class="k">return</span> <span class="kc">None</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_env_device</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">, orig_device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">orig_device</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;orig_device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">orig_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;out_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;in_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;out_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">orig_device</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">in_keys_inv</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">out_keys_inv</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="CatTensors"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CatTensors.html#torchrl.envs.transforms.CatTensors">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CatTensors</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Concatenates several keys in a single tensor.</span>

<span class="sd">    This is especially useful if multiple keys describe a single state (e.g.</span>
<span class="sd">    &quot;observation_position&quot; and</span>
<span class="sd">    &quot;observation_velocity&quot;)</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey): keys to be concatenated. If `None` (or not provided)</span>
<span class="sd">            the keys will be retrieved from the parent environment the first time</span>
<span class="sd">            the transform is used. This behavior will only work if a parent is set.</span>
<span class="sd">        out_key (NestedKey): key of the resulting tensor.</span>
<span class="sd">        dim (int, optional): dimension along which the concatenation will occur.</span>
<span class="sd">            Default is ``-1``.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        del_keys (bool, optional): if ``True``, the input values will be deleted after</span>
<span class="sd">            concatenation. Default is ``True``.</span>
<span class="sd">        unsqueeze_if_oor (bool, optional): if ``True``, CatTensor will check that</span>
<span class="sd">            the indicated dimension exists for the tensors to concatenate. If not,</span>
<span class="sd">            the tensors will be unsqueezed along that dimension.</span>
<span class="sd">            Default is ``False``.</span>
<span class="sd">        sort (bool, optional): if ``True``, the keys will be sorted in the</span>
<span class="sd">            transform. Otherwise, the order provided by the user will prevail.</span>
<span class="sd">            Defaults to ``True``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; transform = CatTensors(in_keys=[&quot;key1&quot;, &quot;key2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;key1&quot;: torch.zeros(1, 1),</span>
<span class="sd">        ...     &quot;key2&quot;: torch.ones(1, 1)}, [1])</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;observation_vector&quot;))</span>
<span class="sd">        tensor([[0., 1.]])</span>
<span class="sd">        &gt;&gt;&gt; transform = CatTensors(in_keys=[&quot;key1&quot;, &quot;key2&quot;], dim=-2, unsqueeze_if_oor=True)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;key1&quot;: torch.zeros(1),</span>
<span class="sd">        ...     &quot;key2&quot;: torch.ones(1)}, [])</span>
<span class="sd">        &gt;&gt;&gt; _ = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;observation_vector&quot;).shape)</span>
<span class="sd">        torch.Size([2, 1])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;observation_vector&quot;</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">del_keys</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">unsqueeze_if_oor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">sort</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Lazy call to CatTensors is only supported when `dim=-1`.&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">sort</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">_sort_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;CatTensors requires out_key to be of type NestedKey&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">out_key</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_del_keys</span> <span class="o">=</span> <span class="n">del_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys_to_exclude</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze_if_oor</span> <span class="o">=</span> <span class="n">unsqueeze_if_oor</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">keys_to_exclude</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys_to_exclude</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_keys_to_exclude</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="k">if</span> <span class="n">key</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys_to_exclude</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_find_in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Gathers all the entries from observation spec which shape is 1d.&quot;&quot;&quot;</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="n">obs_spec</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">observation_spec</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">obs_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">in_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">_sort_keys</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_in_keys</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;CatTensor failed, as it expected input keys =&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span><span class="w"> </span><span class="n">key</span><span class="o">=</span><span class="n">_sort_keys</span><span class="p">)</span><span class="si">}</span><span class="s2"> but got a TensorDict with keys&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span><span class="w"> </span><span class="n">key</span><span class="o">=</span><span class="n">_sort_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze_if_oor</span><span class="p">:</span>
            <span class="n">pos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="n">abs_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="k">if</span> <span class="n">pos_idx</span> <span class="k">else</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">values</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">v</span>
                <span class="k">if</span> <span class="n">abs_idx</span> <span class="o">&lt;</span> <span class="n">v</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span>
                <span class="k">else</span> <span class="n">v</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">pos_idx</span>
                <span class="k">else</span> <span class="n">v</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span>
            <span class="p">]</span>

        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_del_keys</span><span class="p">:</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">keys_to_exclude</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="CatTensors.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.CatTensors.html#torchrl.envs.transforms.CatTensors.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_in_keys</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># check that all keys are in observation_spec</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;CatTensor cannot infer the output observation spec as there are multiple input keys but &quot;</span>
                <span class="s2">&quot;only one observation_spec.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span>
            <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;CatTensor got a list of keys that does not match the keys in observation_spec. &quot;</span>
                <span class="s2">&quot;Make sure the environment has an observation_spec attribute that includes all the specs needed for CatTensor.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="c1"># by def, there must be only one key</span>
            <span class="k">return</span> <span class="n">observation_spec</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">]</span>

        <span class="n">sum_shape</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">observation_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">observation_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">else</span> <span class="mi">1</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">spec0</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">out_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">spec0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">spec0</span><span class="o">.</span><span class="n">device</span>
        <span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_shape</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">observation_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Unbounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">spec0</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_del_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys_to_exclude</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                    <span class="k">del</span> <span class="n">observation_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, out_key&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="UnaryTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">UnaryTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies a unary operation on the specified inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey): the keys of inputs to the unary operation.</span>
<span class="sd">        out_keys (sequence of NestedKey): the keys of the outputs of the unary operation.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): the keys of inputs to the unary operation during inverse call.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): the keys of the outputs of the unary operation durin inverse call.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        fn (Callable[[Any], Tensor | TensorDictBase]): the function to use as the unary operation. If it accepts</span>
<span class="sd">            a non-tensor input, it must also accept ``None``.</span>
<span class="sd">        inv_fn (Callable[[Any], Any], optional): the function to use as the unary operation during inverse calls.</span>
<span class="sd">            If it accepts a non-tensor input, it must also accept ``None``.</span>
<span class="sd">            Can be ommitted, in which case :attr:`fn` will be used for inverse maps.</span>
<span class="sd">        use_raw_nontensor (bool, optional): if ``False``, data is extracted from</span>
<span class="sd">            :class:`~tensordict.NonTensorData`/:class:`~tensordict.NonTensorStack` inputs before ``fn`` is called</span>
<span class="sd">            on them. If ``True``, the raw :class:`~tensordict.NonTensorData`/:class:`~tensordict.NonTensorStack`</span>
<span class="sd">            inputs are given directly to ``fn``, which must support those</span>
<span class="sd">            inputs. Default is ``False``.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv, UnaryTransform</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = env.append_transform(</span>
<span class="sd">        ...     UnaryTransform(</span>
<span class="sd">        ...         in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...         out_keys=[&quot;observation_trsf&quot;],</span>
<span class="sd">        ...             fn=lambda tensor: str(tensor.numpy().tobytes())))</span>
<span class="sd">        &gt;&gt;&gt; env.observation_spec</span>
<span class="sd">        Composite(</span>
<span class="sd">            observation: BoundedContinuous(</span>
<span class="sd">                shape=torch.Size([3]),</span>
<span class="sd">                space=ContinuousBox(</span>
<span class="sd">                    low=Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, contiguous=True),</span>
<span class="sd">                    high=Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, contiguous=True)),</span>
<span class="sd">                device=cpu,</span>
<span class="sd">                dtype=torch.float32,</span>
<span class="sd">                domain=continuous),</span>
<span class="sd">            observation_trsf: NonTensor(</span>
<span class="sd">                shape=torch.Size([]),</span>
<span class="sd">                space=None,</span>
<span class="sd">                device=cpu,</span>
<span class="sd">                dtype=None,</span>
<span class="sd">                domain=None),</span>
<span class="sd">            device=None,</span>
<span class="sd">            shape=torch.Size([]))</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(3)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        observation_trsf: NonTensorStack(</span>
<span class="sd">                            [&quot;b&#39;\\xbe\\xbc\\x7f?8\\x859=/\\x81\\xbe;&#39;&quot;, &quot;b&#39;\\x...,</span>
<span class="sd">                            batch_size=torch.Size([3]),</span>
<span class="sd">                            device=None),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation_trsf: NonTensorStack(</span>
<span class="sd">                    [&quot;b&#39;\\x9a\\xbd\\x7f?\\xb8T8=8.c&gt;&#39;&quot;, &quot;b&#39;\\xbe\\xbc\...,</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; env.check_env_specs()</span>
<span class="sd">        [torchrl][INFO] check_env_specs succeeded!</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">enable_inv_on_reset</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">inv_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_raw_nontensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span> <span class="o">=</span> <span class="n">fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inv_fn</span> <span class="o">=</span> <span class="n">inv_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_raw_nontensor</span> <span class="o">=</span> <span class="n">use_raw_nontensor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_raw_nontensor</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">NonTensorData</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">NonTensorStack</span><span class="p">):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_raw_nontensor</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">NonTensorData</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">NonTensorStack</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_fn</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="UnaryTransform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># Make a generic input from the spec, call the transform with that</span>
        <span class="c1"># input, and then generate the output spec from the output.</span>
        <span class="n">zero_input_</span> <span class="o">=</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
        <span class="n">test_input</span> <span class="o">=</span> <span class="n">zero_input_</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">zero_input_</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># We use forward and not inv because the spec comes from the base env and</span>
        <span class="c1"># we are trying to infer what the spec looks like from the outside.</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">test_input</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">test_input</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">test_input</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">test_output</span> <span class="o">=</span> <span class="n">test_input</span>
        <span class="c1"># test_output = self.inv(test_input)</span>
        <span class="n">test_input_spec</span> <span class="o">=</span> <span class="n">make_composite_from_td</span><span class="p">(</span>
            <span class="n">test_output</span><span class="p">,</span> <span class="n">unsqueeze_null_shapes</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_action_spec</span><span class="p">(</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">],</span>
            <span class="n">test_input_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;full_state_spec&quot;</span> <span class="ow">in</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_state_spec</span><span class="p">(</span>
                <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">],</span>
                <span class="n">test_input_spec</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="UnaryTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">output_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># Make a generic input from the spec, call the transform with that</span>
        <span class="c1"># input, and then generate the output spec from the output.</span>
        <span class="n">zero_input_</span> <span class="o">=</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
        <span class="n">test_input</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">zero_input_</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
            <span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">zero_input_</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">])</span>
            <span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">zero_input_</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">test_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
        <span class="n">test_output_spec</span> <span class="o">=</span> <span class="n">make_composite_from_td</span><span class="p">(</span>
            <span class="n">test_output</span><span class="p">,</span> <span class="n">unsqueeze_null_shapes</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">],</span>
            <span class="n">test_output_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;full_reward_spec&quot;</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_reward_spec</span><span class="p">(</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">],</span>
                <span class="n">test_output_spec</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;full_done_spec&quot;</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_done_spec</span><span class="p">(</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">],</span>
                <span class="n">test_output_spec</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">inverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">: Only specs of type Composite can be transformed&quot;</span><span class="p">)</span>

        <span class="n">spec_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

        <span class="n">iterator</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">inverse</span>
            <span class="k">else</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">spec_keys</span><span class="p">:</span>
                <span class="n">spec</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">spec</span>

<div class="viewcode-block" id="UnaryTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">:</span> <span class="n">TensorSpec</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="UnaryTransform.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">:</span> <span class="n">TensorSpec</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="UnaryTransform.transform_done_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_done_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_done_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">:</span> <span class="n">TensorSpec</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">done_spec</span><span class="p">,</span> <span class="n">test_output_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="UnaryTransform.transform_action_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_action_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">test_input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">test_input_spec</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="UnaryTransform.transform_state_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform.transform_state_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">test_input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">state_spec</span><span class="p">,</span> <span class="n">test_input_spec</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Hash"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Hash.html#torchrl.envs.transforms.Hash">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Hash</span><span class="p">(</span><span class="n">UnaryTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds a hash value to a tensordict.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey): the keys of the values to hash.</span>
<span class="sd">        out_keys (sequence of NestedKey): the keys of the resulting hashes.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): the keys of the values to hash during inv call.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): the keys of the resulting hashes during inv call.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        hash_fn (Callable, optional): the hash function to use. The function</span>
<span class="sd">            signature must be</span>
<span class="sd">            ``(input: Any, seed: Any | None) -&gt; torch.Tensor``.</span>
<span class="sd">            ``seed`` is only used if this transform is initialized with the</span>
<span class="sd">            ``seed`` argument.  Default is ``Hash.reproducible_hash``.</span>
<span class="sd">        seed (optional): seed to use for the hash function, if it requires one.</span>
<span class="sd">        use_raw_nontensor (bool, optional): if ``False``, data is extracted from</span>
<span class="sd">            :class:`~tensordict.NonTensorData`/:class:`~tensordict.NonTensorStack` inputs before ``fn`` is called</span>
<span class="sd">            on them. If ``True``, the raw :class:`~tensordict.NonTensorData`/:class:`~tensordict.NonTensorStack`</span>
<span class="sd">            inputs are given directly to ``fn``, which must support those</span>
<span class="sd">            inputs. Default is ``False``.</span>
<span class="sd">        repertoire (Dict[Tuple[int], Any], optional): If given, this dict stores</span>
<span class="sd">            the inverse mappings from hashes to inputs. This repertoire isn&#39;t</span>
<span class="sd">            copied, so it can be modified in the same workspace after the</span>
<span class="sd">            transform instantiation and these modifications will be reflected in</span>
<span class="sd">            the map. Missing hashes will be mapped to ``None``. Default: ``None``</span>

<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv, UnaryTransform, Hash</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # Add a string output</span>
<span class="sd">        &gt;&gt;&gt; env = env.append_transform(</span>
<span class="sd">        ...     UnaryTransform(</span>
<span class="sd">        ...         in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...         out_keys=[&quot;observation_str&quot;],</span>
<span class="sd">        ...             fn=lambda tensor: str(tensor.numpy().tobytes())))</span>
<span class="sd">        &gt;&gt;&gt; # process the string output</span>
<span class="sd">        &gt;&gt;&gt; env = env.append_transform(</span>
<span class="sd">        ...     Hash(</span>
<span class="sd">        ...         in_keys=[&quot;observation_str&quot;],</span>
<span class="sd">        ...         out_keys=[&quot;observation_hash&quot;],)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; env.observation_spec</span>
<span class="sd">        Composite(</span>
<span class="sd">            observation: BoundedContinuous(</span>
<span class="sd">                shape=torch.Size([3]),</span>
<span class="sd">                space=ContinuousBox(</span>
<span class="sd">                    low=Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, contiguous=True),</span>
<span class="sd">                    high=Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, contiguous=True)),</span>
<span class="sd">                device=cpu,</span>
<span class="sd">                dtype=torch.float32,</span>
<span class="sd">                domain=continuous),</span>
<span class="sd">            observation_str: NonTensor(</span>
<span class="sd">                shape=torch.Size([]),</span>
<span class="sd">                space=None,</span>
<span class="sd">                device=cpu,</span>
<span class="sd">                dtype=None,</span>
<span class="sd">                domain=None),</span>
<span class="sd">            observation_hash: UnboundedDiscrete(</span>
<span class="sd">                shape=torch.Size([32]),</span>
<span class="sd">                space=ContinuousBox(</span>
<span class="sd">                    low=Tensor(shape=torch.Size([32]), device=cpu, dtype=torch.uint8, contiguous=True),</span>
<span class="sd">                    high=Tensor(shape=torch.Size([32]), device=cpu, dtype=torch.uint8, contiguous=True)),</span>
<span class="sd">                device=cpu,</span>
<span class="sd">                dtype=torch.uint8,</span>
<span class="sd">                domain=discrete),</span>
<span class="sd">            device=None,</span>
<span class="sd">            shape=torch.Size([]))</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(3)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        observation_hash: Tensor(shape=torch.Size([3, 32]), device=cpu, dtype=torch.uint8, is_shared=False),</span>
<span class="sd">                        observation_str: NonTensorStack(</span>
<span class="sd">                            [&quot;b&#39;g\\x08\\x8b\\xbexav\\xbf\\x00\\xee(&gt;&#39;&quot;, &quot;b&#39;\\x...,</span>
<span class="sd">                            batch_size=torch.Size([3]),</span>
<span class="sd">                            device=None),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation_hash: Tensor(shape=torch.Size([3, 32]), device=cpu, dtype=torch.uint8, is_shared=False),</span>
<span class="sd">                observation_str: NonTensorStack(</span>
<span class="sd">                    [&quot;b&#39;\\xb5\\x17\\x8f\\xbe\\x88\\xccu\\xbf\\xc0Vr?&#39;&quot;...,</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; env.check_env_specs()</span>
<span class="sd">        [torchrl][INFO] check_env_specs succeeded!</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">hash_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_raw_nontensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">repertoire</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">hash_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hash_fn</span> <span class="o">=</span> <span class="n">Hash</span><span class="o">.</span><span class="n">reproducible_hash</span>

        <span class="k">if</span> <span class="n">repertoire</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span> <span class="o">=</span> <span class="n">repertoire</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hash_fn</span> <span class="o">=</span> <span class="n">hash_fn</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">call_hash_fn</span><span class="p">,</span>
            <span class="n">inv_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_from_hash</span><span class="p">,</span>
            <span class="n">use_raw_nontensor</span><span class="o">=</span><span class="n">use_raw_nontensor</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="Hash.state_dict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Hash.html#torchrl.envs.transforms.Hash.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;_repertoire&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span><span class="p">}</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">hash_to_repertoire_key</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">hash_tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hash_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">hash_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">hash_tensor</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">hash_to_repertoire_key</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">hash_tensor</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hash_tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">hash_to_repertoire_key</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">hash_tensor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hash_tensor</span>

<div class="viewcode-block" id="Hash.get_input_from_hash"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Hash.html#torchrl.envs.transforms.Hash.get_input_from_hash">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_from_hash</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hash_tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up the input that was given for a particular hash output.</span>

<span class="sd">        This feature is only available if, during initialization, either the</span>
<span class="sd">        ``repertoire`` argument was given or both the ``in_keys_inv`` and</span>
<span class="sd">        ``out_keys_inv`` arguments were given.</span>

<span class="sd">        Args:</span>
<span class="sd">            hash_tensor (Tensor): The hash output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Any: The input that the hash was generated from.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;An inverse transform was queried but the repertoire is None.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_to_repertoire_key</span><span class="p">(</span><span class="n">hash_tensor</span><span class="p">)]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">call_hash_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hash_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash_fn</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hash_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash_fn</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">hash_tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Hash function must return a tensor, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hash_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_repertoire</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_to_repertoire_key</span><span class="p">(</span><span class="n">hash_tensor</span><span class="p">)]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hash_tensor</span>

<div class="viewcode-block" id="Hash.reproducible_hash"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Hash.html#torchrl.envs.transforms.Hash.reproducible_hash">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reproducible_hash</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">string</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates a reproducible 256-bit hash from a string using a seed.</span>

<span class="sd">        Args:</span>
<span class="sd">            string (str or None): The input string. If ``None``, null string ``&quot;&quot;`` is used.</span>
<span class="sd">            seed (str, optional): The seed value. Default is ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Shape ``(32,)`` with dtype ``torch.uint8``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">string</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">string</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Prepend the seed to the string</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">seeded_string</span> <span class="o">=</span> <span class="n">seed</span> <span class="o">+</span> <span class="n">string</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">seeded_string</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>

        <span class="c1"># Create a new SHA-256 hash object</span>
        <span class="n">hash_object</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">()</span>

        <span class="c1"># Update the hash object with the seeded string</span>
        <span class="n">hash_object</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">seeded_string</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>

        <span class="c1"># Get the hash value as bytes</span>
        <span class="n">hash_bytes</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">(</span><span class="n">hash_object</span><span class="o">.</span><span class="n">digest</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">hash_bytes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Tokenizer"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Tokenizer.html#torchrl.envs.transforms.Tokenizer">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="p">(</span><span class="n">UnaryTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies a tokenization operation on the specified inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey): the keys of inputs to the tokenization operation.</span>
<span class="sd">        out_keys (sequence of NestedKey): the keys of the outputs of the tokenization operation.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): the keys of inputs to the tokenization operation during inverse call.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): the keys of the outputs of the tokenization operation during inverse call.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        tokenizer (transformers.PretrainedTokenizerBase or str, optional): the tokenizer to use. If ``None``,</span>
<span class="sd">            &quot;bert-base-uncased&quot; will be used by default. If a string is provided, it should be the name of a</span>
<span class="sd">            pre-trained tokenizer.</span>
<span class="sd">        use_raw_nontensor (bool, optional): if ``False``, data is extracted from</span>
<span class="sd">            :class:`~tensordict.NonTensorData`/:class:`~tensordict.NonTensorStack` inputs before the tokenization</span>
<span class="sd">            function is called on them. If ``True``, the raw :class:`~tensordict.NonTensorData`/:class:`~tensordict.NonTensorStack`</span>
<span class="sd">            inputs are given directly to the tokenization function, which must support those inputs. Default is ``False``.</span>
<span class="sd">        additional_tokens (List[str], optional): list of additional tokens to add to the tokenizer&#39;s vocabulary.</span>

<span class="sd">    .. note:: This transform can be used both to transform output strings into tokens and to transform back tokenized</span>
<span class="sd">        actions or states into strings. If the environment has a string state-spec, the transformed version will have</span>
<span class="sd">        a tokenized state-spec. If it is a string action spec, it will result in a tokenized action spec.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">PretrainedTokenizerBase</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
        <span class="n">use_raw_nontensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">additional_tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">skip_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">add_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_attention_mask</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">missing_tolerance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">call_before_reset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_special_tokens</span> <span class="o">=</span> <span class="n">add_special_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skip_special_tokens</span> <span class="o">=</span> <span class="n">skip_special_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span> <span class="o">=</span> <span class="n">return_attention_mask</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">call_before_reset</span> <span class="o">=</span> <span class="n">call_before_reset</span>
        <span class="k">if</span> <span class="n">additional_tokens</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">additional_tokens</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">call_tokenizer_fn</span><span class="p">,</span>
            <span class="n">inv_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">call_tokenizer_inv_fn</span><span class="p">,</span>
            <span class="n">use_raw_nontensor</span><span class="o">=</span><span class="n">use_raw_nontensor</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span> <span class="o">=</span> <span class="n">missing_tolerance</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;_device&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">return</span> <span class="n">device</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># Specialized for attention mask</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">observation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
                    <span class="n">observation</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">observation</span>
                    <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                        <span class="n">_replace_last</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">),</span>
                        <span class="n">attention_mask</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">out_key</span><span class="p">,</span>
                    <span class="n">observation</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span>
                <span class="ow">and</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">attention_key</span> <span class="o">=</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">attention_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">next_tensordict</span><span class="p">:</span>
                    <span class="n">next_tensordict</span><span class="p">[</span><span class="n">attention_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span>
                        <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">: &#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">next_tensordict</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="Tokenizer.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Tokenizer.html#torchrl.envs.transforms.Tokenizer.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;in_keys&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;out_keys&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
                    <span class="n">data</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                        <span class="n">_replace_last</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">),</span>
                        <span class="n">attention_mask</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_env_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_before_reset</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_before_reset</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict_reset</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">call_tokenizer_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;add_special_tokens&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;padding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;max_length&quot;</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># TODO: incorporate attention mask</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;padding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;max_length&quot;</span>
            <span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;return_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span>
            <span class="c1"># kwargs[&quot;return_token_type_ids&quot;] = False</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">out</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">device</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">attention_mask</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># Override _inv_call to account for ragged dims</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_apply_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">out_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">call_tokenizer_inv_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
                <span class="n">value</span><span class="o">.</span><span class="n">int</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">skip_special_tokens</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                <span class="n">value</span><span class="o">.</span><span class="n">int</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">skip_special_tokens</span>
            <span class="p">)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_str_device</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">NonTensorStack</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">device</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">NonTensorData</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_str_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">in_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
            <span class="n">in_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">observation_keys</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">parent</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">action_keys</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">parent</span><span class="o">.</span><span class="n">full_action_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">state_keys</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">parent</span><span class="o">.</span><span class="n">full_state_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="k">return</span> <span class="kc">None</span>

<div class="viewcode-block" id="Tokenizer.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Tokenizer.html#torchrl.envs.transforms.Tokenizer.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="c1"># We need to cap the spec to generate valid random strings</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The input keys </span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2"> wasn&#39;t found in the env input specs.&quot;</span>
                <span class="p">)</span>
            <span class="n">local_spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="n">local_dtype</span> <span class="o">=</span> <span class="n">local_spec</span><span class="o">.</span><span class="n">dtype</span>
            <span class="k">if</span> <span class="n">local_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">local_dtype</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span>
                <span class="n">local_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Then we can&#39;t tell what the shape will be</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="n">new_shape</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="n">new_shape</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,))</span>
            <span class="n">spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">local_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">local_dtype</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

    <span class="n">transform_output_spec</span> <span class="o">=</span> <span class="n">Transform</span><span class="o">.</span><span class="n">transform_output_spec</span>
    <span class="n">transform_reward_spec</span> <span class="o">=</span> <span class="n">Transform</span><span class="o">.</span><span class="n">transform_reward_spec</span>
    <span class="n">transform_done_spec</span> <span class="o">=</span> <span class="n">Transform</span><span class="o">.</span><span class="n">transform_done_spec</span>

<div class="viewcode-block" id="Tokenizer.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Tokenizer.html#torchrl.envs.transforms.Tokenizer.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">attention_mask_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">in_spec</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
                <span class="n">obs_dtype</span> <span class="o">=</span> <span class="n">in_spec</span><span class="o">.</span><span class="n">dtype</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">in_spec</span><span class="o">.</span><span class="n">device</span>
            <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                <span class="c1"># In some cases (eg, the tokenizer is applied during reset on data that</span>
                <span class="c1">#  originates from a dataloader) we don&#39;t have an in_spec</span>
                <span class="n">in_spec</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">obs_dtype</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span>
            <span class="k">if</span> <span class="n">obs_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">obs_dtype</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span>
                <span class="n">obs_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="n">observation_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">obs_dtype</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask_key</span> <span class="o">=</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">attention_mask_key</span> <span class="ow">in</span> <span class="n">attention_mask_keys</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="s2">&quot;Conflicting attention_mask keys. Make sure the token tensors are &quot;</span>
                        <span class="s2">&quot;nested at different places in the tensordict such that `(*root, &#39;attention_mask&#39;)` &quot;</span>
                        <span class="s2">&quot;entries are unique.&quot;</span>
                    <span class="p">)</span>
                <span class="n">attention_mask_keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">attention_mask_key</span><span class="p">)</span>
                <span class="n">attention_dtype</span> <span class="o">=</span> <span class="n">obs_dtype</span>
                <span class="k">if</span> <span class="n">attention_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">attention_dtype</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span>
                    <span class="n">attention_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
                <span class="n">observation_spec</span><span class="p">[</span><span class="n">attention_mask_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                    <span class="mi">0</span><span class="p">,</span>
                    <span class="mi">2</span><span class="p">,</span>
                    <span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">attention_dtype</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div></div>


<div class="viewcode-block" id="Stack"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Stack.html#torchrl.envs.transforms.Stack">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Stack</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stacks tensors and tensordicts.</span>

<span class="sd">    Concatenates a sequence of tensors or tensordicts along a new dimension.</span>
<span class="sd">    The tensordicts or tensors under ``in_keys`` must all have the same shapes.</span>

<span class="sd">    This transform only stacks the inputs into one output key. Stacking multiple</span>
<span class="sd">    groups of input keys into different output keys requires multiple</span>
<span class="sd">    transforms.</span>

<span class="sd">    This transform can be useful for environments that have multiple agents with</span>
<span class="sd">    identical specs under different keys. The specs and tensordicts for the</span>
<span class="sd">    agents can be stacked together under a shared key, in order to run MARL</span>
<span class="sd">    algorithms that expect the tensors for observations, rewards, etc. to</span>
<span class="sd">    contain batched data for all the agents.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey): keys to be stacked.</span>
<span class="sd">        out_key (NestedKey): key of the resulting stacked entry.</span>
<span class="sd">        in_key_inv (NestedKey, optional): key to unstack during :meth:`~.inv`</span>
<span class="sd">            calls. Default is ``None``.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): keys of the resulting</span>
<span class="sd">            unstacked entries after :meth:`~.inv` calls. Default is ``None``.</span>
<span class="sd">        dim (int, optional): dimension to insert. Default is ``-1``.</span>
<span class="sd">        allow_positive_dim (bool, optional): if ``True``, positive dimensions</span>
<span class="sd">            are accepted.  Defaults to ``False``, ie. non-negative dimensions are</span>
<span class="sd">            not permitted.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        del_keys (bool, optional): if ``True``, the input values will be deleted</span>
<span class="sd">            after stacking. Default is ``True``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import Stack</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;key1&quot;: torch.zeros(3), &quot;key2&quot;: torch.ones(3)}, [])</span>
<span class="sd">        &gt;&gt;&gt; td</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                key1: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                key2: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; transform = Stack(in_keys=[&quot;key1&quot;, &quot;key2&quot;], out_key=&quot;out&quot;, dim=-2)</span>
<span class="sd">        &gt;&gt;&gt; transform(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                out: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td[&quot;out&quot;]</span>
<span class="sd">        tensor([[0., 0., 0.],</span>
<span class="sd">                [1., 1., 1.]])</span>

<span class="sd">        &gt;&gt;&gt; agent_0 = TensorDict({&quot;obs&quot;: torch.rand(4, 5), &quot;reward&quot;: torch.zeros(1)})</span>
<span class="sd">        &gt;&gt;&gt; agent_1 = TensorDict({&quot;obs&quot;: torch.rand(4, 5), &quot;reward&quot;: torch.zeros(1)})</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;agent_0&quot;: agent_0, &quot;agent_1&quot;: agent_1})</span>
<span class="sd">        &gt;&gt;&gt; transform = Stack(in_keys=[&quot;agent_0&quot;, &quot;agent_1&quot;], out_key=&quot;agents&quot;)</span>
<span class="sd">        &gt;&gt;&gt; transform(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                agents: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        obs: Tensor(shape=torch.Size([2, 4, 5]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
        <span class="n">out_key</span><span class="p">:</span> <span class="n">NestedKey</span><span class="p">,</span>
        <span class="n">in_key_inv</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">allow_positive_dim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">del_keys</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">allow_positive_dim</span> <span class="ow">and</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;dim should be negative to accommodate for envs of different &quot;</span>
                <span class="s2">&quot;batch_sizes. If you need dim to be positive, set &quot;</span>
                <span class="s2">&quot;allow_positive_dim=True.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">in_key_inv</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;out_keys_inv was specified, but in_key_inv was not&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">in_key_inv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;in_key_inv was specified, but out_keys_inv was not&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">out_key</span><span class="p">],</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">in_key_inv</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">in_key_inv</span><span class="p">],</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys_inv</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">k1</span> <span class="o">==</span> <span class="n">k2</span> <span class="k">for</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">: out_key cannot be in in_keys&quot;</span><span class="p">)</span>
        <span class="n">parent_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">parent_level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)):</span>
                    <span class="n">parent_key</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">key</span><span class="p">[:</span><span class="o">-</span><span class="n">parent_level</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">parent_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parent_keys</span><span class="p">:</span>
                        <span class="n">parent_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parent_key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_del_parent_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">parent_keys</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_del_keys</span> <span class="o">=</span> <span class="n">del_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys_to_exclude</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">: &#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">next_tensordict</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_del_keys</span><span class="p">:</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">parent_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_del_parent_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">[</span><span class="n">parent_key</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">next_tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="n">parent_key</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">tensordict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">value</span><span class="p">,</span> <span class="n">out_key_inv</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key_inv</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">: Only specs of type Composite can be transformed&quot;</span><span class="p">)</span>

        <span class="n">spec_keys</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">keys_to_stack</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">spec_keys</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">]</span>
        <span class="n">specs_to_stack</span> <span class="o">=</span> <span class="p">[</span><span class="n">spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys_to_stack</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">specs_to_stack</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">spec</span>

        <span class="n">stacked_specs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">specs_to_stack</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">spec</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stacked_specs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_del_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys_to_stack</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">parent_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_del_parent_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="n">parent_key</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">spec</span><span class="p">[</span><span class="n">parent_key</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">spec</span>

<div class="viewcode-block" id="Stack.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Stack.html#torchrl.envs.transforms.Stack.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="Stack.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Stack.html#torchrl.envs.transforms.Stack.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="Stack.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Stack.html#torchrl.envs.transforms.Stack.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="Stack.transform_done_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Stack.html#torchrl.envs.transforms.Stack.transform_done_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_done_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_spec</span><span class="p">(</span><span class="n">done_spec</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;out_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;dim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="s2">&quot;)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DiscreteActionProjection"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DiscreteActionProjection.html#torchrl.envs.transforms.DiscreteActionProjection">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DiscreteActionProjection</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Projects discrete actions from a high dimensional space to a low dimensional space.</span>

<span class="sd">    Given a discrete action (from 1 to N) encoded as a one-hot vector and a</span>
<span class="sd">    maximum action index num_actions (with num_actions &lt; N), transforms the action such that</span>
<span class="sd">    action_out is at most num_actions.</span>

<span class="sd">    If the input action is &gt; num_actions, it is being replaced by a random value</span>
<span class="sd">    between 0 and num_actions-1. Otherwise the same action is kept.</span>
<span class="sd">    This is intended to be used with policies applied over multiple discrete</span>
<span class="sd">    control environments with different action space.</span>

<span class="sd">    A call to DiscreteActionProjection.forward (eg from a replay buffer or in a</span>
<span class="sd">    sequence of nn.Modules) will call the transform num_actions_effective -&gt; max_actions</span>
<span class="sd">    on the :obj:`&quot;in_keys&quot;`, whereas a call to _call will be ignored. Indeed,</span>
<span class="sd">    transformed envs are instructed to update the input keys only for the inner</span>
<span class="sd">    base_env, but the original input keys will remain unchanged.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_actions_effective (int): max number of action considered.</span>
<span class="sd">        max_actions (int): maximum number of actions that this module can read.</span>
<span class="sd">        action_key (NestedKey, optional): key name of the action. Defaults to &quot;action&quot;.</span>
<span class="sd">        include_forward (bool, optional): if ``True``, a call to forward will also</span>
<span class="sd">            map the action from one domain to the other when the module is called</span>
<span class="sd">            by a replay buffer or an nn.Module chain. Defaults to `True`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; N = 3</span>
<span class="sd">        &gt;&gt;&gt; M = 2</span>
<span class="sd">        &gt;&gt;&gt; action = torch.zeros(N, dtype=torch.long)</span>
<span class="sd">        &gt;&gt;&gt; action[-1] = 1</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;action&quot;: action}, [])</span>
<span class="sd">        &gt;&gt;&gt; transform = DiscreteActionProjection(num_actions_effective=M, max_actions=N)</span>
<span class="sd">        &gt;&gt;&gt; _ = transform.inv(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;action&quot;))</span>
<span class="sd">        tensor([1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_actions_effective</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">max_actions</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">action_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span><span class="p">,</span>
        <span class="n">include_forward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[</span><span class="n">action_key</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">include_forward</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys_inv</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">),</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys_inv</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions_effective</span> <span class="o">=</span> <span class="n">num_actions_effective</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span> <span class="o">=</span> <span class="n">max_actions</span>
        <span class="k">if</span> <span class="n">max_actions</span> <span class="o">&lt;</span> <span class="n">num_actions_effective</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;The `max_actions` int must be greater or equal to `num_actions_effective`.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># We don&#39;t do anything here because the action is modified by the inv</span>
        <span class="c1"># method but we don&#39;t need to map it back as it won&#39;t be updated in the original</span>
        <span class="c1"># tensordict</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># We still need to code the forward transform for replay buffers and models</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># bool to int</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;action.shape[-1]=</span><span class="si">{</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> must match self.max_actions=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># bool to int</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">action</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions_effective</span>
        <span class="k">if</span> <span class="n">idx</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">action</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions_effective</span><span class="p">,</span> <span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">sum</span><span class="p">(),))</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions_effective</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span>

<div class="viewcode-block" id="DiscreteActionProjection.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.DiscreteActionProjection.html#torchrl.envs.transforms.DiscreteActionProjection.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">):</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;key not found in action_spec.&quot;</span><span class="p">)</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">OneHot</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">input_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span><span class="p">),</span>
            <span class="n">device</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">input_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(num_actions_effective=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions_effective</span><span class="si">}</span><span class="s2">, max_actions=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_actions</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;in_keys_inv=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="FrameSkipTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.FrameSkipTransform.html#torchrl.envs.transforms.FrameSkipTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">FrameSkipTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A frame-skip transform.</span>

<span class="sd">    This transform applies the same action repeatedly in the parent environment,</span>
<span class="sd">    which improves stability on certain training sota-implementations.</span>

<span class="sd">    Args:</span>
<span class="sd">        frame_skip (int, optional): a positive integer representing the number</span>
<span class="sd">            of frames during which the same action must be applied.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame_skip</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">frame_skip</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;frame_skip should have a value greater or equal to one.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frame_skip</span> <span class="o">=</span> <span class="n">frame_skip</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;parent not found for FrameSkipTransform&quot;</span><span class="p">)</span>
        <span class="n">reward_key</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">reward_key</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reward_key</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frame_skip</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reward_key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">reward_key</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>

<div class="viewcode-block" id="FrameSkipTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.FrameSkipTransform.html#torchrl.envs.transforms.FrameSkipTransform.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;FrameSkipTransform can only be used when appended to a transformed env.&quot;</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="NoopResetEnv"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.NoopResetEnv.html#torchrl.envs.transforms.NoopResetEnv">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">NoopResetEnv</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a series of random actions when an environment is reset.</span>

<span class="sd">    Args:</span>
<span class="sd">        env (EnvBase): env on which the random actions have to be</span>
<span class="sd">            performed. Can be the same env as the one provided to the</span>
<span class="sd">            TransformedEnv class</span>
<span class="sd">        noops (int, optional): upper-bound on the number of actions</span>
<span class="sd">            performed after reset. Default is `30`.</span>
<span class="sd">            If noops is too high such that it results in the env being</span>
<span class="sd">            done or truncated before the all the noops are applied,</span>
<span class="sd">            in multiple trials, the transform raises a RuntimeError.</span>
<span class="sd">        random (bool, optional): if False, the number of random ops will</span>
<span class="sd">            always be equal to the noops value. If True, the number of</span>
<span class="sd">            random actions will be randomly selected between 0 and noops.</span>
<span class="sd">            Default is `True`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noops</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="n">random</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample initial states by taking random number of no-ops on reset.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noops</span> <span class="o">=</span> <span class="n">noops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="n">random</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">base_env</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Do no-op action for a number of steps in [1, noop_max].&quot;&quot;&quot;</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;NoopResetEnv.parent not found. Make sure that the parent is set.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Merge the two tensordicts</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">_reset_proc_data</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="c1"># check that there is a single done state -- behavior is undefined for multiple dones</span>
        <span class="n">done_keys</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span>
        <span class="n">reward_key</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">reward_key</span>
        <span class="k">if</span> <span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The parent environment batch-size is non-null. &quot;</span>
                <span class="s2">&quot;NoopResetEnv is designed to work on single env instances, as partial reset &quot;</span>
                <span class="s2">&quot;is currently not supported. If you feel like this is a missing feature, submit &quot;</span>
                <span class="s2">&quot;an issue on TorchRL github repo. &quot;</span>
                <span class="s2">&quot;In case you are trying to use NoopResetEnv over a batch of environments, know &quot;</span>
                <span class="s2">&quot;that you can have a transformed batch of transformed envs, such as: &quot;</span>
                <span class="s2">&quot;`TransformedEnv(ParallelEnv(3, lambda: TransformedEnv(MyEnv(), NoopResetEnv(3))), OtherTransform())`.&quot;</span>
            <span class="p">)</span>

        <span class="n">noops</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noops</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noops</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">trial</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">trial</span> <span class="o">&lt;=</span> <span class="n">_MAX_NOOPS_TRIALS</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">noops</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">rand_step</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="c1"># if any of the done_keys is True, we break</span>
                <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="n">done_keys</span><span class="p">:</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">done_key</span><span class="p">))</span>
                    <span class="k">if</span> <span class="n">done</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> only supports scalar done states.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                        <span class="n">reset</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">break</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="n">step_mdp</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">exclude_done</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
                    <span class="n">tensordict</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">trial</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Parent env was repeatedly done or truncated&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; before the sampled number of noops (=</span><span class="si">{</span><span class="n">noops</span><span class="si">}</span><span class="s2">) could be applied. &quot;</span>
            <span class="p">)</span>
        <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">tensordict</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="n">reward_key</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">random</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random</span>
        <span class="n">noops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noops</span>
        <span class="n">class_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">(noops=</span><span class="si">{</span><span class="n">noops</span><span class="si">}</span><span class="s2">, random=</span><span class="si">{</span><span class="n">random</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="TensorDictPrimer"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TensorDictPrimer.html#torchrl.envs.transforms.TensorDictPrimer">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TensorDictPrimer</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A primer for TensorDict initialization at reset time.</span>

<span class="sd">    This transform will populate the tensordict at reset with values drawn from</span>
<span class="sd">    the relative tensorspecs provided at initialization.</span>
<span class="sd">    If the transform is used out of the env context (e.g. as an nn.Module or</span>
<span class="sd">    appended to a replay buffer), a call to `forward` will also populate the</span>
<span class="sd">    tensordict with the desired features.</span>

<span class="sd">    Args:</span>
<span class="sd">        primers (dict or Composite, optional): a dictionary containing</span>
<span class="sd">            key-spec pairs which will be used to populate the input tensordict.</span>
<span class="sd">            :class:`~torchrl.data.Composite` instances are supported too.</span>
<span class="sd">        random (bool, optional): if ``True``, the values will be drawn randomly from</span>
<span class="sd">            the TensorSpec domain (or a unit Gaussian if unbounded). Otherwise a fixed value will be assumed.</span>
<span class="sd">            Defaults to `False`.</span>
<span class="sd">        default_value (:obj:`float`, Callable, Dict[NestedKey, float], Dict[NestedKey, Callable], optional): If non-random</span>
<span class="sd">            filling is chosen, `default_value` will be used to populate the tensors.</span>

<span class="sd">            - If `default_value` is a float or any other scala, all elements of the tensors will be set to that value.</span>
<span class="sd">            - If it is a callable and `single_default_value=False` (default), this callable is expected to return a tensor</span>
<span class="sd">              fitting the specs (ie, ``default_value()`` will be called independently for each leaf spec).</span>
<span class="sd">            - If it is a callable and ``single_default_value=True``, then the callable will be called just once and it is expected</span>
<span class="sd">              that the structure of its returned TensorDict instance or equivalent will match the provided specs.</span>
<span class="sd">              The ``default_value`` must accept an optional `reset` keyword argument indicating which envs are to be reset.</span>
<span class="sd">              The returned `TensorDict` must have as many elements as the number of envs to reset.</span>

<span class="sd">              .. seealso:: :class:`~torchrl.envs.DataLoadingPrimer`</span>

<span class="sd">            - Finally, if `default_value` is a dictionary of tensors or a dictionary of callables with keys matching</span>
<span class="sd">              those of the specs, these will be used to generate the corresponding tensors. Defaults to `0.0`.</span>

<span class="sd">        reset_key (NestedKey, optional): the reset key to be used as partial</span>
<span class="sd">            reset indicator. Must be unique. If not provided, defaults to the</span>
<span class="sd">            only reset key of the parent environment (if it has only one)</span>
<span class="sd">            and raises an exception otherwise.</span>
<span class="sd">        single_default_value (bool, optional): if ``True`` and `default_value` is a callable, it will be expected that</span>
<span class="sd">            ``default_value`` returns a single tensordict matching the specs. If `False`, `default_value()` will be</span>
<span class="sd">            called independently for each leaf. Defaults to ``False``.</span>
<span class="sd">        call_before_env_reset (bool, optional): if ``True``, the tensordict is populated before `env.reset` is called.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        **kwargs: each keyword argument corresponds to a key in the tensordict.</span>
<span class="sd">            The corresponding value has to be a TensorSpec instance indicating</span>
<span class="sd">            what the value must be.</span>

<span class="sd">    When used in a `TransformedEnv`, the spec shapes must match the environment&#39;s shape if</span>
<span class="sd">    the parent environment is batch-locked (`env.batch_locked=True`). If the spec shapes and</span>
<span class="sd">    parent shapes do not match, the spec shapes are modified in-place to match the leading</span>
<span class="sd">    dimensions of the parent&#39;s batch size. This adjustment is made for cases where the parent</span>
<span class="sd">    batch size dimension is not known during instantiation.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import SerialEnv</span>
<span class="sd">        &gt;&gt;&gt; base_env = SerialEnv(2, lambda: GymEnv(&quot;Pendulum-v1&quot;))</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env)</span>
<span class="sd">        &gt;&gt;&gt; # the env is batch-locked, so the leading dims of the spec must match those of the env</span>
<span class="sd">        &gt;&gt;&gt; env.append_transform(TensorDictPrimer(mykey=Unbounded([2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; td = env.reset()</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                mykey: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; # the entry is populated with 0s</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;mykey&quot;))</span>
<span class="sd">        tensor([[0., 0., 0.],</span>
<span class="sd">                [0., 0., 0.]])</span>

<span class="sd">    When calling ``env.step()``, the current value of the key will be carried</span>
<span class="sd">    in the ``&quot;next&quot;`` tensordict __unless it already exists__.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; td = env.rand_step(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get((&quot;next&quot;, &quot;mykey&quot;)))</span>
<span class="sd">        tensor([[0., 0., 0.],</span>
<span class="sd">                [0., 0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; # with another value for &quot;mykey&quot;, the previous value is not carried on</span>
<span class="sd">        &gt;&gt;&gt; td = env.reset()</span>
<span class="sd">        &gt;&gt;&gt; td = td.set((&quot;next&quot;, &quot;mykey&quot;), torch.ones(2, 3))</span>
<span class="sd">        &gt;&gt;&gt; td = env.rand_step(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get((&quot;next&quot;, &quot;mykey&quot;)))</span>
<span class="sd">        tensor([[1., 1., 1.],</span>
<span class="sd">                [1., 1., 1.]])</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import SerialEnv, TransformedEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.utils import get_primers_from_module</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import GRUModule</span>
<span class="sd">        &gt;&gt;&gt; base_env = SerialEnv(2, lambda: GymEnv(&quot;Pendulum-v1&quot;))</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env)</span>
<span class="sd">        &gt;&gt;&gt; model = GRUModule(input_size=2, hidden_size=2, in_key=&quot;observation&quot;, out_key=&quot;action&quot;)</span>
<span class="sd">        &gt;&gt;&gt; primers = get_primers_from_module(model)</span>
<span class="sd">        &gt;&gt;&gt; print(primers) # Primers shape is independent of the env batch size</span>
<span class="sd">        TensorDictPrimer(primers=Composite(</span>
<span class="sd">            recurrent_state: UnboundedContinuous(</span>
<span class="sd">                shape=torch.Size([1, 2]),</span>
<span class="sd">                space=ContinuousBox(</span>
<span class="sd">                    low=Tensor(shape=torch.Size([1, 2]), device=cpu, dtype=torch.float32, contiguous=True),</span>
<span class="sd">                    high=Tensor(shape=torch.Size([1, 2]), device=cpu, dtype=torch.float32, contiguous=True)),</span>
<span class="sd">                device=cpu,</span>
<span class="sd">                dtype=torch.float32,</span>
<span class="sd">                domain=continuous),</span>
<span class="sd">            device=None,</span>
<span class="sd">            shape=torch.Size([])), default_value={&#39;recurrent_state&#39;: 0.0}, random=None)</span>
<span class="sd">        &gt;&gt;&gt; env.append_transform(primers)</span>
<span class="sd">        &gt;&gt;&gt; print(env.reset()) # The primers are automatically expanded to match the env batch size</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                recurrent_state: Tensor(shape=torch.Size([2, 1, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    .. note:: Some TorchRL modules rely on specific keys being present in the environment TensorDicts,</span>
<span class="sd">        like :class:`~torchrl.modules.models.LSTM` or :class:`~torchrl.modules.models.GRU`.</span>
<span class="sd">        To facilitate this process, the method :func:`~torchrl.modules.utils.get_primers_from_module`</span>
<span class="sd">        automatically checks for required primer transforms in a module and its submodules and</span>
<span class="sd">        generates them.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">primers</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="n">Composite</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">random</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">default_value</span><span class="p">:</span> <span class="nb">float</span>
        <span class="o">|</span> <span class="n">Callable</span>
        <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">expand_specs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">single_default_value</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">call_before_env_reset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">primers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;providing the primers as a dictionary is incompatible with extra keys &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&#39; provided as kwargs.&quot;</span>
                <span class="p">)</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">primers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="k">if</span> <span class="s2">&quot;batch_size&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">)}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">primers</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">primers</span> <span class="o">=</span> <span class="n">primers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expand_specs</span> <span class="o">=</span> <span class="n">expand_specs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">call_before_env_reset</span> <span class="o">=</span> <span class="n">call_before_env_reset</span>

        <span class="k">if</span> <span class="n">random</span> <span class="ow">and</span> <span class="n">default_value</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Setting random to True and providing a default_value are incompatible.&quot;</span>
            <span class="p">)</span>
        <span class="n">default_value</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">default_value</span> <span class="ow">or</span> <span class="mf">0.0</span>
        <span class="p">)</span>  <span class="c1"># if not random and no default value, use 0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="n">random</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">default_value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">default_value</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">default_value</span><span class="p">,</span> <span class="p">[])</span>
            <span class="n">default_value_keys</span> <span class="o">=</span> <span class="n">default_value</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="n">is_leaf</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">NonTensorData</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">default_value_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If a default_value dictionary is provided, it must match the primers keys.&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">single_default_value</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_value</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">default_value</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">single_default_value</span> <span class="o">=</span> <span class="n">single_default_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span> <span class="o">=</span> <span class="n">default_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span> <span class="o">=</span> <span class="n">reset_key</span>

        <span class="c1"># sanity check</span>
        <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The values of the primers must be a subtype of the TensorSpec class. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">reset_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_reset_key&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reset_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Missing parent, cannot infer reset_key automatically.&quot;</span>
                <span class="p">)</span>
            <span class="n">reset_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reset_keys</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Got more than one reset key in env </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="si">}</span><span class="s2">, cannot infer which one to use. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Consider providing the reset key in the </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> constructor.&quot;</span>
                <span class="p">)</span>
            <span class="n">reset_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">reset_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">reset_key</span>

    <span class="nd">@reset_key</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;parent&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">device</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">return</span> <span class="n">device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<div class="viewcode-block" id="TensorDictPrimer.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TensorDictPrimer.html#torchrl.envs.transforms.TensorDictPrimer.to">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="n">convert_to_format</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_nn</span><span class="o">.</span><span class="n">_parse_to</span><span class="p">(</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">primers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_expand_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span><span class="o">.</span><span class="n">expand</span><span class="p">((</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<div class="viewcode-block" id="TensorDictPrimer.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TensorDictPrimer.html#torchrl.envs.transforms.TensorDictPrimer.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;observation_spec was expected to be of type Composite. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">ndim</span><span class="p">]</span> <span class="o">!=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand_specs</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">primers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expand_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand_specs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;expand_specs wasn&#39;t specified in the </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> constructor, and the shape of the primers &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;and observation specs mismatch (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2"> and </span><span class="si">{</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2">) - indicating a batch-size incongruency. Make sure the expand_specs arg &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;is properly set or that the primer shape matches the environment batch-size.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span>
        <span class="n">observation_spec</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="TensorDictPrimer.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TensorDictPrimer.html#torchrl.envs.transforms.TensorDictPrimer.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">new_state_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="n">new_state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">,</span> <span class="n">action_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_state_spec</span><span class="p">[</span><span class="n">action_key</span><span class="p">]</span>
                <span class="k">del</span> <span class="n">new_state_spec</span><span class="p">[</span><span class="n">action_key</span><span class="p">]</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_state_spec</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_value_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_in</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;spec </span><span class="si">{</span><span class="n">spec</span><span class="si">}</span><span class="s2">, spec.shape </span><span class="si">{</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, value.shape </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, spec.device </span><span class="si">{</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">, value.device </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">, spec.dtype </span><span class="si">{</span><span class="n">spec</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">, value.dtype </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value (</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">) is not in the spec domain (</span><span class="si">{</span><span class="n">spec</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>

<div class="viewcode-block" id="TensorDictPrimer.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TensorDictPrimer.html#torchrl.envs.transforms.TensorDictPrimer.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_default_value</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">):</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_value_tensor</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">spec</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span> <span class="o">!=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;The leading shape of the spec must match the tensordict&#39;s, &quot;</span>
                    <span class="s2">&quot;but it does not: got &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;tensordict.shape=</span><span class="si">{</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> whereas </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> spec&#39;s shape is &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">()</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_value_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                        <span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                        <span class="n">value</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">)</span>

            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="c1"># We relax a bit the condition here, allowing nested but not leaf values to</span>
            <span class="c1">#  be checked against</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">_is_leaf_nontensor</span><span class="p">):</span>
                <span class="n">prev_val</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">prev_val</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the default values in the input tensordict.</span>

<span class="sd">        If the parent is batch-locked, we make sure the specs have the appropriate leading</span>
<span class="sd">        shape. We allow for execution when the parent is missing, in which case the</span>
<span class="sd">        spec shape is assumed to match the tensordict&#39;s.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_before_env_reset</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict_reset</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reset_func</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_env_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_before_env_reset</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">device</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">device</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="p">())</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reset_func</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_func</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">_reset</span> <span class="o">=</span> <span class="n">_get_reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_locked</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">primers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expand_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_reset</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_default_value</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">_reset</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="c1"># FIXME: use masked op</span>
                    <span class="c1"># tensordict_reset = tensordict_reset.clone()</span>
                    <span class="n">reset_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">(</span><span class="n">reset</span><span class="o">=</span><span class="n">_reset</span><span class="p">)</span>
                    <span class="c1"># This is safE because env.reset calls _update_during_reset which will discard the new data</span>
                    <span class="c1"># tensordict_reset = (</span>
                    <span class="c1">#     self.container.full_observation_spec.zero().select(</span>
                    <span class="c1">#         *reset_val.keys(True)</span>
                    <span class="c1">#     )</span>
                    <span class="c1"># )</span>
                    <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">reset_val</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span>
                        <span class="n">_reset</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">empty_lazy</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>
                    <span class="n">tensordict_reset</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span> <span class="o">=</span> <span class="n">reset_val</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">resets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">(</span><span class="n">reset</span><span class="o">=</span><span class="n">_reset</span><span class="p">)</span>
                    <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">resets</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_value_tensor</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">spec</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">return</span> <span class="n">tensordict_reset</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random</span><span class="p">:</span>
                    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="p">()</span>
                        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_locked</span><span class="p">)</span>
                        <span class="k">else</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="p">)</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">()</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_value_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                            <span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                            <span class="n">value</span><span class="p">,</span>
                            <span class="n">device</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="n">prev_val</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                        <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                            <span class="n">expand_as_right</span><span class="p">(</span><span class="n">_reset</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="n">value</span><span class="p">,</span> <span class="n">prev_val</span>
                        <span class="p">)</span>
                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">class_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="p">):</span>
            <span class="n">default_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_value</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;Callable&quot;</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_value</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">(primers=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">primers</span><span class="si">}</span><span class="s2">, default_value=</span><span class="si">{</span><span class="n">default_value</span><span class="si">}</span><span class="s2">, random=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">random</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="PinMemoryTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.PinMemoryTransform.html#torchrl.envs.transforms.PinMemoryTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">PinMemoryTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calls pin_memory on the tensordict to facilitate writing on CUDA devices.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_sum_left</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
    <span class="k">while</span> <span class="n">val</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">dest</span><span class="o">.</span><span class="n">ndimension</span><span class="p">():</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">val</span>


<div class="viewcode-block" id="gSDENoise"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.gSDENoise.html#torchrl.envs.transforms.gSDENoise">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">gSDENoise</span><span class="p">(</span><span class="n">TensorDictPrimer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A gSDE noise initializer.</span>

<span class="sd">    See the :func:`~torchrl.modules.models.exploration.gSDEModule&#39; for more info.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">state_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">action_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dim</span> <span class="o">=</span> <span class="n">state_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="n">action_dim</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">()</span>
        <span class="n">tail_dim</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="k">if</span> <span class="n">state_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">action_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="n">action_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">random</span> <span class="o">=</span> <span class="n">state_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">action_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">feat_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">tail_dim</span>
        <span class="n">primers</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">({</span><span class="s2">&quot;_eps_gSDE&quot;</span><span class="p">:</span> <span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">feat_shape</span><span class="p">)},</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">primers</span><span class="o">=</span><span class="n">primers</span><span class="p">,</span> <span class="n">random</span><span class="o">=</span><span class="n">random</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_VecNormMeta</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">new_api</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;new_api&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_api</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The VecNorm class is to be deprecated in favor of `torchrl.envs.VecNormV2` and will be replaced by &quot;</span>
                <span class="s2">&quot;that class in v0.10. You can adapt to these changes by using the `new_api` argument or importing &quot;</span>
                <span class="s2">&quot;the `VecNormV2` class from `torchrl.envs`.&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">new_api</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">new_api</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">VecNormV2</span>

            <span class="k">return</span> <span class="n">VecNormV2</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="VecNorm"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">VecNorm</span><span class="p">(</span><span class="n">Transform</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">_VecNormMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Moving average normalization layer for torchrl environments.</span>

<span class="sd">    .. warning:: This class is to be deprecated in favor of :class:`~torchrl.envs.VecNormV2` and will be replaced by</span>
<span class="sd">        that class in v0.10. You can adapt to these changes by using the `new_api` argument or importing the</span>
<span class="sd">        `VecNormV2` class from `torchrl.envs`.</span>

<span class="sd">    VecNorm keeps track of the summary statistics of a dataset to standardize</span>
<span class="sd">    it on-the-fly. If the transform is in &#39;eval&#39; mode, the running</span>
<span class="sd">    statistics are not updated.</span>

<span class="sd">    If multiple processes are running a similar environment, one can pass a</span>
<span class="sd">    TensorDictBase instance that is placed in shared memory: if so, every time</span>
<span class="sd">    the normalization layer is queried it will update the values for all</span>
<span class="sd">    processes that share the same reference.</span>

<span class="sd">    To use VecNorm at inference time and avoid updating the values with the new</span>
<span class="sd">    observations, one should substitute this layer by :meth:`~.to_observation_norm`.</span>
<span class="sd">    This will provide a static version of `VecNorm` which will not be updated</span>
<span class="sd">    when the source transform is updated.</span>
<span class="sd">    To get a frozen copy of the VecNorm layer, see :meth:`~.frozen_copy`.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): keys to be updated.</span>
<span class="sd">            default: [&quot;observation&quot;, &quot;reward&quot;]</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): destination keys.</span>
<span class="sd">            Defaults to ``in_keys``.</span>
<span class="sd">        shared_td (TensorDictBase, optional): A shared tensordict containing the</span>
<span class="sd">            keys of the transform.</span>
<span class="sd">        lock (mp.Lock): a lock to prevent race conditions between processes.</span>
<span class="sd">            Defaults to None (lock created during init).</span>
<span class="sd">        decay (number, optional): decay rate of the moving average.</span>
<span class="sd">            default: 0.99</span>
<span class="sd">        eps (number, optional): lower bound of the running standard</span>
<span class="sd">            deviation (for numerical underflow). Default is 1e-4.</span>
<span class="sd">        shapes (List[torch.Size], optional): if provided, represents the shape</span>
<span class="sd">            of each in_keys. Its length must match the one of ``in_keys``.</span>
<span class="sd">            Each shape must match the trailing dimension of the corresponding</span>
<span class="sd">            entry.</span>
<span class="sd">            If not, the feature dimensions of the entry (ie all dims that do</span>
<span class="sd">            not belong to the tensordict batch-size) will be considered as</span>
<span class="sd">            feature dimension.</span>
<span class="sd">        new_api (bool or None, optional): if ``True``, an instance of VecNormV2 will be returned.</span>
<span class="sd">            If not passed, a warning will be raised.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; t = VecNorm(decay=0.9)</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v0&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(env, t)</span>
<span class="sd">        &gt;&gt;&gt; tds = []</span>
<span class="sd">        &gt;&gt;&gt; for _ in range(1000):</span>
<span class="sd">        ...     td = env.rand_step()</span>
<span class="sd">        ...     if td.get(&quot;done&quot;):</span>
<span class="sd">        ...         _ = env.reset()</span>
<span class="sd">        ...     tds += [td]</span>
<span class="sd">        &gt;&gt;&gt; tds = torch.stack(tds, 0)</span>
<span class="sd">        &gt;&gt;&gt; print((abs(tds.get((&quot;next&quot;, &quot;observation&quot;)).mean(0))&lt;0.2).all())</span>
<span class="sd">        tensor(True)</span>
<span class="sd">        &gt;&gt;&gt; print((abs(tds.get((&quot;next&quot;, &quot;observation&quot;)).std(0)-1)&lt;0.2).all())</span>
<span class="sd">        tensor(True)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shared_td</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lock</span><span class="p">:</span> <span class="n">mp</span><span class="o">.</span><span class="n">Lock</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9999</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">shapes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">new_api</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;This class is to be deprecated in favor of :class:`~torchrl.envs.VecNormV2`.&quot;</span><span class="p">,</span>
            <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">lock</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lock</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="o">=</span> <span class="n">shared_td</span>
        <span class="k">if</span> <span class="n">shared_td</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="n">shared_td</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span> <span class="ow">or</span> <span class="n">shared_td</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;shared_td must be either in shared memory or a memmap &quot;</span> <span class="s2">&quot;tensordict.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">shared_td</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shared_td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                    <span class="ow">or</span> <span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shared_td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                    <span class="ow">or</span> <span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shared_td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> not present in the shared tensordict &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;with keys </span><span class="si">{</span><span class="n">shared_td</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">lock</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span> <span class="o">=</span> <span class="n">decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shapes</span> <span class="o">=</span> <span class="n">shapes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="VecNorm.freeze"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.freeze">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VecNorm</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Freezes the VecNorm, avoiding the stats to be updated when called.</span>

<span class="sd">        See :meth:`~.unfreeze`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="VecNorm.unfreeze"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.unfreeze">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">unfreeze</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VecNorm</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unfreezes the VecNorm.</span>

<span class="sd">        See :meth:`~.freeze`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="VecNorm.frozen_copy"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.frozen_copy">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">frozen_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VecNorm</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a copy of the Transform that keeps track of the stats but does not update them.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure the VecNorm has been initialized before creating a frozen copy.&quot;</span>
            <span class="p">)</span>
        <span class="n">clone</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># replace values</span>
        <span class="n">clone</span><span class="o">.</span><span class="n">_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># freeze</span>
        <span class="k">return</span> <span class="n">clone</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># TODO: remove this decorator when trackers are in data</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lock</span><span class="o">.</span><span class="n">acquire</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">key_out</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="c1"># TODO: init missing rewards with this</span>
                <span class="c1"># for key_suffix in [_append_last(key, suffix) for suffix in (&quot;_sum&quot;, &quot;_ssq&quot;, &quot;_count&quot;)]:</span>
                <span class="c1">#     tensordict.set(key_suffix, self.container.observation_spec[key_suffix].zero())</span>
                <span class="k">continue</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="c1"># update and standardize</span>
            <span class="n">new_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">N</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
            <span class="p">)</span>

            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key_out</span><span class="p">,</span> <span class="n">new_val</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">key</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Conflicting key names: </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> from VecNorm and input tensordict keys.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shapes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">td_view</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">td_select</span> <span class="o">=</span> <span class="n">td_view</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">item</span> <span class="o">=</span> <span class="n">td_select</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">):</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">item</span><span class="p">)}</span>
                <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">):</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">item</span><span class="p">)})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">in_key</span> <span class="o">!=</span> <span class="n">key</span><span class="p">:</span>
                        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shapes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">item</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">):</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">item</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="p">)</span>
                <span class="p">}</span>
                <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">):</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">item</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="p">)</span>
                    <span class="p">}</span>
                <span class="p">)</span>

            <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">):</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span>
                    <span class="p">)</span>
                <span class="p">}</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="p">[])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># TODO: we should revert this and have _td be like: TensorDict{&quot;sum&quot;: ..., &quot;ssq&quot;: ..., &quot;count&quot;...})</span>
        <span class="c1">#  to facilitate the computation of the stats using TD internals.</span>
        <span class="c1">#  Moreover, _td can be locked so these ops will be very fast on CUDA.</span>
        <span class="n">_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">))</span>
        <span class="n">_ssq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">))</span>
        <span class="n">_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">))</span>

        <span class="n">value_sum</span> <span class="o">=</span> <span class="n">_sum_left</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_sum</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
            <span class="n">_sum</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay</span>
            <span class="n">_sum</span> <span class="o">+=</span> <span class="n">value_sum</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span>
                <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">),</span>
                <span class="n">_sum</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">_ssq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">))</span>
        <span class="n">value_ssq</span> <span class="o">=</span> <span class="n">_sum_left</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">_ssq</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
            <span class="n">_ssq</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay</span>
            <span class="n">_ssq</span> <span class="o">+=</span> <span class="n">value_ssq</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span>
                <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">),</span>
                <span class="n">_ssq</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
            <span class="n">_count</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay</span>
            <span class="n">_count</span> <span class="o">+=</span> <span class="n">N</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span>
                <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">),</span>
                <span class="n">_count</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">mean</span> <span class="o">=</span> <span class="n">_sum</span> <span class="o">/</span> <span class="n">_count</span>
        <span class="n">std</span> <span class="o">=</span> <span class="p">(</span><span class="n">_ssq</span> <span class="o">/</span> <span class="n">_count</span> <span class="o">-</span> <span class="n">mean</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

<div class="viewcode-block" id="VecNorm.to_observation_norm"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.to_observation_norm">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_observation_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Compose</span> <span class="o">|</span> <span class="n">ObservationNorm</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts VecNorm into an ObservationNorm class that can be used at inference time.</span>

<span class="sd">        The :class:`~torchrl.envs.ObservationNorm` layer can be updated using the :meth:`~torch.nn.Module.state_dict`</span>
<span class="sd">        API.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import GymEnv, VecNorm</span>
<span class="sd">            &gt;&gt;&gt; vecnorm = VecNorm(in_keys=[&quot;observation&quot;])</span>
<span class="sd">            &gt;&gt;&gt; train_env = GymEnv(&quot;CartPole-v1&quot;, device=None).append_transform(</span>
<span class="sd">            ...     vecnorm)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; r = train_env.rollout(4)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; eval_env = GymEnv(&quot;CartPole-v1&quot;).append_transform(</span>
<span class="sd">            ...     vecnorm.to_observation_norm())</span>
<span class="sd">            &gt;&gt;&gt; print(eval_env.transform.loc, eval_env.transform.scale)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; r = train_env.rollout(4)</span>
<span class="sd">            &gt;&gt;&gt; # Update entries with state_dict</span>
<span class="sd">            &gt;&gt;&gt; eval_env.transform.load_state_dict(</span>
<span class="sd">            ...     vecnorm.to_observation_norm().state_dict())</span>
<span class="sd">            &gt;&gt;&gt; print(eval_env.transform.loc, eval_env.transform.scale)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">key_out</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">_out</span> <span class="o">=</span> <span class="n">ObservationNorm</span><span class="p">(</span>
                <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">),</span>
                <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">),</span>
                <span class="n">standard_normal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
                <span class="n">out_keys</span><span class="o">=</span><span class="n">key_out</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">out</span> <span class="o">+=</span> <span class="p">[</span><span class="n">_out</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Compose</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_out</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_loc_scale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">loc_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scale_only</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">TensorDict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">TensorDict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">_sum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">))</span>
            <span class="n">_ssq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">))</span>
            <span class="n">_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">))</span>
            <span class="n">loc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_sum</span> <span class="o">/</span> <span class="n">_count</span>
            <span class="n">scale</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">_ssq</span> <span class="o">/</span> <span class="n">_count</span> <span class="o">-</span> <span class="n">loc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">scale_only</span><span class="p">:</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">loc_only</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">standard_normal</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether the affine transform given by `loc` and `scale` follows the standard normal equation.</span>

<span class="sd">        Similar to :class:`~torchrl.envs.ObservationNorm` standard_normal attribute.</span>

<span class="sd">        Always returns ``True``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">loc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a TensorDict with the loc to be used for an affine transform.&quot;&quot;&quot;</span>
        <span class="c1"># We can&#39;t cache that value bc the summary stats could be updated by a different process</span>
        <span class="n">loc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loc_scale</span><span class="p">(</span><span class="n">loc_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loc</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a TensorDict with the scale to be used for an affine transform.&quot;&quot;&quot;</span>
        <span class="c1"># We can&#39;t cache that value bc the summary stats could be updated by a different process</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loc_scale</span><span class="p">(</span><span class="n">scale_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scale</span>

<div class="viewcode-block" id="VecNorm.build_td_for_shared_vecnorm"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.build_td_for_shared_vecnorm">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">build_td_for_shared_vecnorm</span><span class="p">(</span>
        <span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span><span class="p">,</span>
        <span class="n">keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">memmap</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates a shared tensordict for normalization across processes.</span>

<span class="sd">        Args:</span>
<span class="sd">            env (EnvBase): example environment to be used to create the</span>
<span class="sd">                tensordict</span>
<span class="sd">            keys (sequence of NestedKey, optional): keys that</span>
<span class="sd">                have to be normalized. Default is `[&quot;next&quot;, &quot;reward&quot;]`</span>
<span class="sd">            memmap (bool): if ``True``, the resulting tensordict will be cast into</span>
<span class="sd">                memmory map (using `memmap_()`). Otherwise, the tensordict</span>
<span class="sd">                will be placed in shared memory.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A memory in shared memory to be sent to each process.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torch import multiprocessing as mp</span>
<span class="sd">            &gt;&gt;&gt; queue = mp.Queue()</span>
<span class="sd">            &gt;&gt;&gt; env = make_env()</span>
<span class="sd">            &gt;&gt;&gt; td_shared = VecNorm.build_td_for_shared_vecnorm(env,</span>
<span class="sd">            ...     [&quot;next&quot;, &quot;reward&quot;])</span>
<span class="sd">            &gt;&gt;&gt; assert td_shared.is_shared()</span>
<span class="sd">            &gt;&gt;&gt; queue.put(td_shared)</span>
<span class="sd">            &gt;&gt;&gt; # on workers</span>
<span class="sd">            &gt;&gt;&gt; v = VecNorm(shared_td=queue.get())</span>
<span class="sd">            &gt;&gt;&gt; env = TransformedEnv(make_env(), v)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;this feature is currently put on hold.&quot;</span><span class="p">)</span>
        <span class="n">sep</span> <span class="o">=</span> <span class="s2">&quot;.-|-.&quot;</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">make_tensordict</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">}</span>
        <span class="n">td_select</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)</span>
        <span class="n">td_select</span> <span class="o">=</span> <span class="n">td_select</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="n">sep</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;VecNorm should be used with non-batched environments. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got batch_size=</span><span class="si">{</span><span class="n">td</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">td_select</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="n">td_select</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_ssq&quot;</span><span class="p">),</span> <span class="n">td_select</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
            <span class="n">td_select</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_count&quot;</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">td</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="mi">1</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">td_select</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="n">td_select</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">_append_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_sum&quot;</span><span class="p">))</span>
        <span class="n">td_select</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="n">td_select</span> <span class="o">=</span> <span class="n">td_select</span><span class="o">.</span><span class="n">unflatten_keys</span><span class="p">(</span><span class="n">sep</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memmap</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">td_select</span><span class="o">.</span><span class="n">memmap_</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td_select</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span></div>

    <span class="c1"># We use a different separator to ensure that keys can have points within them.</span>
    <span class="n">SEP</span> <span class="o">=</span> <span class="s2">&quot;-&lt;.&gt;-&quot;</span>

<div class="viewcode-block" id="VecNorm.get_extra_state"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.get_extra_state">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_extra_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Querying state_dict on an uninitialized VecNorm transform will &quot;</span>
                <span class="s2">&quot;return a `None` value for the summary statistics. &quot;</span>
                <span class="s2">&quot;Loading such a state_dict on an initialized VecNorm will result in &quot;</span>
                <span class="s2">&quot;an error.&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">SEP</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span></div>

<div class="viewcode-block" id="VecNorm.set_extra_state"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.set_extra_state">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_extra_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unflatten_keys</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">SEP</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">td</span><span class="o">.</span><span class="n">is_shared</span><span class="p">():</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;VecNorm wasn&#39;t initialized and the tensordict is not shared. In single &quot;</span>
                    <span class="s2">&quot;process settings, this is ok, but if you need to share the statistics &quot;</span>
                    <span class="s2">&quot;between workers this should require some attention. &quot;</span>
                    <span class="s2">&quot;Make sure that the content of VecNorm is transmitted to the workers &quot;</span>
                    <span class="s2">&quot;after calling load_state_dict and not before, as other workers &quot;</span>
                    <span class="s2">&quot;may not have access to the loaded TensorDict.&quot;</span>
                <span class="p">)</span>
                <span class="n">td</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_td</span><span class="o">.</span><span class="n">update_</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="o">=</span> <span class="n">td</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_td</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;Could not find a tensordict in the state_dict.&quot;</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(decay=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;eps=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">, in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, out_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">()</span>
        <span class="n">_lock</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;lock&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_lock</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;lock_placeholder&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="k">if</span> <span class="s2">&quot;lock_placeholder&quot;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;lock_placeholder&quot;</span><span class="p">)</span>
            <span class="n">_lock</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;lock&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_lock</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

<div class="viewcode-block" id="VecNorm.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Bounded</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Unbounded</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div></div>

    <span class="c1"># TODO: incorporate this when trackers are part of the data</span>
    <span class="c1"># def transform_output_spec(self, output_spec: TensorSpec) -&gt; TensorSpec:</span>
    <span class="c1">#     observation_spec = output_spec[&quot;full_observation_spec&quot;]</span>
    <span class="c1">#     reward_spec = output_spec[&quot;full_reward_spec&quot;]</span>
    <span class="c1">#     for key in list(observation_spec.keys(True, True)):</span>
    <span class="c1">#         if key in self.in_keys:</span>
    <span class="c1">#             observation_spec[_append_last(key, &quot;_sum&quot;)] = observation_spec[key].clone()</span>
    <span class="c1">#             observation_spec[_append_last(key, &quot;_ssq&quot;)] = observation_spec[key].clone()</span>
    <span class="c1">#             observation_spec[_append_last(key, &quot;_count&quot;)] = observation_spec[key].clone()</span>
    <span class="c1">#     for key in list(reward_spec.keys(True, True)):</span>
    <span class="c1">#         if key in self.in_keys:</span>
    <span class="c1">#             observation_spec[_append_last(key, &quot;_sum&quot;)] = reward_spec[key].clone()</span>
    <span class="c1">#             observation_spec[_append_last(key, &quot;_ssq&quot;)] = reward_spec[key].clone()</span>
    <span class="c1">#             observation_spec[_append_last(key, &quot;_count&quot;)] = reward_spec[key].clone()</span>
    <span class="c1">#     return output_spec</span>


<div class="viewcode-block" id="RewardSum"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardSum.html#torchrl.envs.transforms.RewardSum">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RewardSum</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tracks episode cumulative rewards.</span>

<span class="sd">    This transform accepts a list of tensordict reward keys (i.e. &#39;in_keys&#39;) and tracks their cumulative</span>
<span class="sd">    value along the time dimension for each episode.</span>

<span class="sd">    When called, the transform writes a new tensordict entry for each ``in_key`` named</span>
<span class="sd">    ``episode_{in_key}`` where the cumulative values are written.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (list of NestedKeys, optional): Input reward keys.</span>
<span class="sd">            All &#39;in_keys&#39; should be part of the environment reward_spec.</span>
<span class="sd">            If no ``in_keys`` are specified, this transform assumes ``&quot;reward&quot;`` to be the input key.</span>
<span class="sd">            However, multiple rewards (e.g. ``&quot;reward1&quot;`` and ``&quot;reward2&quot;&quot;``) can also be specified.</span>
<span class="sd">        out_keys (list of NestedKeys, optional): The output sum keys, should be one per each input key.</span>
<span class="sd">        reset_keys (list of NestedKeys, optional): the list of reset_keys to be</span>
<span class="sd">            used, if the parent environment cannot be found. If provided, this</span>
<span class="sd">            value will prevail over the environment ``reset_keys``.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        reward_spec (bool, optional): if ``True``, the new reward entry will be registered in the</span>
<span class="sd">            reward specs. Defaults to ``False`` (registered in ``observation_specs``).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.transforms import RewardSum, TransformedEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(GymEnv(&quot;CartPole-v1&quot;), RewardSum())</span>
<span class="sd">        &gt;&gt;&gt; env.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; td = env.reset()</span>
<span class="sd">        &gt;&gt;&gt; print(td[&quot;episode_reward&quot;])</span>
<span class="sd">        tensor([0.])</span>
<span class="sd">        &gt;&gt;&gt; td = env.rollout(3)</span>
<span class="sd">        &gt;&gt;&gt; print(td[&quot;next&quot;, &quot;episode_reward&quot;])</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [2.],</span>
<span class="sd">                [3.]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">reward_spec</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialises the transform. Filters out non-reward input keys and defines output keys.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_keys</span> <span class="o">=</span> <span class="n">reset_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys_checked</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_spec</span> <span class="o">=</span> <span class="n">reward_spec</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_in_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="c1"># retrieve rewards from parent env</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">in_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">return</span> <span class="n">in_keys</span>

    <span class="nd">@in_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_out_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">_replace_last</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;episode_</span><span class="si">{</span><span class="n">_unravel_key_to_tuple</span><span class="p">(</span><span class="n">in_key</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="k">return</span> <span class="n">out_keys</span>

    <span class="nd">@out_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="c1"># we must access the private attribute because this check occurs before</span>
        <span class="c1"># the parent env is defined</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_in_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;RewardSum expects the same number of input and output keys&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">reset_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_reset_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reset_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;reset_keys not provided but parent env not found. &quot;</span>
                    <span class="s2">&quot;Make sure that the reset_keys are provided during &quot;</span>
                    <span class="s2">&quot;construction if the transform does not have a container env.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># let&#39;s try to match the reset keys with the in_keys.</span>
            <span class="c1"># We take the filtered reset keys, which are the only keys that really</span>
            <span class="c1"># matter when calling reset, and check that they match the in_keys root.</span>
            <span class="n">reset_keys</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">reset_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">_check_match</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">,</span> <span class="n">in_keys</span><span class="p">):</span>
                <span class="c1"># if this is called, the length of reset_keys and in_keys must match</span>
                <span class="k">for</span> <span class="n">reset_key</span><span class="p">,</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">,</span> <span class="n">in_keys</span><span class="p">):</span>
                    <span class="c1"># having _reset at the root and the reward_key (&quot;agent&quot;, &quot;reward&quot;) is allowed</span>
                    <span class="c1"># but having (&quot;agent&quot;, &quot;_reset&quot;) and &quot;reward&quot; isn&#39;t</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="k">return</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
                        <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
                        <span class="ow">and</span> <span class="n">in_key</span><span class="p">[:</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reset_key</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">!=</span> <span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="p">):</span>
                        <span class="k">return</span> <span class="kc">False</span>
                <span class="k">return</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_match</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not match the env reset_keys </span><span class="si">{</span><span class="n">reset_keys</span><span class="si">}</span><span class="s2"> with the </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> in_keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Please provide the reset_keys manually. Reset entries can be &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;non-unique and must be right-expandable to the shape of &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;the input entries.&quot;</span>
                <span class="p">)</span>
            <span class="n">reset_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reset_keys</span> <span class="o">=</span> <span class="n">reset_keys</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys_checked</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not match the env reset_keys </span><span class="si">{</span><span class="n">reset_keys</span><span class="si">}</span><span class="s2"> with the in_keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;Please make sure that these have the same length.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys_checked</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="n">reset_keys</span>

    <span class="nd">@reset_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_keys</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets episode rewards.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">reset_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span>
        <span class="p">):</span>
            <span class="n">_reset</span> <span class="o">=</span> <span class="n">_get_reset</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_reward_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">expand_as_right</span><span class="p">(</span><span class="o">~</span><span class="n">_reset</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="n">value</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates the episode rewards with the step rewards.&quot;&quot;&quot;</span>
        <span class="c1"># Update episode rewards</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
                <span class="n">prev_reward</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">prev_reward</span> <span class="o">+</span> <span class="n">reward</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_tolerance</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2">&#39; not found in tensordict </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="RewardSum.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardSum.html#torchrl.envs.transforms.RewardSum.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">state_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">state_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">state_spec</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_episode_reward_spec</span><span class="p">())</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_spec</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_episode_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">episode_reward_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">()</span>
        <span class="n">reward_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_reward_spec</span>
        <span class="n">reward_spec_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span>
        <span class="c1"># Define episode specs for all out_keys</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">in_key</span> <span class="ow">in</span> <span class="n">reward_spec_keys</span>
            <span class="p">):</span>  <span class="c1"># if this out_key has a corresponding key in reward_spec</span>
                <span class="n">out_key</span> <span class="o">=</span> <span class="n">_unravel_key_to_tuple</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
                <span class="n">temp_episode_reward_spec</span> <span class="o">=</span> <span class="n">episode_reward_spec</span>
                <span class="n">temp_rew_spec</span> <span class="o">=</span> <span class="n">reward_spec</span>
                <span class="k">for</span> <span class="n">sub_key</span> <span class="ow">in</span> <span class="n">out_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">temp_rew_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span>
                        <span class="ow">or</span> <span class="n">sub_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">temp_rew_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="p">):</span>
                        <span class="k">break</span>
                    <span class="k">if</span> <span class="n">sub_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">temp_episode_reward_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">temp_episode_reward_spec</span><span class="p">[</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp_rew_spec</span><span class="p">[</span>
                            <span class="n">sub_key</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                    <span class="n">temp_rew_spec</span> <span class="o">=</span> <span class="n">temp_rew_spec</span><span class="p">[</span><span class="n">sub_key</span><span class="p">]</span>
                    <span class="n">temp_episode_reward_spec</span> <span class="o">=</span> <span class="n">temp_episode_reward_spec</span><span class="p">[</span><span class="n">sub_key</span><span class="p">]</span>
                <span class="n">episode_reward_spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_spec</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The in_key: </span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2"> is not present in the reward spec </span><span class="si">{</span><span class="n">reward_spec</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">episode_reward_spec</span>

<div class="viewcode-block" id="RewardSum.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardSum.html#torchrl.envs.transforms.RewardSum.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transforms the observation spec, adding the new keys generated by RewardSum.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_spec</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">observation_spec</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
                <span class="n">observation</span><span class="o">=</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="p">)</span>
        <span class="n">observation_spec</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_episode_reward_spec</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="RewardSum.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardSum.html#torchrl.envs.transforms.RewardSum.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_spec</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">reward_spec</span>
        <span class="n">reward_spec</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_episode_reward_spec</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">reward_spec</span></div>

<div class="viewcode-block" id="RewardSum.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RewardSum.html#torchrl.envs.transforms.RewardSum.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">time_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">names</span><span class="p">)</span> <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;time&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">time_dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;At least one dimension of the tensordict must be named &#39;time&#39; in offline mode&quot;</span>
            <span class="p">)</span>
        <span class="n">time_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="n">in_key</span><span class="p">]</span>
            <span class="n">cumsum</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">time_dim</span><span class="p">)</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">cumsum</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div></div>


<div class="viewcode-block" id="StepCounter"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">StepCounter</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Counts the steps from a reset and optionally sets the truncated state to ``True`` after a certain number of steps.</span>

<span class="sd">    The ``&quot;done&quot;`` state is also adapted accordingly (as done is the disjunction</span>
<span class="sd">    of task completion and early truncation).</span>

<span class="sd">    Args:</span>
<span class="sd">        max_steps (int, optional): a positive integer that indicates the</span>
<span class="sd">            maximum number of steps to take before setting the ``truncated_key``</span>
<span class="sd">            entry to ``True``.</span>
<span class="sd">        truncated_key (str, optional): the key where the truncated entries</span>
<span class="sd">            should be written. Defaults to ``&quot;truncated&quot;``, which is recognised by</span>
<span class="sd">            data collectors as a reset signal.</span>
<span class="sd">            This argument can only be a string (not a nested key) as it will be</span>
<span class="sd">            matched to each of the leaf done key in the parent environment</span>
<span class="sd">            (eg, a ``(&quot;agent&quot;, &quot;done&quot;)`` key will be accompanied by a</span>
<span class="sd">            ``(&quot;agent&quot;, &quot;truncated&quot;)`` if the ``&quot;truncated&quot;`` key name is used).</span>
<span class="sd">        step_count_key (str, optional): the key where the step count entries</span>
<span class="sd">            should be written. Defaults to ``&quot;step_count&quot;``.</span>
<span class="sd">            This argument can only be a string (not a nested key) as it will be</span>
<span class="sd">            matched to each of the leaf done key in the parent environment</span>
<span class="sd">            (eg, a ``(&quot;agent&quot;, &quot;done&quot;)`` key will be accompanied by a</span>
<span class="sd">            ``(&quot;agent&quot;, &quot;step_count&quot;)`` if the ``&quot;step_count&quot;`` key name is used).</span>
<span class="sd">        update_done (bool, optional): if ``True``, the ``&quot;done&quot;`` boolean tensor</span>
<span class="sd">            at the level of ``&quot;truncated&quot;``</span>
<span class="sd">            will be updated.</span>
<span class="sd">            This signal indicates that the trajectory has reached its ends,</span>
<span class="sd">            either because the task is completed (``&quot;completed&quot;`` entry is</span>
<span class="sd">            ``True``) or because it has been truncated (``&quot;truncated&quot;`` entry</span>
<span class="sd">            is ``True``).</span>
<span class="sd">            Defaults to ``True``.</span>

<span class="sd">    .. note:: To ensure compatibility with environments that have multiple</span>
<span class="sd">        done_key(s), this transform will write a step_count entry for</span>
<span class="sd">        every done entry within the tensordict.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import gymnasium</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymWrapper</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymWrapper(gymnasium.make(&quot;Pendulum-v1&quot;))</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env,</span>
<span class="sd">        ...     StepCounter(max_steps=5))</span>
<span class="sd">        &gt;&gt;&gt; rollout = env.rollout(100)</span>
<span class="sd">        &gt;&gt;&gt; print(rollout)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                completed: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        completed: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([5]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(rollout[&quot;next&quot;, &quot;step_count&quot;])</span>
<span class="sd">        tensor([[1],</span>
<span class="sd">                [2],</span>
<span class="sd">                [3],</span>
<span class="sd">                [4],</span>
<span class="sd">                [5]])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">truncated_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;truncated&quot;</span><span class="p">,</span>
        <span class="n">step_count_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;step_count&quot;</span><span class="p">,</span>
        <span class="n">update_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">max_steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_steps should have a value greater or equal to one.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;truncated_key must be a string.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;step_count_key must be a string.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">truncated_key</span> <span class="o">=</span> <span class="n">truncated_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_count_key</span> <span class="o">=</span> <span class="n">step_count_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_done</span> <span class="o">=</span> <span class="n">update_done</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">truncated_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">truncated_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_truncated_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">truncated_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make the default truncated keys</span>
            <span class="n">truncated_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">truncated_key</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">truncated_key</span><span class="p">)</span>
                <span class="n">truncated_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span> <span class="o">=</span> <span class="n">truncated_keys</span>
        <span class="k">return</span> <span class="n">truncated_keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">done_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">done_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_done_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">done_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make the default done keys</span>
            <span class="n">done_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;done&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;done&quot;</span><span class="p">)</span>
                <span class="n">done_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_done_keys&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">done_keys</span>
        <span class="k">return</span> <span class="n">done_keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">terminated_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">terminated_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_terminated_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">terminated_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make the default terminated keys</span>
            <span class="n">terminated_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;terminated&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;terminated&quot;</span><span class="p">)</span>
                <span class="n">terminated_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_terminated_keys&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">terminated_keys</span>
        <span class="k">return</span> <span class="n">terminated_keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">step_count_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">step_count_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_step_count_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">step_count_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make the default step_count keys</span>
            <span class="n">step_count_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_count_key</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_count_key</span><span class="p">)</span>
                <span class="n">step_count_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_step_count_keys&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">step_count_keys</span>
        <span class="k">return</span> <span class="n">step_count_keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span>
        <span class="c1"># fallback on default &quot;_reset&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;_reset&quot;</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">full_done_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># get reset signal</span>
        <span class="k">for</span> <span class="p">(</span>
            <span class="n">step_count_key</span><span class="p">,</span>
            <span class="n">truncated_key</span><span class="p">,</span>
            <span class="n">terminated_key</span><span class="p">,</span>
            <span class="n">reset_key</span><span class="p">,</span>
            <span class="n">done_key</span><span class="p">,</span>
        <span class="p">)</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_count_keys</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">truncated_keys</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">terminated_keys</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">reset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># get done status, just to inform the reset shape, dtype and device</span>
                <span class="k">for</span> <span class="n">entry_name</span> <span class="ow">in</span> <span class="p">(</span><span class="n">terminated_key</span><span class="p">,</span> <span class="n">truncated_key</span><span class="p">,</span> <span class="n">done_key</span><span class="p">):</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">entry_name</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># It may be the case that reset did not provide a done state, in which case</span>
                    <span class="c1"># we fall back on the spec</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec_unbatched</span><span class="p">[</span>
                        <span class="s2">&quot;full_done_spec&quot;</span><span class="p">,</span> <span class="n">entry_name</span>
                    <span class="p">]</span><span class="o">.</span><span class="n">zero</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">done</span><span class="p">)</span>

            <span class="n">step_count</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">step_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">[</span><span class="n">step_count_key</span><span class="p">]</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">step_count</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">reset</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="n">step_count</span> <span class="o">=</span> <span class="n">step_count</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">reset</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># zero the step count if reset is needed</span>
            <span class="n">step_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">reset</span><span class="p">,</span> <span class="n">step_count</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">reset</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">,</span> <span class="n">step_count</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">truncated</span> <span class="o">=</span> <span class="n">step_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span>
                <span class="n">truncated</span> <span class="o">=</span> <span class="n">truncated</span> <span class="o">|</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_done</span><span class="p">:</span>
                    <span class="c1"># we assume no done after reset</span>
                    <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="n">truncated</span><span class="p">)</span>
                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="n">truncated</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">step_count_key</span><span class="p">,</span> <span class="n">truncated_key</span><span class="p">,</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_count_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">truncated_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span>
        <span class="p">):</span>
            <span class="n">step_count</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">)</span>
            <span class="n">next_step_count</span> <span class="o">=</span> <span class="n">step_count</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">,</span> <span class="n">next_step_count</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">truncated</span> <span class="o">=</span> <span class="n">next_step_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span>
                <span class="n">truncated</span> <span class="o">=</span> <span class="n">truncated</span> <span class="o">|</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_done</span><span class="p">:</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                    <span class="c1"># we can have terminated and truncated</span>
                    <span class="c1"># terminated = next_tensordict.get(terminated_key, None)</span>
                    <span class="c1"># if terminated is not None:</span>
                    <span class="c1">#     truncated = truncated &amp; ~terminated</span>

                    <span class="n">done</span> <span class="o">=</span> <span class="n">truncated</span> <span class="o">|</span> <span class="n">done</span>  <span class="c1"># we assume no done after reset</span>
                    <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="n">truncated</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="StepCounter.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;observation_spec was expected to be of type Composite. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">step_count_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_count_keys</span><span class="p">:</span>
            <span class="n">step_count_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">)</span>
            <span class="c1"># find a matching done key (there might be more than one)</span>
            <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                <span class="c1"># check root</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">step_count_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                    <span class="k">break</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not find root of step_count_key </span><span class="si">{</span><span class="n">step_count_key</span><span class="si">}</span><span class="s2"> in done keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">observation_spec</span><span class="p">[</span><span class="n">step_count_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="StepCounter.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span><span class="p">:</span>
            <span class="n">full_done_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">truncated_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">truncated_keys</span><span class="p">:</span>
                <span class="n">truncated_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">)</span>
                <span class="c1"># find a matching done key (there might be more than one)</span>
                <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                    <span class="c1"># check root</span>
                    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">truncated_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                            <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                            <span class="k">break</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                        <span class="k">break</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Could not find root of truncated_key </span><span class="si">{</span><span class="n">truncated_key</span><span class="si">}</span><span class="s2"> in done keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="n">full_done_spec</span><span class="p">[</span><span class="n">truncated_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span>
                    <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">output_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_done</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                    <span class="n">done_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span>
                    <span class="c1"># find a matching done key (there might be more than one)</span>
                    <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                        <span class="c1"># check root</span>
                        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">):</span>
                            <span class="k">continue</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                                <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                                <span class="k">break</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                            <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                            <span class="k">break</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Could not find root of stop_key </span><span class="si">{</span><span class="n">done_key</span><span class="si">}</span><span class="s2"> in done keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>
                    <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span>
                        <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">output_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span>
                    <span class="p">)</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">full_done_spec</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transform_output_spec</span><span class="p">(</span><span class="n">output_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="StepCounter.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;input_spec was expected to be of type Composite. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>

        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">step_count_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_count_keys</span><span class="p">:</span>
            <span class="n">step_count_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">)</span>
            <span class="c1"># find a matching done key (there might be more than one)</span>
            <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                <span class="c1"># check root</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">step_count_key</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">step_count_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                    <span class="k">break</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not find root of step_count_key </span><span class="si">{</span><span class="n">step_count_key</span><span class="si">}</span><span class="s2"> in done keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="n">input_spec</span><span class="p">[</span><span class="n">unravel_key</span><span class="p">((</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">,</span> <span class="n">step_count_key</span><span class="p">))]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">input_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="StepCounter.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;StepCounter cannot be called independently, only its step and reset methods &quot;</span>
            <span class="s2">&quot;are functional. The reason for this is that it is hard to consider using &quot;</span>
            <span class="s2">&quot;StepCounter with non-sequential data, such as those collected by a replay buffer &quot;</span>
            <span class="s2">&quot;or a dataset. If you need StepCounter to work on a batch of sequential data &quot;</span>
            <span class="s2">&quot;(ie as LSTM would work over a whole sequence of data), file an issue on &quot;</span>
            <span class="s2">&quot;TorchRL requesting that feature.&quot;</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="ExcludeTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ExcludeTransform.html#torchrl.envs.transforms.ExcludeTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ExcludeTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Excludes keys from the data.</span>

<span class="sd">    Args:</span>
<span class="sd">        *excluded_keys (iterable of NestedKey): The name of the keys to exclude. If the key is</span>
<span class="sd">            not present, it is simply ignored.</span>
<span class="sd">        inverse (bool, optional): if ``True``, the exclusion will occur during the ``inv`` call.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import gymnasium</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymWrapper</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     GymWrapper(gymnasium.make(&quot;Pendulum-v1&quot;)),</span>
<span class="sd">        ...     ExcludeTransform(&quot;truncated&quot;)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(3)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">excluded_keys</span><span class="p">,</span> <span class="n">inverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">excluded_keys</span> <span class="o">=</span> <span class="n">unravel_key_list</span><span class="p">(</span><span class="n">excluded_keys</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;excluded keys must be a list or tuple of strings or tuples of strings.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">excluded_keys</span> <span class="o">=</span> <span class="n">excluded_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">inverse</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded_keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded_keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded_keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="ExcludeTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ExcludeTransform.html#torchrl.envs.transforms.ExcludeTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span>
            <span class="n">full_done_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
            <span class="n">full_reward_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span>
            <span class="n">full_observation_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">excluded_keys</span><span class="p">:</span>
                <span class="c1"># done_spec</span>
                <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_done_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                    <span class="k">del</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                    <span class="k">continue</span>
                <span class="c1"># reward_spec</span>
                <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_reward_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                    <span class="k">del</span> <span class="n">full_reward_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                    <span class="k">continue</span>
                <span class="c1"># observation_spec</span>
                <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                    <span class="k">del</span> <span class="n">full_observation_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                    <span class="k">continue</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> not found in the environment outputs.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_spec</span></div></div>


<div class="viewcode-block" id="SelectTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.SelectTransform.html#torchrl.envs.transforms.SelectTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">SelectTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select keys from the input tensordict.</span>

<span class="sd">    In general, the :obj:`ExcludeTransform` should be preferred: this transforms also</span>
<span class="sd">        selects the &quot;action&quot; (or other keys from input_spec), &quot;done&quot; and &quot;reward&quot;</span>
<span class="sd">        keys but other may be necessary.</span>

<span class="sd">    Args:</span>
<span class="sd">        *selected_keys (iterable of NestedKey): The name of the keys to select. If the key is</span>
<span class="sd">            not present, it is simply ignored.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        keep_rewards (bool, optional): if ``False``, the reward keys must be provided</span>
<span class="sd">            if they should be kept. Defaults to ``True``.</span>
<span class="sd">        keep_dones (bool, optional): if ``False``, the done keys must be provided</span>
<span class="sd">            if they should be kept. Defaults to ``True``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import gymnasium</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymWrapper</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     GymWrapper(gymnasium.make(&quot;Pendulum-v1&quot;)),</span>
<span class="sd">        ...     SelectTransform(&quot;observation&quot;, &quot;reward&quot;, &quot;done&quot;, keep_dones=False), # we leave done behind</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(3)  # the truncated key is now absent</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">selected_keys</span><span class="p">:</span> <span class="n">NestedKey</span><span class="p">,</span>
        <span class="n">keep_rewards</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">keep_dones</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">selected_keys</span> <span class="o">=</span> <span class="n">unravel_key_list</span><span class="p">(</span><span class="n">selected_keys</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;selected keys must be a list or tuple of strings or tuples of strings.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">selected_keys</span> <span class="o">=</span> <span class="n">selected_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_done_keys</span> <span class="o">=</span> <span class="n">keep_dones</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_reward_keys</span> <span class="o">=</span> <span class="n">keep_rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_reward_keys</span><span class="p">:</span>
            <span class="n">reward_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reward_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_done_keys</span><span class="p">:</span>
            <span class="n">done_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">done_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_keys</span><span class="p">,</span> <span class="o">*</span><span class="n">reward_keys</span><span class="p">,</span> <span class="o">*</span><span class="n">done_keys</span><span class="p">,</span> <span class="o">*</span><span class="n">input_keys</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_reward_keys</span><span class="p">:</span>
            <span class="n">reward_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reward_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_done_keys</span><span class="p">:</span>
            <span class="n">done_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">done_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_keys</span><span class="p">,</span> <span class="o">*</span><span class="n">reward_keys</span><span class="p">,</span> <span class="o">*</span><span class="n">done_keys</span><span class="p">,</span> <span class="o">*</span><span class="n">input_keys</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

<div class="viewcode-block" id="SelectTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.SelectTransform.html#torchrl.envs.transforms.SelectTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
        <span class="n">full_reward_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span>
        <span class="n">full_observation_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_done_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_done_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">selected_keys</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">selected_keys</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">full_observation_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_reward_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_reward_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">selected_keys</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">full_reward_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">output_spec</span></div></div>


<div class="viewcode-block" id="TimeMaxPool"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TimeMaxPool.html#torchrl.envs.transforms.TimeMaxPool">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TimeMaxPool</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Take the maximum value in each position over the last T observations.</span>

<span class="sd">    This transform take the maximum value in each position for all in_keys tensors over the last T time steps.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey, optional): input keys on which the max pool will be applied. Defaults to &quot;observation&quot; if left empty.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): output keys where the output will be written. Defaults to `in_keys` if left empty.</span>
<span class="sd">        T (int, optional): Number of time steps over which to apply max pooling.</span>
<span class="sd">        reset_key (NestedKey, optional): the reset key to be used as partial</span>
<span class="sd">            reset indicator. Must be unique. If not provided, defaults to the</span>
<span class="sd">            only reset key of the parent environment (if it has only one)</span>
<span class="sd">            and raises an exception otherwise.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, TimeMaxPool(in_keys=[&quot;observation&quot;], T=10))</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; env.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; rollout = env.rollout(10)</span>
<span class="sd">        &gt;&gt;&gt; print(rollout[&quot;observation&quot;])  # values should be increasing up until the 10th step</span>
<span class="sd">        tensor([[ 0.0000,  0.0000,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.0000,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.0000,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.0000,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.0216,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.1149,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.1990,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.2749,  0.0000],</span>
<span class="sd">                [ 0.0000,  0.3281,  0.0000],</span>
<span class="sd">                [-0.9290,  0.3702, -0.8978]])</span>

<span class="sd">    .. note:: :class:`~TimeMaxPool` currently only supports ``done`` signal at the root.</span>
<span class="sd">        Nested ``done``, such as those found in MARL settings, are currently not supported.</span>
<span class="sd">        If this feature is needed, please raise an issue on TorchRL repo.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">reset_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">T</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;TimeMaxPoolTransform T parameter should have a value greater or equal to one.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;TimeMaxPoolTransform in_keys and out_keys don&#39;t have the same number of elements&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="n">T</span>
        <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">buffer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_name</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span>
                <span class="n">buffer_name</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">(</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span> <span class="o">=</span> <span class="n">reset_key</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_buffer_name</span><span class="p">(</span><span class="n">in_key</span><span class="p">):</span>
        <span class="n">in_key_str</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">in_key</span>
        <span class="n">buffer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_maxpool_buffer_</span><span class="si">{</span><span class="n">in_key_str</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">buffer_name</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NestedKey</span><span class="p">:</span>
        <span class="n">reset_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_reset_key&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reset_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reset_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reset_keys</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Got more than one reset key in env </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="si">}</span><span class="s2">, cannot infer which one to use. Consider providing the reset key in the </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> constructor.&quot;</span>
                <span class="p">)</span>
            <span class="n">reset_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">reset_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">reset_key</span>

    <span class="nd">@reset_key</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_key</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>

        <span class="n">_reset</span> <span class="o">=</span> <span class="n">_get_reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="n">buffer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_name</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="n">buffer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">_reset</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                <span class="n">_reset_exp</span> <span class="o">=</span> <span class="n">_reset</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="n">_reset</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">buffer</span><span class="p">[</span><span class="n">_reset_exp</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">buffer</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
                <span class="n">val_reset</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">val_prev</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="c1"># if an in_key is missing, we try to copy it from the previous step</span>
                <span class="k">if</span> <span class="n">val_reset</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">val_prev</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">val_prev</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">val_prev</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">val_reset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not find </span><span class="si">{</span><span class="n">in_key</span><span class="si">}</span><span class="s2"> in the reset data.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">,</span> <span class="n">_reset</span><span class="o">=</span><span class="n">_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_missing_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">):</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">size</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
        <span class="n">buffer</span><span class="o">.</span><span class="n">materialize</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">buffer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">_reset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the episode tensordict with max pooled keys.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="c1"># Lazy init of buffers</span>
            <span class="n">buffer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_name</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
            <span class="n">buffer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">):</span>
                <span class="n">buffer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_missing_buffer</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">,</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_reset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># we must use only the reset data</span>
                <span class="n">buffer</span><span class="p">[:,</span> <span class="n">_reset</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">buffer</span><span class="p">[:,</span> <span class="n">_reset</span><span class="p">],</span> <span class="n">shifts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="c1"># add new obs</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">)</span>
                <span class="n">buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">_reset</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">_reset</span><span class="p">]</span>
                <span class="c1"># apply max pooling</span>
                <span class="n">pooled_tensor</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[:,</span> <span class="n">_reset</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">pooled_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">masked_scatter_</span><span class="p">(</span>
                    <span class="n">expand_as_right</span><span class="p">(</span><span class="n">_reset</span><span class="p">,</span> <span class="n">data</span><span class="p">),</span> <span class="n">pooled_tensor</span>
                <span class="p">)</span>
                <span class="c1"># add to tensordict</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">pooled_tensor</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="c1"># shift obs 1 position to the right</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
            <span class="c1"># add new obs</span>
            <span class="n">buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">))</span>
            <span class="c1"># apply max pooling</span>
            <span class="n">pooled_tensor</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># add to tensordict</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">pooled_tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="TimeMaxPool.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TimeMaxPool.html#torchrl.envs.transforms.TimeMaxPool.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="TimeMaxPool.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TimeMaxPool.html#torchrl.envs.transforms.TimeMaxPool.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;TimeMaxPool cannot be called independently, only its step and reset methods &quot;</span>
            <span class="s2">&quot;are functional. The reason for this is that it is hard to consider using &quot;</span>
            <span class="s2">&quot;TimeMaxPool with non-sequential data, such as those collected by a replay buffer &quot;</span>
            <span class="s2">&quot;or a dataset. If you need TimeMaxPool to work on a batch of sequential data &quot;</span>
            <span class="s2">&quot;(ie as LSTM would work over a whole sequence of data), file an issue on &quot;</span>
            <span class="s2">&quot;TorchRL requesting that feature.&quot;</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="RandomCropTensorDict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RandomCropTensorDict.html#torchrl.envs.transforms.RandomCropTensorDict">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RandomCropTensorDict</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A trajectory sub-sampler for ReplayBuffer and modules.</span>

<span class="sd">    Gathers a sub-sequence of a defined length along the last dimension of the input</span>
<span class="sd">    tensordict.</span>
<span class="sd">    This can be used to get cropped trajectories from trajectories sampled</span>
<span class="sd">    from a ReplayBuffer.</span>

<span class="sd">    This transform is primarily designed to be used with replay buffers and modules.</span>
<span class="sd">    Currently, it cannot be used as an environment transform.</span>
<span class="sd">    Do not hesitate to request for this behavior through an issue if this is</span>
<span class="sd">    desired.</span>

<span class="sd">    Args:</span>
<span class="sd">        sub_seq_len (int): the length of the sub-trajectory to sample</span>
<span class="sd">        sample_dim (int, optional): the dimension along which the cropping</span>
<span class="sd">            should occur. Negative dimensions should be preferred to make</span>
<span class="sd">            the transform robust to tensordicts of varying batch dimensions.</span>
<span class="sd">            Defaults to -1 (the default time dimension in TorchRL).</span>
<span class="sd">        mask_key (NestedKey): If provided, this represents the mask key to be looked</span>
<span class="sd">            for when doing the sampling. If provided, it only valid elements will</span>
<span class="sd">            be returned. It is assumed that the mask is a boolean tensor with</span>
<span class="sd">            first True values and then False values, not mixed together.</span>
<span class="sd">            :class:`RandomCropTensorDict` will NOT check that this is respected</span>
<span class="sd">            hence any error caused by an improper mask risks to go unnoticed.</span>
<span class="sd">            Defaults: None (no mask key).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sub_seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sample_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span> <span class="o">=</span> <span class="n">sub_seq_len</span>
        <span class="k">if</span> <span class="n">sample_dim</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;A positive shape has been passed to the RandomCropTensorDict &quot;</span>
                <span class="s2">&quot;constructor. This may have unexpected behaviors when the &quot;</span>
                <span class="s2">&quot;passed tensordicts have inconsistent batch dimensions. &quot;</span>
                <span class="s2">&quot;For context, by convention, TorchRL concatenates time steps &quot;</span>
                <span class="s2">&quot;along the last dimension of the tensordict.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_dim</span> <span class="o">=</span> <span class="n">sample_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_key</span> <span class="o">=</span> <span class="n">mask_key</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="RandomCropTensorDict.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RandomCropTensorDict.html#torchrl.envs.transforms.RandomCropTensorDict.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_dim</span>
        <span class="c1"># shape must have at least one dimension</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot sub-sample from a tensordict with an empty shape.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot sample trajectories of length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span><span class="si">}</span><span class="s2"> along&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; dimension </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> given a tensordict of shape &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Consider reducing the sub_seq_len &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;parameter or increase sample length.&quot;</span>
            <span class="p">)</span>
        <span class="n">max_idx_0</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span>
        <span class="n">idx_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">idx_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">idx_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">max_idx_0</span><span class="p">,</span> <span class="n">idx_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># get the traj length for each entry</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_key</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected a mask of the same shape as the tensordict. Got &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;mask.shape=</span><span class="si">{</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and tensordict.shape=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
            <span class="n">traj_lengths</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_dim</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_dim</span><span class="p">,</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">traj_lengths</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Cannot sample trajectories of length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span><span class="si">}</span><span class="s2"> when the minimum &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;trajectory length is </span><span class="si">{</span><span class="n">traj_lengths</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># take a random number between 0 and traj_lengths - self.sub_seq_len</span>
            <span class="n">idx_0</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">idx_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">traj_lengths</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">arange</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sub_seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">idx_0</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">arange_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndimension</span><span class="p">())]</span>
        <span class="n">arange_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arange</span><span class="p">)</span>
        <span class="n">arange</span> <span class="o">=</span> <span class="n">arange</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">arange_shape</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">idx_0</span> <span class="o">+</span> <span class="n">arange</span>
        <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_dim</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="InitTracker"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.InitTracker.html#torchrl.envs.transforms.InitTracker">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">InitTracker</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reset tracker.</span>

<span class="sd">    This transform populates the step/reset tensordict with a reset tracker entry</span>
<span class="sd">    that is set to ``True`` whenever :meth:`~.reset` is called.</span>

<span class="sd">    Args:</span>
<span class="sd">         init_key (NestedKey, optional): the key to be used for the tracker entry.</span>
<span class="sd">            In case of multiple _reset flags, this key is used as the leaf replacement for each.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(GymEnv(&quot;Pendulum-v1&quot;), InitTracker())</span>
<span class="sd">        &gt;&gt;&gt; td = env.reset()</span>
<span class="sd">        &gt;&gt;&gt; print(td[&quot;is_init&quot;])</span>
<span class="sd">        tensor(True)</span>
<span class="sd">        &gt;&gt;&gt; td = env.rand_step(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td[&quot;next&quot;, &quot;is_init&quot;])</span>
<span class="sd">        tensor(False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;is_init&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;init_key can only be of type str as it will be the leaf key associated to each reset flag.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_key</span> <span class="o">=</span> <span class="n">init_key</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">container</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">EnvBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_keys</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="n">container</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_keys</span>

    <span class="nd">@out_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="k">return</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot set non-empty out-keys when out-keys are defined by the init_key value.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">init_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_init_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">init_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">init_keys</span>
        <span class="n">init_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">init_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_key</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">((</span><span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_key</span><span class="p">))</span>
            <span class="n">init_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">init_key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_keys</span> <span class="o">=</span> <span class="n">init_keys</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_filtered_reset_keys</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">init_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_keys</span><span class="p">:</span>
            <span class="n">done_key</span> <span class="o">=</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">init_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">init_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">device</span>
                <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">init_key</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">reset_key</span><span class="p">,</span> <span class="n">init_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_keys</span><span class="p">):</span>
            <span class="n">_reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_reset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">done_key</span> <span class="o">=</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">init_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">_safe_shape</span>
                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">init_key</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                        <span class="n">shape</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init_val</span> <span class="o">=</span> <span class="n">_reset</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">parent_td</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">tensordict_reset</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">init_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">init_val</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">parent_td</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                    <span class="c1"># unsqueeze, to match the done shape</span>
                    <span class="n">init_val</span> <span class="o">=</span> <span class="n">init_val</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">init_key</span><span class="p">,</span> <span class="n">init_val</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="InitTracker.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.InitTracker.html#torchrl.envs.transforms.InitTracker.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">init_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                <span class="c1"># check root</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">init_key</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">init_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not find root of init_key </span><span class="si">{</span><span class="n">init_key</span><span class="si">}</span><span class="s2"> within done_keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">observation_spec</span><span class="p">[</span><span class="n">init_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span>
                <span class="mi">2</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="InitTracker.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.InitTracker.html#torchrl.envs.transforms.InitTracker.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="RenameTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RenameTransform.html#torchrl.envs.transforms.RenameTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RenameTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform to rename entries in the output tensordict (or input tensordict via the inverse keys).</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (sequence of NestedKey): the entries to rename.</span>
<span class="sd">        out_keys (sequence of NestedKey): the name of the entries after renaming.</span>
<span class="sd">        in_keys_inv (sequence of NestedKey, optional): the entries to rename</span>
<span class="sd">            in the input tensordict, which will be passed to :meth:`EnvBase._step`.</span>
<span class="sd">        out_keys_inv (sequence of NestedKey, optional): the names of the entries</span>
<span class="sd">            in the input tensordict after renaming.</span>
<span class="sd">        create_copy (bool, optional): if ``True``, the entries will be copied</span>
<span class="sd">            with a different name rather than being renamed. This allows for</span>
<span class="sd">            renaming immutable entries such as ``&quot;reward&quot;`` and ``&quot;done&quot;``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     GymEnv(&quot;Pendulum-v1&quot;),</span>
<span class="sd">        ...     RenameTransform([&quot;observation&quot;, ], [&quot;stuff&quot;,], create_copy=False),</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; tensordict = env.rollout(3)</span>
<span class="sd">        &gt;&gt;&gt; print(tensordict)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        stuff: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                stuff: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; # if the output is also an input, we need to rename if both ways:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.brax import BraxEnv</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     BraxEnv(&quot;fast&quot;),</span>
<span class="sd">        ...     RenameTransform([&quot;state&quot;], [&quot;newname&quot;], [&quot;state&quot;], [&quot;newname&quot;])</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; _ = env.set_seed(1)</span>
<span class="sd">        &gt;&gt;&gt; tensordict = env.rollout(3)</span>
<span class="sd">        &gt;&gt;&gt; assert &quot;newname&quot; in tensordict.keys()</span>
<span class="sd">        &gt;&gt;&gt; assert &quot;state&quot; not in tensordict.keys()</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">,</span> <span class="n">in_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">create_copy</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span> <span class="o">=</span> <span class="n">create_copy</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">,</span> <span class="n">in_keys_inv</span><span class="p">,</span> <span class="n">out_keys_inv</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The number of in_keys (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">) should match the number of out_keys (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The number of in_keys_inv (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">)</span><span class="si">}</span><span class="s2">) should match the number of out_keys_inv (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">out_keys</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot have matching in and out_keys because order is unclear. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Please use separated transforms. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got in_keys=</span><span class="si">{</span><span class="n">in_keys</span><span class="si">}</span><span class="s2"> and out_keys=</span><span class="si">{</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span><span class="p">:</span>
                        <span class="k">raise</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">next_tensordict</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span><span class="p">:</span>
                        <span class="k">raise</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># no in-place modif</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">in_key</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span><span class="p">:</span>
                        <span class="k">raise</span>

            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">rename_key_</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">in_key</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_tolerance</span><span class="p">:</span>
                        <span class="k">raise</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="RenameTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RenameTransform.html#torchrl.envs.transforms.RenameTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>  <span class="c1"># noqa: B007</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">done_key</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># unreachable</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">][</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">][</span>
                    <span class="n">done_key</span>
                <span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">][</span><span class="n">done_key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">reward_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">reward_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>  <span class="c1"># noqa: B007</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">reward_key</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># unreachable</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">][</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span>
                    <span class="s2">&quot;full_reward_spec&quot;</span>
                <span class="p">][</span><span class="n">reward_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">][</span><span class="n">reward_key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">observation_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">observation_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">):</span>  <span class="c1"># noqa: B007</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">observation_key</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># unreachable</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">][</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span>
                    <span class="s2">&quot;full_observation_spec&quot;</span>
                <span class="p">][</span><span class="n">observation_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">][</span><span class="n">observation_key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

<div class="viewcode-block" id="RenameTransform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RenameTransform.html#torchrl.envs.transforms.RenameTransform.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">action_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>  <span class="c1"># noqa: B007</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">action_key</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># unreachable</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span>
                <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">][</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span>
                    <span class="s2">&quot;full_action_spec&quot;</span>
                <span class="p">][</span><span class="n">action_key</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">action_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">][</span><span class="n">action_key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">state_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">state_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>  <span class="c1"># noqa: B007</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">state_key</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># unreachable</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span>
                <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">][</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">][</span>
                    <span class="n">state_key</span>
                <span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_copy</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">state_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">state_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">][</span><span class="n">state_key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">input_spec</span></div></div>


<div class="viewcode-block" id="Reward2GoTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Reward2GoTransform.html#torchrl.envs.transforms.Reward2GoTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Reward2GoTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates the reward to go based on the episode reward and a discount factor.</span>

<span class="sd">    As the :class:`~.Reward2GoTransform` is only an inverse transform the ``in_keys`` will be directly used for the ``in_keys_inv``.</span>
<span class="sd">    The reward-to-go can be only calculated once the episode is finished. Therefore, the transform should be applied to the replay buffer</span>
<span class="sd">    and not to the collector or within an environment.</span>

<span class="sd">    Args:</span>
<span class="sd">        gamma (:obj:`float` or torch.Tensor): the discount factor. Defaults to 1.0.</span>
<span class="sd">        in_keys (sequence of NestedKey): the entries to rename. Defaults to</span>
<span class="sd">            ``(&quot;next&quot;, &quot;reward&quot;)`` if none is provided.</span>
<span class="sd">        out_keys (sequence of NestedKey): the entries to rename. Defaults to</span>
<span class="sd">            the values of ``in_keys`` if none is provided.</span>
<span class="sd">        done_key (NestedKey): the done entry. Defaults to ``&quot;done&quot;``.</span>
<span class="sd">        truncated_key (NestedKey): the truncated entry. Defaults to ``&quot;truncated&quot;``.</span>
<span class="sd">            If no truncated entry is found, only the ``&quot;done&quot;`` will be used.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Using this transform as part of a replay buffer</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import ReplayBuffer, LazyTensorStorage</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; r2g = Reward2GoTransform(gamma=0.99, out_keys=[&quot;reward_to_go&quot;])</span>
<span class="sd">        &gt;&gt;&gt; rb = ReplayBuffer(storage=LazyTensorStorage(100), transform=r2g)</span>
<span class="sd">        &gt;&gt;&gt; batch, timesteps = 4, 5</span>
<span class="sd">        &gt;&gt;&gt; done = torch.zeros(batch, timesteps, 1, dtype=torch.bool)</span>
<span class="sd">        &gt;&gt;&gt; for i in range(batch):</span>
<span class="sd">        ...     while not done[i].any():</span>
<span class="sd">        ...         done[i] = done[i].bernoulli_(0.1)</span>
<span class="sd">        &gt;&gt;&gt; reward = torch.ones(batch, timesteps, 1)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(</span>
<span class="sd">        ...     {&quot;next&quot;: {&quot;done&quot;: done, &quot;reward&quot;: reward}},</span>
<span class="sd">        ...     [batch, timesteps],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; rb.extend(td)</span>
<span class="sd">        &gt;&gt;&gt; sample = rb.sample(1)</span>
<span class="sd">        &gt;&gt;&gt; print(sample[&quot;next&quot;, &quot;reward&quot;])</span>
<span class="sd">        tensor([[[1.],</span>
<span class="sd">                 [1.],</span>
<span class="sd">                 [1.],</span>
<span class="sd">                 [1.],</span>
<span class="sd">                 [1.]]])</span>
<span class="sd">        &gt;&gt;&gt; print(sample[&quot;reward_to_go&quot;])</span>
<span class="sd">        tensor([[[4.9010],</span>
<span class="sd">                 [3.9404],</span>
<span class="sd">                 [2.9701],</span>
<span class="sd">                 [1.9900],</span>
<span class="sd">                 [1.0000]]])</span>

<span class="sd">    One can also use this transform directly with a collector: make sure to</span>
<span class="sd">    append the `inv` method of the transform.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.utils import RandomPolicy        &gt;&gt;&gt; from torchrl.collectors import SyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; t = Reward2GoTransform(gamma=0.99, out_keys=[&quot;reward_to_go&quot;])</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; collector = SyncDataCollector(</span>
<span class="sd">        ...     env,</span>
<span class="sd">        ...     RandomPolicy(env.action_spec),</span>
<span class="sd">        ...     frames_per_batch=200,</span>
<span class="sd">        ...     total_frames=-1,</span>
<span class="sd">        ...     postproc=t.inv</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; for data in collector:</span>
<span class="sd">        ...     break</span>
<span class="sd">        &gt;&gt;&gt; print(data)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                reward_to_go: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    Using this transform as part of an env will raise an exception</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; t = Reward2GoTransform(gamma=0.99)</span>
<span class="sd">        &gt;&gt;&gt; TransformedEnv(GymEnv(&quot;Pendulum-v1&quot;), t)  # crashes</span>

<span class="sd">    .. note:: In settings where multiple done entries are present, one should build</span>
<span class="sd">        a single :class:`~Reward2GoTransform` for each done-reward pair.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ENV_ERR</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;The Reward2GoTransform is only an inverse transform and can &quot;</span>
        <span class="s2">&quot;only be applied to the replay buffer.&quot;</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">done_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;done&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="c1"># out_keys = [&quot;reward_to_go&quot;]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">in_keys_inv</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys_inv</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done_key</span> <span class="o">=</span> <span class="n">done_key</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ENV_ERR</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_key</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;No episode ends found to calculate the reward to go. Make sure that the number of frames_per_batch is larger than number of steps per episode.&quot;</span>
            <span class="p">)</span>
        <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">in_key</span><span class="p">,</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">in_key</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_apply_transform</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">in_key</span><span class="p">),</span> <span class="n">done</span><span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not find any of the input keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="Reward2GoTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Reward2GoTransform.html#torchrl.envs.transforms.Reward2GoTransform.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ENV_ERR</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">done</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.objectives.value.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">reward2go</span>

        <span class="k">return</span> <span class="n">reward2go</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">container</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">container</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">)</span> <span class="ow">or</span> <span class="n">container</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ENV_ERR</span><span class="p">)</span></div>


<div class="viewcode-block" id="ActionMask"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ActionMask.html#torchrl.envs.transforms.ActionMask">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ActionMask</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An adaptive action masker.</span>

<span class="sd">    This transform is useful to ensure that randomly generated actions</span>
<span class="sd">    respect legal actions, by masking the action specs.</span>
<span class="sd">    It reads the mask from the input tensordict after the step is executed,</span>
<span class="sd">    and adapts the mask of the finite action spec.</span>

<span class="sd">      .. note:: This transform will fail when used without an environment.</span>

<span class="sd">    Args:</span>
<span class="sd">        action_key (NestedKey, optional): the key where the action tensor can be found.</span>
<span class="sd">            Defaults to ``&quot;action&quot;``.</span>
<span class="sd">        mask_key (NestedKey, optional): the key where the action mask can be found.</span>
<span class="sd">            Defaults to ``&quot;action_mask&quot;``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.tensor_specs import Categorical, Binary, Unbounded, Composite</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.transforms import ActionMask, TransformedEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.common import EnvBase</span>
<span class="sd">        &gt;&gt;&gt; class MaskedEnv(EnvBase):</span>
<span class="sd">        ...     def __init__(self, *args, **kwargs):</span>
<span class="sd">        ...         super().__init__(*args, **kwargs)</span>
<span class="sd">        ...         self.action_spec = Categorical(4)</span>
<span class="sd">        ...         self.state_spec = Composite(action_mask=Binary(4, dtype=torch.bool))</span>
<span class="sd">        ...         self.observation_spec = Composite(obs=Unbounded(3))</span>
<span class="sd">        ...         self.reward_spec = Unbounded(1)</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _reset(self, tensordict=None):</span>
<span class="sd">        ...         td = self.observation_spec.rand()</span>
<span class="sd">        ...         td.update(torch.ones_like(self.state_spec.rand()))</span>
<span class="sd">        ...         return td</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _step(self, data):</span>
<span class="sd">        ...         td = self.observation_spec.rand()</span>
<span class="sd">        ...         mask = data.get(&quot;action_mask&quot;)</span>
<span class="sd">        ...         action = data.get(&quot;action&quot;)</span>
<span class="sd">        ...         mask = mask.scatter(-1, action.unsqueeze(-1), 0)</span>
<span class="sd">        ...</span>
<span class="sd">        ...         td.set(&quot;action_mask&quot;, mask)</span>
<span class="sd">        ...         td.set(&quot;reward&quot;, self.reward_spec.rand())</span>
<span class="sd">        ...         td.set(&quot;done&quot;, ~mask.any().view(1))</span>
<span class="sd">        ...         return td</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _set_seed(self, seed) -&gt; None:</span>
<span class="sd">        ...         pass</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; base_env = MaskedEnv()</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, ActionMask())</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(10)</span>
<span class="sd">        &gt;&gt;&gt; r[&quot;action_mask&quot;]</span>
<span class="sd">        tensor([[ True,  True,  True,  True],</span>
<span class="sd">                [ True,  True, False,  True],</span>
<span class="sd">                [ True,  True, False, False],</span>
<span class="sd">                [ True, False, False, False]])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ACCEPTED_SPECS</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">OneHot</span><span class="p">,</span>
        <span class="n">Categorical</span><span class="p">,</span>
        <span class="n">MultiOneHot</span><span class="p">,</span>
        <span class="n">MultiCategorical</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">SPEC_TYPE_ERROR</span> <span class="o">=</span> <span class="s2">&quot;The action spec must be one of </span><span class="si">{}</span><span class="s2">. Got </span><span class="si">{}</span><span class="s2"> instead.&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">action_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;action_mask&quot;</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_key</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The action key must be a nested key. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">action_key</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_key</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The mask key must be a nested key. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">mask_key</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="n">action_key</span><span class="p">,</span> <span class="n">mask_key</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[],</span> <span class="n">in_keys_inv</span><span class="o">=</span><span class="p">[],</span> <span class="n">out_keys_inv</span><span class="o">=</span><span class="p">[]</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ActionMask.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ActionMask.html#torchrl.envs.transforms.ActionMask.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)))</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">action_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="o">.</span><span class="n">full_action_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_spec</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ACCEPTED_SPECS</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">SPEC_TYPE_ERROR</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ACCEPTED_SPECS</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">action_spec</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">action_spec</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">.parent cannot be None: make sure this transform is executed within an environment.&quot;</span>
            <span class="p">)</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">update_mask</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span></div>


<div class="viewcode-block" id="VecGymEnvTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecGymEnvTransform.html#torchrl.envs.transforms.VecGymEnvTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">VecGymEnvTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform for GymWrapper subclasses that handles the auto-reset in a consistent way.</span>

<span class="sd">    Gym, gymnasium and SB3 provide vectorized (read, parallel or batched) environments</span>
<span class="sd">    that are automatically reset. When this occurs, the actual observation resulting</span>
<span class="sd">    from the action is saved within a key in the info.</span>
<span class="sd">    The class :class:`torchrl.envs.libs.gym.terminal_obs_reader` reads that observation</span>
<span class="sd">    and stores it in a ``&quot;final&quot;`` key within the output tensordict.</span>
<span class="sd">    In turn, this transform reads that final data, swaps it with the observation</span>
<span class="sd">    written in its place that results from the actual reset, and saves the</span>
<span class="sd">    reset output in a private container. The resulting data truly reflects</span>
<span class="sd">    the output of the step.</span>

<span class="sd">    This class works from gym 0.13 till the most recent gymnasium version.</span>

<span class="sd">    .. note:: Gym versions &lt; 0.22 did not return the final observations. For these,</span>
<span class="sd">        we simply fill the next observations with NaN (because it is lost) and</span>
<span class="sd">        do the swap at the next step.</span>

<span class="sd">    Then, when calling `env.reset`, the saved data is written back where it belongs</span>
<span class="sd">    (and the `reset` is a no-op).</span>

<span class="sd">    This transform is automatically appended to the gym env whenever the wrapper</span>
<span class="sd">    is created with an async env.</span>

<span class="sd">    Args:</span>
<span class="sd">        final_name (str, optional): the name of the final observation in the dict.</span>
<span class="sd">            Defaults to `&quot;final&quot;`.</span>
<span class="sd">        missing_obs_value (Any, optional): default value to use as placeholder for missing</span>
<span class="sd">            last observations. Defaults to `np.nan`.</span>

<span class="sd">    .. note:: In general, this class should not be handled directly. It is</span>
<span class="sd">        created whenever a vectorized environment is placed within a :class:`GymWrapper`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;final&quot;</span><span class="p">,</span> <span class="n">missing_obs_value</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_name</span> <span class="o">=</span> <span class="n">final_name</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_memo</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">missing_obs_value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">missing_obs_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">missing_obs_value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">missing_obs_value</span> <span class="o">=</span> <span class="n">missing_obs_value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_container</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">container</span><span class="p">:</span> <span class="n">Transform</span> <span class="o">|</span> <span class="n">EnvBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_container</span><span class="p">(</span><span class="n">container</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_done_keys</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obs_keys</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># save the final info</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
            <span class="c1"># we assume dones can be broadcast</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">done</span> <span class="o">|</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not find any done signal in tensordict:</span><span class="se">\n</span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_memo</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">done</span>
        <span class="n">final</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="c1"># if anything&#39;s done, we need to swap the final obs</span>
        <span class="k">if</span> <span class="n">done</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">final</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">saved_next</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">final</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">next_tensordict</span><span class="p">[</span><span class="n">done</span><span class="p">]</span> <span class="o">=</span> <span class="n">final</span><span class="p">[</span><span class="n">done</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">saved_next</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_keys</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">obs_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_keys</span><span class="p">:</span>
                    <span class="n">next_tensordict</span><span class="p">[</span><span class="n">obs_key</span><span class="p">][</span><span class="n">done</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">missing_obs_value</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_memo</span><span class="p">[</span><span class="s2">&quot;saved_next&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">saved_next</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memo</span><span class="p">[</span><span class="s2">&quot;saved_next&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memo</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_reset&quot;</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">reset</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">reset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">done</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">reset</span> <span class="o">!=</span> <span class="n">done</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
            <span class="c1"># it can happen that all are reset, in which case</span>
            <span class="c1"># it&#39;s fine (doesn&#39;t need to match done)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">reset</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot partially reset a gym(nasium) async env with a &quot;</span>
                <span class="s2">&quot;reset mask that does not match the done mask. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got reset=</span><span class="si">{</span><span class="n">reset</span><span class="si">}</span><span class="se">\n</span><span class="s2">and done=</span><span class="si">{</span><span class="n">done</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="c1"># if not reset.any(), we don&#39;t need to do anything.</span>
        <span class="c1"># if reset.all(), we don&#39;t either (bc GymWrapper will call a plain reset).</span>
        <span class="k">if</span> <span class="n">reset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">reset</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">reset</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                <span class="c1"># We&#39;re fine: this means that a full reset was passed and the</span>
                <span class="c1"># env was manually reset</span>
                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">tensordict_reset</span>
            <span class="n">saved_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memo</span><span class="p">[</span><span class="s2">&quot;saved_next&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">saved_next</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Did not find a saved tensordict while the reset mask was &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;not empty: reset=</span><span class="si">{</span><span class="n">reset</span><span class="si">}</span><span class="s2">. Done was </span><span class="si">{</span><span class="n">done</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># reset = reset.view(tensordict.shape)</span>
            <span class="c1"># we have a data container from the previous call to step</span>
            <span class="c1"># that contains part of the observation we need.</span>
            <span class="c1"># We can safely place them back in the reset result tensordict:</span>
            <span class="c1"># in env.rollout(), the result of reset() is assumed to be just</span>
            <span class="c1"># the td from previous step with updated values from reset.</span>
            <span class="c1"># In our case, it will always be the case that all these values</span>
            <span class="c1"># are properly set.</span>
            <span class="c1"># collectors even take care of doing an extra masking so it&#39;s even</span>
            <span class="c1"># safer.</span>
            <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">saved_next</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                <span class="c1"># Make sure that all done are False</span>
                <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="p">(</span><span class="o">*</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">done_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_done_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span>
            <span class="c1"># we just want the &quot;done&quot; key</span>
            <span class="n">_done_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span><span class="p">,)</span>
                <span class="k">if</span> <span class="n">key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;done&quot;</span><span class="p">:</span>
                    <span class="n">_done_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">_done_keys</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Could not find a &#39;done&#39; key in the env specs.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_done_keys</span> <span class="o">=</span> <span class="n">_done_keys</span>
        <span class="k">return</span> <span class="n">keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">obs_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_obs_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_obs_keys</span> <span class="o">=</span> <span class="n">keys</span>
        <span class="k">return</span> <span class="n">keys</span>

<div class="viewcode-block" id="VecGymEnvTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecGymEnvTransform.html#torchrl.envs.transforms.VecGymEnvTransform.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_name</span> <span class="ow">in</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">del</span> <span class="n">observation_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">final_name</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="VecGymEnvTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.VecGymEnvTransform.html#torchrl.envs.transforms.VecGymEnvTransform.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)))</span></div></div>


<div class="viewcode-block" id="BurnInTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BurnInTransform.html#torchrl.envs.transforms.BurnInTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">BurnInTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform to partially burn-in data sequences.</span>

<span class="sd">    This transform is useful to obtain up-to-date recurrent states when</span>
<span class="sd">    they are not available. It burns-in a number of steps along the time dimension</span>
<span class="sd">    from sampled sequential data slices and returns the remaining data sequence with</span>
<span class="sd">    the burnt-in data in its initial time step. This transform is intended to be used as a</span>
<span class="sd">    replay buffer transform, not as an environment transform.</span>

<span class="sd">    Args:</span>
<span class="sd">        modules (sequence of TensorDictModule): A list of modules used to burn-in data sequences.</span>
<span class="sd">        burn_in (int): The number of time steps to burn in.</span>
<span class="sd">        out_keys (sequence of NestedKey, optional): destination keys. Defaults to</span>
<span class="sd">        all the modules `out_keys` that point to the next time step (e.g. `&quot;hidden&quot;` if `</span>
<span class="sd">        (&quot;next&quot;, &quot;hidden&quot;)` is part of the `out_keys` of a module).</span>

<span class="sd">    .. note::</span>
<span class="sd">        This transform expects as inputs TensorDicts with its last dimension being the</span>
<span class="sd">        time dimension. It also assumes that all provided modules can process</span>
<span class="sd">        sequential data.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.transforms import BurnInTransform</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import GRUModule</span>
<span class="sd">        &gt;&gt;&gt; gru_module = GRUModule(</span>
<span class="sd">        ...     input_size=10,</span>
<span class="sd">        ...     hidden_size=10,</span>
<span class="sd">        ...     in_keys=[&quot;observation&quot;, &quot;hidden&quot;],</span>
<span class="sd">        ...     out_keys=[&quot;intermediate&quot;, (&quot;next&quot;, &quot;hidden&quot;)],</span>
<span class="sd">        ...     default_recurrent_mode=True,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; burn_in_transform = BurnInTransform(</span>
<span class="sd">        ...     modules=[gru_module],</span>
<span class="sd">        ...     burn_in=5,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({</span>
<span class="sd">        ...     &quot;observation&quot;: torch.randn(2, 10, 10),</span>
<span class="sd">        ...      &quot;hidden&quot;: torch.randn(2, 10, gru_module.gru.num_layers, 10),</span>
<span class="sd">        ...      &quot;is_init&quot;: torch.zeros(2, 10, 1),</span>
<span class="sd">        ... }, batch_size=[2, 10])</span>
<span class="sd">        &gt;&gt;&gt; td = burn_in_transform(td)</span>
<span class="sd">        &gt;&gt;&gt; td.shape</span>
<span class="sd">        torch.Size([2, 5])</span>
<span class="sd">        &gt;&gt;&gt; td.get(&quot;hidden&quot;).abs().sum()</span>
<span class="sd">        tensor(86.3008)</span>

<span class="sd">        &gt;&gt;&gt; from torchrl.data import LazyMemmapStorage, TensorDictReplayBuffer</span>
<span class="sd">        &gt;&gt;&gt; buffer = TensorDictReplayBuffer(</span>
<span class="sd">        ...     storage=LazyMemmapStorage(2),</span>
<span class="sd">        ...     batch_size=1,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; buffer.append_transform(burn_in_transform)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({</span>
<span class="sd">        ...     &quot;observation&quot;: torch.randn(2, 10, 10),</span>
<span class="sd">        ...      &quot;hidden&quot;: torch.randn(2, 10, gru_module.gru.num_layers, 10),</span>
<span class="sd">        ...      &quot;is_init&quot;: torch.zeros(2, 10, 1),</span>
<span class="sd">        ... }, batch_size=[2, 10])</span>
<span class="sd">        &gt;&gt;&gt; buffer.extend(td)</span>
<span class="sd">        &gt;&gt;&gt; td = buffer.sample(1)</span>
<span class="sd">        &gt;&gt;&gt; td.shape</span>
<span class="sd">        torch.Size([1, 5])</span>
<span class="sd">        &gt;&gt;&gt; td.get(&quot;hidden&quot;).abs().sum()</span>
<span class="sd">        tensor(37.0344)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invertible</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">modules</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TensorDictModuleBase</span><span class="p">],</span>
        <span class="n">burn_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">modules</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;All modules must be TensorDictModules, but a </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span><span class="si">}</span><span class="s2"> was provided.&quot;</span>
                <span class="p">)</span>

        <span class="n">in_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
            <span class="n">in_keys</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;next&quot;</span><span class="p">:</span>
                        <span class="n">out_keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_keys_</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;next&quot;</span><span class="p">:</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The &#39;next&#39; key is not needed in the BurnInTransform `out_key` </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> and &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;will be ignored. This transform already assumes that `out_keys` will be &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;retrieved from the next time step of the burnt-in data.&quot;</span>
                    <span class="p">)</span>
                <span class="n">out_keys_</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys_</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modules</span> <span class="o">=</span> <span class="n">modules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span> <span class="o">=</span> <span class="n">burn_in</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;BurnInTransform can only be appended to a ReplayBuffer&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;BurnInTransform can only be appended to a ReplayBuffer.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="BurnInTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BurnInTransform.html#torchrl.envs.transforms.BurnInTransform.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span>

        <span class="n">td_device</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="o">*</span><span class="n">extra_dims</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span>

        <span class="c1"># Split the tensor dict into burn-in data and the rest.</span>
        <span class="n">td_burn_in</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span><span class="p">]</span>
        <span class="n">td_out</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span> <span class="p">:]</span>

        <span class="c1"># Burn in the recurrent state.</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                <span class="n">module_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span> <span class="ow">or</span> <span class="kc">None</span>
                <span class="n">td_burn_in</span> <span class="o">=</span> <span class="n">td_burn_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">module_device</span><span class="p">)</span>
                <span class="n">td_burn_in</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">td_burn_in</span><span class="p">)</span>
        <span class="n">td_burn_in</span> <span class="o">=</span> <span class="n">td_burn_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">td_device</span><span class="p">)</span>

        <span class="c1"># Update out TensorDict with the burnt-in data.</span>
        <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">out_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td_out</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="n">include_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">td_out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">out_key</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span><span class="p">,</span> <span class="o">*</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="n">td_out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">][</span><span class="n">out_key</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">td_burn_in</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">out_key</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">td_out</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(burn_in=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span><span class="si">}</span><span class="s2">, in_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="si">}</span><span class="s2">, out_keys=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="SignTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.SignTransform.html#torchrl.envs.transforms.SignTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">SignTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform to compute the signs of TensorDict values.</span>

<span class="sd">    This transform reads the tensors in ``in_keys`` and ``in_keys_inv``, computes the</span>
<span class="sd">    signs of their elements and writes the resulting sign tensors to ``out_keys`` and</span>
<span class="sd">    ``out_keys_inv`` respectively.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (list of NestedKeys): input entries (read)</span>
<span class="sd">        out_keys (list of NestedKeys): input entries (write)</span>
<span class="sd">        in_keys_inv (list of NestedKeys): input entries (read) during :meth:`~.inv` calls.</span>
<span class="sd">        out_keys_inv (list of NestedKeys): input entries (write) during :meth:`~.inv` calls.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv, TransformedEnv, SignTransform</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, SignTransform(in_keys=[&#39;observation&#39;]))</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(100)</span>
<span class="sd">        &gt;&gt;&gt; obs = r[&quot;observation&quot;]</span>
<span class="sd">        &gt;&gt;&gt; assert (torch.logical_or(torch.logical_or(obs == -1, obs == 1), obs == 0.0)).all()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">in_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys_inv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">out_keys_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys_inv</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">,</span> <span class="n">in_keys_inv</span><span class="p">,</span> <span class="n">out_keys_inv</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>

<div class="viewcode-block" id="SignTransform.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.SignTransform.html#torchrl.envs.transforms.SignTransform.transform_observation_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Bounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="SignTransform.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.SignTransform.html#torchrl.envs.transforms.SignTransform.transform_reward_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">:</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
                    <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                    <span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">_set_missing_tolerance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="RemoveEmptySpecs"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.html#torchrl.envs.transforms.RemoveEmptySpecs">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RemoveEmptySpecs</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Removes empty specs and content from an environment.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import Unbounded, Composite, \</span>
<span class="sd">        ...     Categorical</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import EnvBase, TransformedEnv, RemoveEmptySpecs</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; class DummyEnv(EnvBase):</span>
<span class="sd">        ...     def __init__(self, *args, **kwargs):</span>
<span class="sd">        ...         super().__init__(*args, **kwargs)</span>
<span class="sd">        ...         self.observation_spec = Composite(</span>
<span class="sd">        ...             observation=UnboundedContinuous((*self.batch_size, 3)),</span>
<span class="sd">        ...             other=Composite(</span>
<span class="sd">        ...                 another_other=Composite(shape=self.batch_size),</span>
<span class="sd">        ...                 shape=self.batch_size,</span>
<span class="sd">        ...             ),</span>
<span class="sd">        ...             shape=self.batch_size,</span>
<span class="sd">        ...         )</span>
<span class="sd">        ...         self.action_spec = UnboundedContinuous((*self.batch_size, 3))</span>
<span class="sd">        ...         self.done_spec = Categorical(</span>
<span class="sd">        ...             2, (*self.batch_size, 1), dtype=torch.bool</span>
<span class="sd">        ...         )</span>
<span class="sd">        ...         self.full_done_spec[&quot;truncated&quot;] = self.full_done_spec[</span>
<span class="sd">        ...             &quot;terminated&quot;].clone()</span>
<span class="sd">        ...         self.reward_spec = Composite(</span>
<span class="sd">        ...             reward=UnboundedContinuous(*self.batch_size, 1),</span>
<span class="sd">        ...             other_reward=Composite(shape=self.batch_size),</span>
<span class="sd">        ...             shape=self.batch_size</span>
<span class="sd">        ...             )</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _reset(self, tensordict):</span>
<span class="sd">        ...         return self.observation_spec.rand().update(self.full_done_spec.zero())</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _step(self, tensordict):</span>
<span class="sd">        ...         return TensorDict(</span>
<span class="sd">        ...             {},</span>
<span class="sd">        ...             batch_size=[]</span>
<span class="sd">        ...         ).update(self.observation_spec.rand()).update(</span>
<span class="sd">        ...             self.full_done_spec.zero()</span>
<span class="sd">        ...             ).update(self.full_reward_spec.rand())</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _set_seed(self, seed) -&gt; None:</span>
<span class="sd">        ...         pass</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; base_env = DummyEnv()</span>
<span class="sd">        &gt;&gt;&gt; print(base_env.rollout(2))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        other: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                another_other: TensorDict(</span>
<span class="sd">                                    fields={</span>
<span class="sd">                                    },</span>
<span class="sd">                                    batch_size=torch.Size([2]),</span>
<span class="sd">                                    device=cpu,</span>
<span class="sd">                                    is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([2]),</span>
<span class="sd">                            device=cpu,</span>
<span class="sd">                            is_shared=False),</span>
<span class="sd">                        other_reward: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                            },</span>
<span class="sd">                            batch_size=torch.Size([2]),</span>
<span class="sd">                            device=cpu,</span>
<span class="sd">                            is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; check_env_specs(base_env)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, RemoveEmptySpecs())</span>
<span class="sd">        &gt;&gt;&gt; print(env.rollout(2))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([2]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        check_env_specs(env)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_has_empty_input</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_sorter</span><span class="p">(</span><span class="n">key_val</span><span class="p">):</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key_val</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

<div class="viewcode-block" id="RemoveEmptySpecs.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.html#torchrl.envs.transforms.RemoveEmptySpecs.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
        <span class="n">full_reward_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span>
        <span class="n">full_observation_spec</span> <span class="o">=</span> <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
        <span class="c1"># we reverse things to make sure we delete things from the back</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">full_done_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="k">del</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">full_observation_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="k">del</span> <span class="n">full_observation_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">full_reward_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="k">del</span> <span class="n">full_reward_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

<div class="viewcode-block" id="RemoveEmptySpecs.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.html#torchrl.envs.transforms.RemoveEmptySpecs.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">full_action_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
        <span class="n">full_state_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
        <span class="c1"># we reverse things to make sure we delete things from the back</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_has_empty_input</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">full_action_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_has_empty_input</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">del</span> <span class="n">full_action_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">full_state_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_has_empty_input</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">del</span> <span class="n">full_state_spec</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_empty_input</span><span class="p">:</span>
            <span class="n">input_spec</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="p">,</span> <span class="s2">&quot;input_spec&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">input_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">tensordict</span>

            <span class="n">full_action_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
            <span class="n">full_state_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
            <span class="c1"># we reverse things to make sure we delete things from the back</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="n">full_action_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">()</span>
                    <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">create_nested</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="n">full_state_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">is_empty</span><span class="p">()</span>
                    <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="n">tensordict</span><span class="o">.</span><span class="n">create_nested</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sorter</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">NonTensorData</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">is_empty</span><span class="p">()</span>
            <span class="p">):</span>
                <span class="k">del</span> <span class="n">next_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets a transform if it is stateful.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_InvertTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
    <span class="n">_MISSING_TRANSFORM_ERROR</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;There is not generic rule to invert a spec transform. &quot;</span>
        <span class="s2">&quot;Please file an issue on github to get help.&quot;</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">in_keys_inv</span>

    <span class="nd">@in_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set non-null value in in_keys.&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">in_keys</span>

    <span class="nd">@in_keys_inv</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set non-null value in in_keys_inv.&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">out_keys_inv</span>

    <span class="nd">@out_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set non-null value in out_keys.&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">out_keys</span>

    <span class="nd">@out_keys_inv</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set non-null value in out_keys_inv.&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MISSING_TRANSFORM_ERROR</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MISSING_TRANSFORM_ERROR</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MISSING_TRANSFORM_ERROR</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MISSING_TRANSFORM_ERROR</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_done_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MISSING_TRANSFORM_ERROR</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_CallableTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
    <span class="c1"># A wrapper around a custom callable to make it possible to transform any data type</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>


<div class="viewcode-block" id="BatchSizeTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BatchSizeTransform.html#torchrl.envs.transforms.BatchSizeTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">BatchSizeTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform to modify the batch-size of an environment.</span>

<span class="sd">    This transform has two distinct usages: it can be used to set the</span>
<span class="sd">    batch-size for non-batch-locked (e.g. stateless) environments to</span>
<span class="sd">    enable data collection using data collectors. It can also be used</span>
<span class="sd">    to modify the batch-size of an environment (e.g. squeeze, unsqueeze or</span>
<span class="sd">    reshape).</span>

<span class="sd">    This transform modifies the environment batch-size to match the one provided.</span>
<span class="sd">    It expects the parent environment batch-size to be expandable to the</span>
<span class="sd">    provided one.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        batch_size (torch.Size or equivalent, optional): the new batch-size of the environment.</span>
<span class="sd">            Exclusive with ``reshape_fn``.</span>
<span class="sd">        reshape_fn (callable, optional): a callable to modify the environment batch-size.</span>
<span class="sd">            Exclusive with ``batch_size``.</span>

<span class="sd">            .. note:: Currently, transformations involving</span>
<span class="sd">                ``reshape``, ``flatten``, ``unflatten``, ``squeeze`` and ``unsqueeze``</span>
<span class="sd">                are supported. If another reshape operation is required, please submit</span>
<span class="sd">                a feature request on TorchRL github.</span>

<span class="sd">        reset_func (callable, optional): a function that produces a reset tensordict.</span>
<span class="sd">            The signature must match ``Callable[[TensorDictBase, TensorDictBase], TensorDictBase]``</span>
<span class="sd">            where the first input argument is the optional tensordict passed to the</span>
<span class="sd">            environment during the call to :meth:`~EnvBase.reset` and the second</span>
<span class="sd">            is the output of ``TransformedEnv.base_env.reset``. It can also support an</span>
<span class="sd">            optional ``env`` keyword argument if ``env_kwarg=True``.</span>
<span class="sd">        env_kwarg (bool, optional): if ``True``, ``reset_func`` must support a</span>
<span class="sd">            ``env`` keyword argument. Defaults to ``False``. The env passed will</span>
<span class="sd">            be the env accompanied by its transform.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; # Changing the batch-size with a function</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;CartPole-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(base_env, BatchSizeTransform(reshape_fn=lambda data: data.reshape(1, 1)))</span>
<span class="sd">        &gt;&gt;&gt; env.rollout(4)</span>
<span class="sd">        &gt;&gt;&gt; # Setting the shape of a stateless environment</span>
<span class="sd">        &gt;&gt;&gt; class MyEnv(EnvBase):</span>
<span class="sd">        ...     batch_locked = False</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.observation_spec = Composite(observation=Unbounded(3))</span>
<span class="sd">        ...         self.reward_spec = Unbounded(1)</span>
<span class="sd">        ...         self.action_spec = Unbounded(1)</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _reset(self, tensordict: TensorDictBase, **kwargs) -&gt; TensorDictBase:</span>
<span class="sd">        ...         tensordict_batch_size = tensordict.batch_size if tensordict is not None else torch.Size([])</span>
<span class="sd">        ...         result = self.observation_spec.rand(tensordict_batch_size)</span>
<span class="sd">        ...         result.update(self.full_done_spec.zero(tensordict_batch_size))</span>
<span class="sd">        ...         return result</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _step(</span>
<span class="sd">        ...         self,</span>
<span class="sd">        ...         tensordict: TensorDictBase,</span>
<span class="sd">        ...     ) -&gt; TensorDictBase:</span>
<span class="sd">        ...         result = self.observation_spec.rand(tensordict.batch_size)</span>
<span class="sd">        ...         result.update(self.full_done_spec.zero(tensordict.batch_size))</span>
<span class="sd">        ...         result.update(self.full_reward_spec.zero(tensordict.batch_size))</span>
<span class="sd">        ...         return result</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _set_seed(self, seed: Optional[int]) -&gt; None:</span>
<span class="sd">        ...         pass</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(MyEnv(), BatchSizeTransform([5]))</span>
<span class="sd">        &gt;&gt;&gt; assert env.batch_size == torch.Size([5])</span>
<span class="sd">        &gt;&gt;&gt; assert env.rollout(10).shape == torch.Size([5, 10])</span>

<span class="sd">    The ``reset_func`` can create a tensordict with the desired batch-size, allowing for</span>
<span class="sd">    a fine-grained reset call:</span>

<span class="sd">        &gt;&gt;&gt; def reset_func(tensordict, tensordict_reset, env):</span>
<span class="sd">        ...     result = env.observation_spec.rand()</span>
<span class="sd">        ...     result.update(env.full_done_spec.zero())</span>
<span class="sd">        ...     assert result.batch_size != torch.Size([])</span>
<span class="sd">        ...     return result</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(MyEnv(), BatchSizeTransform([5], reset_func=reset_func, env_kwarg=True))</span>
<span class="sd">        &gt;&gt;&gt; print(env.rollout(2))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([5, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([5, 2]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5, 2]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    This transform can be used to deploy non-batch-locked environments within data</span>
<span class="sd">    collectors:</span>

<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import SyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; collector = SyncDataCollector(env, lambda td: env.rand_action(td), frames_per_batch=10, total_frames=-1)</span>
<span class="sd">        &gt;&gt;&gt; for data in collector:</span>
<span class="sd">        ...     print(data)</span>
<span class="sd">        ...     break</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([5, 2]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([5, 2]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([5, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([5, 2]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5, 2]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; collector.shutdown()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_ENV_ERR</span> <span class="o">=</span> <span class="s2">&quot;BatchSizeTransform.</span><span class="si">{}</span><span class="s2"> requires a parent env.&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reshape_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_kwarg</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">((</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="o">^</span> <span class="p">(</span><span class="n">reshape_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;One and only one of batch_size OR reshape_fn must be provided.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span> <span class="o">=</span> <span class="n">reshape_fn</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span> <span class="o">=</span> <span class="n">reshape_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_func</span> <span class="o">=</span> <span class="n">reset_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_kwarg</span> <span class="o">=</span> <span class="n">env_kwarg</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_kwarg</span><span class="p">:</span>
                <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_func</span><span class="p">(</span>
                    <span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">container</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_func</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="n">forward</span> <span class="o">=</span> <span class="n">_call</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">parent_batch_size</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">parent_batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="BatchSizeTransform.transform_env_batch_size"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BatchSizeTransform.html#torchrl.envs.transforms.BatchSizeTransform.transform_env_batch_size">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_env_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;meta&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span></div>

<div class="viewcode-block" id="BatchSizeTransform.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BatchSizeTransform.html#torchrl.envs.transforms.BatchSizeTransform.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span><span class="p">(</span><span class="n">output_spec</span><span class="p">)</span></div>

<div class="viewcode-block" id="BatchSizeTransform.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.BatchSizeTransform.html#torchrl.envs.transforms.BatchSizeTransform.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_fn</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="AutoResetEnv"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.AutoResetEnv.html#torchrl.envs.transforms.AutoResetEnv">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">AutoResetEnv</span><span class="p">(</span><span class="n">TransformedEnv</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A subclass for auto-resetting envs.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We must avoid modifying the original tensordict so a shallow copy is necessary.</span>
            <span class="c1"># We just select the input data and reset signal, which is all we need.</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make sure all transforms see a source tensordict</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">_complete_done</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="AutoResetEnv.insert_transform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.AutoResetEnv.html#torchrl.envs.transforms.AutoResetEnv.insert_transform">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">insert_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">transform</span><span class="p">:</span> <span class="n">Transform</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot insert a transform in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__class_</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="AutoResetTransform"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.AutoResetTransform.html#torchrl.envs.transforms.AutoResetTransform">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">AutoResetTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform for auto-resetting environments.</span>

<span class="sd">    This transform can be appended to any auto-resetting environment, or automatically</span>
<span class="sd">    appended using ``env = SomeEnvClass(..., auto_reset=True)``. If the transform is explicitly</span>
<span class="sd">    appended to an env, a :class:`~torchrl.envs.transforms.AutoResetEnv` must be used.</span>

<span class="sd">    An auto-reset environment must have the following properties (differences from this</span>
<span class="sd">    description should be accounted for by subclassing this class):</span>

<span class="sd">      - the reset function can be called once at the beginning (after instantiation) with</span>
<span class="sd">        or without effect. Whether calls to `reset` are allowed after that is up to the</span>
<span class="sd">        environment itself.</span>
<span class="sd">      - During a rollout, any ``done`` state will result in a reset and produce an observation</span>
<span class="sd">        that isn&#39;t the last observation of the current episode, but the first observation</span>
<span class="sd">        of the next episode (this transform will extract and cache this observation</span>
<span class="sd">        and fill the obs with some arbitrary value).</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        replace (bool, optional): if ``False``, values are just placed as they are in the</span>
<span class="sd">            ``&quot;next&quot;`` entry even if they are not valid. Defaults to ``True``. A value of</span>
<span class="sd">            ``False`` overrides any subsequent filling keyword argument.</span>
<span class="sd">            This argument can also be passed with the constructor method by passing a</span>
<span class="sd">            ``auto_reset_replace`` argument: ``env = FooEnv(..., auto_reset=True, auto_reset_replace=False)``.</span>
<span class="sd">        fill_float (:obj:`float` or str, optional): The filling value for floating point tensors</span>
<span class="sd">            that terminate an episode. A value of ``None`` means no replacement (values are just</span>
<span class="sd">            placed as they are in the ``&quot;next&quot;`` entry even if they are not valid).</span>
<span class="sd">        fill_int (int, optional): The filling value for signed integer tensors</span>
<span class="sd">            that terminate an episode.  A value of ``None`` means no replacement (values are just</span>
<span class="sd">            placed as they are in the ``&quot;next&quot;`` entry even if they are not valid).</span>
<span class="sd">        fill_bool (bool, optional): The filling value for boolean tensors</span>
<span class="sd">            that terminate an episode.  A value of ``None`` means no replacement (values are just</span>
<span class="sd">            placed as they are in the ``&quot;next&quot;`` entry even if they are not valid).</span>

<span class="sd">    Arguments are only available when the transform is explicitly instantiated (not through `EnvType(..., auto_reset=True)`).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import set_gym_backend</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; class AutoResettingGymEnv(GymEnv):</span>
<span class="sd">        ...     def _step(self, tensordict):</span>
<span class="sd">        ...         tensordict = super()._step(tensordict)</span>
<span class="sd">        ...         if tensordict[&quot;done&quot;].any():</span>
<span class="sd">        ...             td_reset = super().reset()</span>
<span class="sd">        ...             tensordict.update(td_reset.exclude(*self.done_keys))</span>
<span class="sd">        ...         return tensordict</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def _reset(self, tensordict=None):</span>
<span class="sd">        ...         if tensordict is not None and &quot;_reset&quot; in tensordict:</span>
<span class="sd">        ...             return tensordict.copy()</span>
<span class="sd">        ...         return super()._reset(tensordict)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; with set_gym_backend(&quot;gym&quot;):</span>
<span class="sd">        ...     env = AutoResettingGymEnv(&quot;CartPole-v1&quot;, auto_reset=True, auto_reset_replace=True)</span>
<span class="sd">        ...     env.set_seed(0)</span>
<span class="sd">        ...     r = env.rollout(30, break_when_any_done=False)</span>
<span class="sd">        &gt;&gt;&gt; print(r[&quot;next&quot;, &quot;done&quot;].squeeze())</span>
<span class="sd">        tensor([False, False, False, False, False, False, False, False, False, False,</span>
<span class="sd">                False, False, False,  True, False, False, False, False, False, False,</span>
<span class="sd">                False, False, False, False, False,  True, False, False, False, False])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;observation after reset are set as nan&quot;, r[&quot;next&quot;, &quot;observation&quot;])</span>
<span class="sd">        observation after reset are set as nan tensor([[-4.3633e-02, -1.4877e-01,  1.2849e-02,  2.7584e-01],</span>
<span class="sd">                [-4.6609e-02,  4.6166e-02,  1.8366e-02, -1.2761e-02],</span>
<span class="sd">                [-4.5685e-02,  2.4102e-01,  1.8111e-02, -2.9959e-01],</span>
<span class="sd">                [-4.0865e-02,  4.5644e-02,  1.2119e-02, -1.2542e-03],</span>
<span class="sd">                [-3.9952e-02,  2.4059e-01,  1.2094e-02, -2.9009e-01],</span>
<span class="sd">                [-3.5140e-02,  4.3554e-01,  6.2920e-03, -5.7893e-01],</span>
<span class="sd">                [-2.6429e-02,  6.3057e-01, -5.2867e-03, -8.6963e-01],</span>
<span class="sd">                [-1.3818e-02,  8.2576e-01, -2.2679e-02, -1.1640e+00],</span>
<span class="sd">                [ 2.6972e-03,  1.0212e+00, -4.5959e-02, -1.4637e+00],</span>
<span class="sd">                [ 2.3121e-02,  1.2168e+00, -7.5232e-02, -1.7704e+00],</span>
<span class="sd">                [ 4.7457e-02,  1.4127e+00, -1.1064e-01, -2.0854e+00],</span>
<span class="sd">                [ 7.5712e-02,  1.2189e+00, -1.5235e-01, -1.8289e+00],</span>
<span class="sd">                [ 1.0009e-01,  1.0257e+00, -1.8893e-01, -1.5872e+00],</span>
<span class="sd">                [        nan,         nan,         nan,         nan],</span>
<span class="sd">                [-3.9405e-02, -1.7766e-01, -1.0403e-02,  3.0626e-01],</span>
<span class="sd">                [-4.2959e-02, -3.7263e-01, -4.2775e-03,  5.9564e-01],</span>
<span class="sd">                [-5.0411e-02, -5.6769e-01,  7.6354e-03,  8.8698e-01],</span>
<span class="sd">                [-6.1765e-02, -7.6292e-01,  2.5375e-02,  1.1820e+00],</span>
<span class="sd">                [-7.7023e-02, -9.5836e-01,  4.9016e-02,  1.4826e+00],</span>
<span class="sd">                [-9.6191e-02, -7.6387e-01,  7.8667e-02,  1.2056e+00],</span>
<span class="sd">                [-1.1147e-01, -9.5991e-01,  1.0278e-01,  1.5219e+00],</span>
<span class="sd">                [-1.3067e-01, -7.6617e-01,  1.3322e-01,  1.2629e+00],</span>
<span class="sd">                [-1.4599e-01, -5.7298e-01,  1.5848e-01,  1.0148e+00],</span>
<span class="sd">                [-1.5745e-01, -7.6982e-01,  1.7877e-01,  1.3527e+00],</span>
<span class="sd">                [-1.7285e-01, -9.6668e-01,  2.0583e-01,  1.6956e+00],</span>
<span class="sd">                [        nan,         nan,         nan,         nan],</span>
<span class="sd">                [-4.3962e-02,  1.9845e-01, -4.5015e-02, -2.5903e-01],</span>
<span class="sd">                [-3.9993e-02,  3.9418e-01, -5.0196e-02, -5.6557e-01],</span>
<span class="sd">                [-3.2109e-02,  5.8997e-01, -6.1507e-02, -8.7363e-01],</span>
<span class="sd">                [-2.0310e-02,  3.9574e-01, -7.8980e-02, -6.0090e-01]])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">replace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fill_float</span><span class="o">=</span><span class="s2">&quot;nan&quot;</span><span class="p">,</span>
        <span class="n">fill_int</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">fill_bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">replace</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">fill_float</span> <span class="o">=</span> <span class="n">fill_int</span> <span class="o">=</span> <span class="n">fill_bool</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">fill_float</span> <span class="o">==</span> <span class="s2">&quot;nan&quot;</span><span class="p">:</span>
            <span class="n">fill_float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_float</span> <span class="o">=</span> <span class="n">fill_float</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_int</span> <span class="o">=</span> <span class="n">fill_int</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_bool</span> <span class="o">=</span> <span class="n">fill_bool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_container</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">AutoResetEnv</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> container must be of type AutoResetEnv.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validated</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_container</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_auto_reset_vals</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="o">=</span><span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_correct_auto_reset_vals</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>

<div class="viewcode-block" id="AutoResetTransform.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.AutoResetTransform.html#torchrl.envs.transforms.AutoResetTransform.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_simple_done</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">_simple_done</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_correct_auto_reset_vals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="c1"># we need to move the data from tensordict to tensordict_</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">replace_and_set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">saved_td_autoreset</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="n">tensordict</span><span class="p">):</span>
            <span class="n">saved_td_autoreset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_float</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">val_set_nan</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">val_set_nan</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                        <span class="n">expand_as_right</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">val</span><span class="p">),</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_float</span><span class="p">),</span>
                        <span class="n">val</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_signed</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_int</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">val_set_nan</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">val_set_nan</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                        <span class="n">expand_as_right</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">val</span><span class="p">),</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_int</span><span class="p">),</span>
                        <span class="n">val</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_bool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">val_set_nan</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">val_set_nan</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                        <span class="n">expand_as_right</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">val</span><span class="p">),</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_bool</span><span class="p">),</span>
                        <span class="n">val</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val_set_nan</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_simple_done</span><span class="p">:</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_saved_td_autorest</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                    <span class="n">replace_and_set</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">saved_td_autoreset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_saved_td_autorest</span>
                    <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># Go through each &quot;done&quot; key and get the corresponding agent.</span>
            <span class="n">_saved_td_autorest</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">obs_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">_ends_with</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                            <span class="s2">&quot;A &#39;done&#39; key was a string but a tuple was expected.&quot;</span>
                        <span class="p">)</span>
                    <span class="n">agent_key</span> <span class="o">=</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span>
                    <span class="n">mask</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">done</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">_saved_td_autorest</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">_saved_td_autorest</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">()</span>
                        <span class="n">agent</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">agent_key</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
                            <span class="n">agents</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">tensordicts</span>
                            <span class="n">masks</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
                            <span class="n">saved_td_autorest_agent</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                                <span class="o">*</span><span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">agents</span><span class="p">],</span>
                                <span class="n">stack_dim</span><span class="o">=</span><span class="n">agent</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="n">saved_td_autorest_agents</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="n">saved_td_autorest_agent</span><span class="o">.</span><span class="n">tensordicts</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">agents</span> <span class="o">=</span> <span class="p">[</span><span class="n">agent</span><span class="p">]</span>
                            <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">mask</span><span class="p">]</span>
                            <span class="n">saved_td_autorest_agent</span> <span class="o">=</span> <span class="n">_saved_td_autorest</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span>
                                <span class="n">agent_key</span><span class="p">,</span> <span class="n">agent</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                            <span class="p">)</span>
                            <span class="n">saved_td_autorest_agents</span> <span class="o">=</span> <span class="p">[</span><span class="n">saved_td_autorest_agent</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">obs_keys</span><span class="p">:</span>
                            <span class="k">if</span> <span class="p">(</span>
                                <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
                                <span class="ow">and</span> <span class="n">key</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">agent_key</span><span class="p">)]</span> <span class="o">==</span> <span class="n">agent_key</span>
                            <span class="p">):</span>
                                <span class="k">for</span> <span class="n">_agent</span><span class="p">,</span> <span class="n">_mask</span><span class="p">,</span> <span class="n">_saved_td_autorest_agent</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                                    <span class="n">agents</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">saved_td_autorest_agents</span>
                                <span class="p">):</span>
                                    <span class="n">val</span> <span class="o">=</span> <span class="n">_agent</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">agent_key</span><span class="p">)</span> <span class="p">:])</span>
                                    <span class="n">replace_and_set</span><span class="p">(</span>
                                        <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">agent_key</span><span class="p">)</span> <span class="p">:],</span>
                                        <span class="n">val</span><span class="p">,</span>
                                        <span class="n">_mask</span><span class="p">,</span>
                                        <span class="n">saved_td_autoreset</span><span class="o">=</span><span class="n">_saved_td_autorest_agent</span><span class="p">,</span>
                                        <span class="n">agent</span><span class="o">=</span><span class="n">_agent</span><span class="p">,</span>
                                    <span class="p">)</span>
                    <span class="n">parents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">_saved_td_autorest</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_saved_td_autorest&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_saved_td_autorest</span>

        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_replace_auto_reset_vals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">):</span>
        <span class="n">_saved_td_autorest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_saved_td_autorest&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_saved_td_autorest</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict_reset</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_simple_done</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_td_autorest</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">_ends_with</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="n">val_set_reg</span> <span class="o">=</span> <span class="n">val</span>
                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val_set_reg</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">_ends_with</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">):</span>
                    <span class="n">agent_key</span> <span class="o">=</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_td_autorest</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                        <span class="n">_replace_last</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="s2">&quot;__mask__&quot;</span><span class="p">),</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">agent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_td_autorest</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">agent_key</span><span class="p">)</span>

                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
                            <span class="n">agents</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">tensordicts</span>
                            <span class="n">masks</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
                            <span class="n">dests</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span>
                                <span class="n">agent_key</span><span class="p">,</span>
                                <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                                    <span class="o">*</span><span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">agents</span><span class="p">],</span>
                                    <span class="n">stack_dim</span><span class="o">=</span><span class="n">agent</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
                                <span class="p">),</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">agents</span> <span class="o">=</span> <span class="p">[</span><span class="n">agent</span><span class="p">]</span>
                            <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">mask</span><span class="p">]</span>
                            <span class="n">dests</span> <span class="o">=</span> <span class="p">[</span>
                                <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">agent_key</span><span class="p">,</span> <span class="n">agent</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
                            <span class="p">]</span>
                        <span class="k">for</span> <span class="n">_agent</span><span class="p">,</span> <span class="n">_mask</span><span class="p">,</span> <span class="n">_dest</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">agents</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">dests</span><span class="p">):</span>
                            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">_agent</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                                <span class="k">if</span> <span class="n">_ends_with</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">):</span>
                                    <span class="k">continue</span>
                                <span class="k">if</span> <span class="ow">not</span> <span class="n">_mask</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                                    <span class="n">val_not_reset</span> <span class="o">=</span> <span class="n">_dest</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                                    <span class="n">val_set_reg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                                        <span class="n">expand_as_right</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">val</span><span class="p">),</span> <span class="n">val</span><span class="p">,</span> <span class="n">val_not_reset</span>
                                    <span class="p">)</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">val_set_reg</span> <span class="o">=</span> <span class="n">val</span>
                                <span class="n">_dest</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val_set_reg</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_saved_td_autorest&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span></div>


<div class="viewcode-block" id="ActionDiscretizer"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ActionDiscretizer.html#torchrl.envs.transforms.ActionDiscretizer">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ActionDiscretizer</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform to discretize a continuous action space.</span>

<span class="sd">    This transform makes it possible to use an algorithm designed for discrete</span>
<span class="sd">    action spaces such as DQN over environments with a continuous action space.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_intervals (int or torch.Tensor): the number of discrete values</span>
<span class="sd">            for each element of the action space. If a single integer is provided,</span>
<span class="sd">            all action items are sliced with the same number of elements.</span>
<span class="sd">            If a tensor is provided, it must have the same number of elements</span>
<span class="sd">            as the action space (ie, the length of the ``num_intervals`` tensor</span>
<span class="sd">            must match the last dimension of the action space).</span>
<span class="sd">        action_key (NestedKey, optional): the action key to use. Points to</span>
<span class="sd">            the action of the parent env (the floating point action).</span>
<span class="sd">            Defaults to ``&quot;action&quot;``.</span>
<span class="sd">        out_action_key (NestedKey, optional): the key where the discrete</span>
<span class="sd">            action should be written. If ``None`` is provided, it defaults to</span>
<span class="sd">            the value of ``action_key``. If both keys do not match, the</span>
<span class="sd">            continuous action_spec is moved from the ``full_action_spec``</span>
<span class="sd">            environment attribute to the ``full_state_spec`` container,</span>
<span class="sd">            as only the discrete action should be sampled for an action to</span>
<span class="sd">            be taken. Providing ``out_action_key`` can ensure that the</span>
<span class="sd">            floating point action is available to be recorded.</span>
<span class="sd">        sampling (ActionDiscretizer.SamplingStrategy, optinoal): an element</span>
<span class="sd">            of the ``ActionDiscretizer.SamplingStrategy`` ``IntEnum`` object</span>
<span class="sd">            (``MEDIAN``, ``LOW``, ``HIGH`` or ``RANDOM``). Indicates how the</span>
<span class="sd">            continuous action should be sampled in the provided interval.</span>
<span class="sd">        categorical (bool, optional): if ``False``, one-hot encoding is used.</span>
<span class="sd">            Defaults to ``True``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv, check_env_specs</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;HalfCheetah-v4&quot;)</span>
<span class="sd">        &gt;&gt;&gt; num_intervals = torch.arange(5, 11)</span>
<span class="sd">        &gt;&gt;&gt; categorical = True</span>
<span class="sd">        &gt;&gt;&gt; sampling = ActionDiscretizer.SamplingStrategy.MEDIAN</span>
<span class="sd">        &gt;&gt;&gt; t = ActionDiscretizer(</span>
<span class="sd">        ...     num_intervals=num_intervals,</span>
<span class="sd">        ...     categorical=categorical,</span>
<span class="sd">        ...     sampling=sampling,</span>
<span class="sd">        ...     out_action_key=&quot;action_disc&quot;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; env = base_env.append_transform(t)</span>
<span class="sd">        TransformedEnv(</span>
<span class="sd">            env=GymEnv(env=HalfCheetah-v4, batch_size=torch.Size([]), device=cpu),</span>
<span class="sd">            transform=ActionDiscretizer(</span>
<span class="sd">                num_intervals=tensor([ 5,  6,  7,  8,  9, 10]),</span>
<span class="sd">                action_key=action,</span>
<span class="sd">                out_action_key=action_disc,,</span>
<span class="sd">                sampling=0,</span>
<span class="sd">                categorical=True))</span>
<span class="sd">        &gt;&gt;&gt; check_env_specs(env)</span>
<span class="sd">        &gt;&gt;&gt; # Produce a rollout</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(4)</span>
<span class="sd">        &gt;&gt;&gt; print(r)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                action_disc: Tensor(shape=torch.Size([4, 6]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([4, 17]), device=cpu, dtype=torch.float64, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([4]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([4, 17]), device=cpu, dtype=torch.float64, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([4]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; assert r[&quot;action&quot;].dtype == torch.float</span>
<span class="sd">        &gt;&gt;&gt; assert r[&quot;action_disc&quot;].dtype == torch.int64</span>
<span class="sd">        &gt;&gt;&gt; assert (r[&quot;action&quot;] &lt; base_env.action_spec.high).all()</span>
<span class="sd">        &gt;&gt;&gt; assert (r[&quot;action&quot;] &gt; base_env.action_spec.low).all()</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ActionDiscretizer.SamplingStrategy"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ActionDiscretizer.html#torchrl.envs.transforms.ActionDiscretizer.SamplingStrategy">[docs]</a>    <span class="k">class</span><span class="w"> </span><span class="nc">SamplingStrategy</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The sampling strategies for ActionDiscretizer.&quot;&quot;&quot;</span>

        <span class="n">MEDIAN</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">LOW</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">HIGH</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">RANDOM</span> <span class="o">=</span> <span class="mi">3</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_intervals</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">action_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span><span class="p">,</span>
        <span class="n">out_action_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sampling</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">categorical</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">out_action_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_action_key</span> <span class="o">=</span> <span class="n">action_key</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="o">=</span><span class="p">[</span><span class="n">action_key</span><span class="p">],</span> <span class="n">out_keys_inv</span><span class="o">=</span><span class="p">[</span><span class="n">out_action_key</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="o">=</span> <span class="n">action_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span> <span class="o">=</span> <span class="n">out_action_key</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_intervals</span> <span class="o">=</span> <span class="n">num_intervals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;num_intervals&quot;</span><span class="p">,</span> <span class="n">num_intervals</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sampling</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SamplingStrategy</span><span class="o">.</span><span class="n">MEDIAN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span> <span class="o">=</span> <span class="n">sampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">categorical</span> <span class="o">=</span> <span class="n">categorical</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_indent</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">indent</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>

        <span class="n">num_intervals</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;num_intervals=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_intervals</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">action_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;action_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">out_action_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;out_action_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">sampling</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;sampling=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sampling</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">categorical</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;categorical=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="n">_indent</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">_indent</span><span class="p">(</span><span class="n">action_key</span><span class="p">)</span><span class="si">}</span><span class="s2">,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">_indent</span><span class="p">(</span><span class="n">out_action_key</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">_indent</span><span class="p">(</span><span class="n">sampling</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="si">{</span><span class="n">_indent</span><span class="p">(</span><span class="n">categorical</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_custom_arange</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nint</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">end</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="n">nint</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">result_</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">SamplingStrategy</span><span class="o">.</span><span class="n">HIGH</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">SamplingStrategy</span><span class="o">.</span><span class="n">MEDIAN</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">result_</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">SamplingStrategy</span><span class="o">.</span><span class="n">MEDIAN</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">result</span> <span class="o">+</span> <span class="n">result_</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result_</span>
        <span class="k">return</span> <span class="n">result</span>

<div class="viewcode-block" id="ActionDiscretizer.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ActionDiscretizer.html#torchrl.envs.transforms.ActionDiscretizer.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">action_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">full_action_spec_unbatched</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">Bounded</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;action spec type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">action_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not supported. The action spec type must be Bounded.&quot;</span>
                <span class="p">)</span>

            <span class="n">n_act</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">n_act</span><span class="p">:</span>
                <span class="n">n_act</span> <span class="o">=</span> <span class="p">()</span>
                <span class="n">empty_shape</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_act</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_act</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
                <span class="n">empty_shape</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_act</span> <span class="o">=</span> <span class="n">n_act</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">dtype</span>
            <span class="n">interval</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">high</span> <span class="o">-</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">low</span>

            <span class="n">num_intervals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_intervals</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">empty_shape</span><span class="p">:</span>
                <span class="n">interval</span> <span class="o">=</span> <span class="n">interval</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">num_intervals</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_intervals</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_intervals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">arange</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_custom_arange</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="p">(</span><span class="o">*</span><span class="n">n_act</span><span class="p">,</span> <span class="n">num_intervals</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="o">*</span> <span class="n">interval</span>
                <span class="p">)</span>
                <span class="n">low</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">low</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">empty_shape</span><span class="p">:</span>
                    <span class="n">low</span> <span class="o">=</span> <span class="n">low</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;intervals&quot;</span><span class="p">,</span> <span class="n">low</span> <span class="o">+</span> <span class="n">arange</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">arange</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_custom_arange</span><span class="p">(</span><span class="n">_num_intervals</span><span class="p">,</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">interval</span>
                    <span class="k">for</span> <span class="n">_num_intervals</span><span class="p">,</span> <span class="n">interval</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                        <span class="n">num_intervals</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">interval</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">intervals</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">low</span> <span class="o">+</span> <span class="n">arange</span>
                    <span class="k">for</span> <span class="n">low</span><span class="p">,</span> <span class="n">arange</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                        <span class="n">action_spec</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">arange</span>
                    <span class="p">)</span>
                <span class="p">]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">nvec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">num_intervals</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">action_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nvec</span> <span class="o">=</span> <span class="n">num_intervals</span>
            <span class="k">if</span> <span class="n">nvec</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot use num_intervals with shape </span><span class="si">{</span><span class="n">nvec</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nvec</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">nvec</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">empty_shape</span><span class="p">:</span>
                    <span class="n">nvec</span> <span class="o">=</span> <span class="n">nvec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">nvec</span> <span class="o">=</span> <span class="n">nvec</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;nvec&quot;</span><span class="p">,</span> <span class="n">nvec</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">SamplingStrategy</span><span class="o">.</span><span class="n">RANDOM</span><span class="p">:</span>
                <span class="c1"># compute jitters</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">jitters</span> <span class="o">=</span> <span class="n">interval</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">nvec</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">categorical</span>
                <span class="k">else</span> <span class="p">(</span><span class="o">*</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nvec</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">empty_shape</span><span class="p">:</span>
                <span class="bp">cls</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">MultiCategorical</span><span class="p">,</span> <span class="n">remove_singleton</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">categorical</span>
                    <span class="k">else</span> <span class="n">MultiOneHot</span>
                <span class="p">)</span>
                <span class="n">action_spec</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">nvec</span><span class="o">=</span><span class="n">nvec</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">action_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">cls</span> <span class="o">=</span> <span class="n">Categorical</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">categorical</span> <span class="k">else</span> <span class="n">OneHot</span>
                <span class="n">action_spec</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">nvec</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">action_spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
                <span class="n">action_spec</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">action_spec</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span>
                    <span class="s2">&quot;full_action_spec&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">del</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">return</span> <span class="n">input_spec</span>
        <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="c1"># To avoid silent AttributeErrors</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">))</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># We just need to access the action spec for everything to be initialized</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="o">.</span><span class="n">full_action_spec</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot execute transform </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> without a parent env.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="ActionDiscretizer.inv"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ActionDiscretizer.html#torchrl.envs.transforms.ActionDiscretizer.inv">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="c1"># We re-write this because we don&#39;t want to clone the TD here</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="c1"># action is categorical, map it to desired dtype</span>
        <span class="n">intervals</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;intervals&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">intervals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">()</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">categorical</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="o">-</span><span class="n">intervals</span><span class="o">.</span><span class="n">ndim</span><span class="p">]</span>
                <span class="n">intervals</span> <span class="o">=</span> <span class="n">intervals</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">shape</span> <span class="o">+</span> <span class="n">intervals</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">intervals</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">action</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">interval</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">action</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">interval</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
                    <span class="p">],</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nvec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvec</span>
            <span class="n">empty_shape</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">nvec</span><span class="o">.</span><span class="n">ndim</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">empty_shape</span><span class="p">:</span>
                <span class="n">nvec</span> <span class="o">=</span> <span class="n">nvec</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">shape</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="p">(</span><span class="o">-</span><span class="n">intervals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
                    <span class="n">intervals</span> <span class="o">=</span> <span class="n">intervals</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">shape</span> <span class="o">+</span> <span class="n">intervals</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="n">intervals</span> <span class="o">=</span> <span class="n">intervals</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">nvec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">intervals</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                        <span class="k">for</span> <span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                    <span class="p">],</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="o">-</span><span class="n">intervals</span><span class="o">.</span><span class="n">ndim</span><span class="p">]</span>
                <span class="n">intervals</span> <span class="o">=</span> <span class="n">intervals</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">shape</span> <span class="o">+</span> <span class="n">intervals</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">intervals</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">SamplingStrategy</span><span class="o">.</span><span class="n">RANDOM</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">action</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">jitters</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">jitters</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_keys_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">)</span></div>


<div class="viewcode-block" id="TrajCounter"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TrajCounter.html#torchrl.envs.transforms.TrajCounter">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TrajCounter</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Global trajectory counter transform.</span>

<span class="sd">    TrajCounter can be used to count the number of trajectories (i.e., the number of times `reset` is called) in any</span>
<span class="sd">    TorchRL environment.</span>
<span class="sd">    This transform will work within a single node across multiple processes (see note below).</span>
<span class="sd">    A single transform can only count the trajectories associated with a single done state, but nested done states are</span>
<span class="sd">    accepted as long as their prefix matches the prefix of the counter key.</span>

<span class="sd">    Args:</span>
<span class="sd">        out_key (NestedKey, optional): The entry name of the trajectory counter. Defaults to ``&quot;traj_count&quot;``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv, StepCounter, TrajCounter</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v1&quot;).append_transform(StepCounter(6))</span>
<span class="sd">        &gt;&gt;&gt; env = env.append_transform(TrajCounter())</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(18, break_when_any_done=False)  # 18 // 6 = 3 trajectories</span>
<span class="sd">        &gt;&gt;&gt; r[&quot;next&quot;, &quot;traj_count&quot;]</span>
<span class="sd">        tensor([[0],</span>
<span class="sd">                [0],</span>
<span class="sd">                [0],</span>
<span class="sd">                [0],</span>
<span class="sd">                [0],</span>
<span class="sd">                [0],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2]])</span>

<span class="sd">    .. note::</span>
<span class="sd">        Sharing a trajectory counter among workers can be done in multiple ways, but it will usually involve wrapping the environment in a :class:`~torchrl.envs.EnvCreator`. Not doing so may result in an error during serialization of the transform. The counter will be shared among the workers, meaning that at any point in time, it is guaranteed that there will not be two environments that will share the same trajectory count (and each (step-count, traj-count) pair will be unique).</span>
<span class="sd">        Here are examples of valid ways of sharing a ``TrajCounter`` object between processes:</span>

<span class="sd">            &gt;&gt;&gt; # Option 1: Create the trajectory counter outside the environment.</span>
<span class="sd">            &gt;&gt;&gt; #  This requires the counter to be cloned within the transformed env, as a single transform object cannot have two parents.</span>
<span class="sd">            &gt;&gt;&gt; t = TrajCounter()</span>
<span class="sd">            &gt;&gt;&gt; def make_env(max_steps=4, t=t):</span>
<span class="sd">            ...     # See CountingEnv in torchrl.test.mocking_classes</span>
<span class="sd">            ...     env = TransformedEnv(CountingEnv(max_steps=max_steps), t.clone())</span>
<span class="sd">            ...     env.transform.transform_observation_spec(env.base_env.observation_spec)</span>
<span class="sd">            ...     return env</span>
<span class="sd">            &gt;&gt;&gt; penv = ParallelEnv(</span>
<span class="sd">            ...     2,</span>
<span class="sd">            ...     [EnvCreator(make_env, max_steps=4), EnvCreator(make_env, max_steps=5)],</span>
<span class="sd">            ...     mp_start_method=&quot;spawn&quot;,</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Option 2: Create the transform within the constructor.</span>
<span class="sd">            &gt;&gt;&gt; #  In this scenario, we still need to tell each sub-env what kwarg has to be used.</span>
<span class="sd">            &gt;&gt;&gt; #  Both EnvCreator and ParallelEnv offer that possibility.</span>
<span class="sd">            &gt;&gt;&gt; def make_env(max_steps=4):</span>
<span class="sd">            ...     t = TrajCounter()</span>
<span class="sd">            ...     env = TransformedEnv(CountingEnv(max_steps=max_steps), t)</span>
<span class="sd">            ...     env.transform.transform_observation_spec(env.base_env.observation_spec)</span>
<span class="sd">            ...     return env</span>
<span class="sd">            &gt;&gt;&gt; make_env_c0 = EnvCreator(make_env)</span>
<span class="sd">            &gt;&gt;&gt; # Create a variant of the env with different kwargs</span>
<span class="sd">            &gt;&gt;&gt; make_env_c1 = make_env_c0.make_variant(max_steps=5)</span>
<span class="sd">            &gt;&gt;&gt; penv = ParallelEnv(</span>
<span class="sd">            ...     2,</span>
<span class="sd">            ...     [make_env_c0, make_env_c1],</span>
<span class="sd">            ...     mp_start_method=&quot;spawn&quot;,</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Alternatively, pass the kwargs to the ParallelEnv</span>
<span class="sd">            &gt;&gt;&gt; penv = ParallelEnv(</span>
<span class="sd">            ...     2,</span>
<span class="sd">            ...     [make_env_c0, make_env_c0],</span>
<span class="sd">            ...     create_env_kwargs=[{&quot;max_steps&quot;: 5}, {&quot;max_steps&quot;: 4}],</span>
<span class="sd">            ...     mp_start_method=&quot;spawn&quot;,</span>
<span class="sd">            ... )</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">out_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;traj_count&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">out_key</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_make_shared_value</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">repeats</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">repeats</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">repeats</span> <span class="o">=</span> <span class="n">repeats</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_shared_value</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">()</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_traj_count&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
        <span class="n">clone</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># All clones share the same _traj_count and lock</span>
        <span class="n">clone</span><span class="o">.</span><span class="n">_traj_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span>
        <span class="k">return</span> <span class="n">clone</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">rk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reset_keys</span>
        <span class="n">traj_count_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">is_str</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">traj_count_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_rk</span> <span class="ow">in</span> <span class="n">rk</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_rk</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">rk</span> <span class="o">=</span> <span class="n">_rk</span>
                <span class="k">break</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="n">is_str</span>
                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_rk</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">_rk</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">traj_count_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">rk</span> <span class="o">=</span> <span class="n">_rk</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Did not find reset key that matched the prefix of the traj counter key. Reset keys: </span><span class="si">{</span><span class="n">rk</span><span class="si">}</span><span class="s2">, traj count: </span><span class="si">{</span><span class="n">traj_count_key</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">reset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">rk</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">container</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">tensordict_reset</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">with</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="p">):</span>
            <span class="n">tc</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="o">.</span><span class="n">value</span> <span class="o">+</span> <span class="n">reset</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">episodes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">tc</span><span class="p">,</span> <span class="n">tc</span> <span class="o">+</span> <span class="n">reset</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">episodes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reset</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">episodes</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">reset</span><span class="p">,</span> <span class="n">episodes</span>
            <span class="p">)</span>
            <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">traj_count_key</span><span class="p">,</span> <span class="n">episodes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;_step was called before _reset was called.&quot;</span><span class="p">)</span>
        <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> can only be called within an environment step or reset.&quot;</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TrajCounter.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TrajCounter.html#torchrl.envs.transforms.TrajCounter.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> can only be called within an environment step or reset.&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="TrajCounter.state_dict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TrajCounter.html#torchrl.envs.transforms.TrajCounter.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;traj_count&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="o">.</span><span class="n">value</span><span class="p">),</span>
        <span class="p">}</span></div>

<div class="viewcode-block" id="TrajCounter.load_state_dict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TrajCounter.html#torchrl.envs.transforms.TrajCounter.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">assign</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="o">.</span><span class="n">value</span> <span class="o">*=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_count</span><span class="o">.</span><span class="n">value</span> <span class="o">+=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">]</span></div>

<div class="viewcode-block" id="TrajCounter.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.TrajCounter.html#torchrl.envs.transforms.TrajCounter.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;observation_spec was expected to be of type Composite. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="n">full_done_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
        <span class="n">traj_count_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># find a matching done key (there might be more than one)</span>
        <span class="k">for</span> <span class="n">done_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">done_keys</span><span class="p">:</span>
            <span class="c1"># check root</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">done_key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">traj_count_key</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">done_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">traj_count_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">break</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not find root of traj_count key </span><span class="si">{</span><span class="n">traj_count_key</span><span class="si">}</span><span class="s2"> in done keys </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">observation_spec</span><span class="p">[</span><span class="n">traj_count_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transform_observation_spec</span><span class="p">(</span><span class="n">observation_spec</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LineariseRewards"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.LineariseRewards.html#torchrl.envs.transforms.LineariseRewards">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">LineariseRewards</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms a multi-objective reward signal to a single-objective one via a weighted sum.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (List[NestedKey]): The keys under which the multi-objective rewards are found.</span>
<span class="sd">        out_keys (List[NestedKey], optional): The keys under which single-objective rewards should be written. Defaults to :attr:`in_keys`.</span>
<span class="sd">        weights (List[float], Tensor, optional): Dictates how to weight each reward when summing them. Defaults to `[1.0, 1.0, ...]`.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        If a sequence of `in_keys` of length strictly greater than one is passed (e.g. one group for each agent in a</span>
<span class="sd">        multi-agent set-up), the same weights will be applied for each entry. If you need to aggregate rewards</span>
<span class="sd">        differently for each group, use several :class:`~torchrl.envs.LineariseRewards` in a row.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import mo_gymnasium as mo_gym</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import MOGymWrapper</span>
<span class="sd">        &gt;&gt;&gt; mo_env = MOGymWrapper(mo_gym.make(&quot;deep-sea-treasure-v0&quot;))</span>
<span class="sd">        &gt;&gt;&gt; mo_env.reward_spec</span>
<span class="sd">        BoundedContinuous(</span>
<span class="sd">            shape=torch.Size([2]),</span>
<span class="sd">            space=ContinuousBox(</span>
<span class="sd">            low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),</span>
<span class="sd">            high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),</span>
<span class="sd">            ...)</span>
<span class="sd">        &gt;&gt;&gt; so_env = TransformedEnv(mo_env, LineariseRewards(in_keys=(&quot;reward&quot;,)))</span>
<span class="sd">        &gt;&gt;&gt; so_env.reward_spec</span>
<span class="sd">        BoundedContinuous(</span>
<span class="sd">            shape=torch.Size([1]),</span>
<span class="sd">            space=ContinuousBox(</span>
<span class="sd">                low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),</span>
<span class="sd">                high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),</span>
<span class="sd">            ...)</span>
<span class="sd">        &gt;&gt;&gt; td = so_env.rollout(5)</span>
<span class="sd">        &gt;&gt;&gt; td[&quot;next&quot;, &quot;reward&quot;].shape</span>
<span class="sd">        torch.Size([5, 1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="n">in_keys</span> <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">out_keys</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

            <span class="c1"># This transform should only receive vectorial weights (all batch dimensions will be aggregated similarly).</span>
            <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected weights to be a unidimensional tensor. Got </span><span class="si">{</span><span class="n">weights</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimension.&quot;</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="LineariseRewards.transform_reward_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.LineariseRewards.html#torchrl.envs.transforms.LineariseRewards.transform_reward_spec">[docs]</a>    <span class="nd">@_apply_to_composite</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Aggregation of rewards that take discrete values is not supported.&quot;</span>
            <span class="p">)</span>

        <span class="o">*</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_rewards</span> <span class="o">=</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_rewards</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="p">)</span>

        <span class="n">num_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_weights</span> <span class="o">!=</span> <span class="n">num_rewards</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The number of rewards and weights should match. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got: </span><span class="si">{</span><span class="n">num_rewards</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">num_weights</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_spec</span><span class="p">,</span> <span class="n">UnboundedContinuous</span><span class="p">):</span>
            <span class="n">reward_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">reward_spec</span>

        <span class="n">weights_pos</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weights_neg</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">low_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">weights_pos</span> <span class="o">*</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">low_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">weights_neg</span> <span class="o">*</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">high_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">weights_pos</span> <span class="o">*</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">high_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">weights_neg</span> <span class="o">*</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">BoundedContinuous</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="n">low_pos</span> <span class="o">+</span> <span class="n">low_neg</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="n">high_pos</span> <span class="o">+</span> <span class="n">high_neg</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">reward</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="o">*</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_rewards</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">num_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_weights</span> <span class="o">!=</span> <span class="n">num_rewards</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The number of rewards and weights should match. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got: </span><span class="si">{</span><span class="n">num_rewards</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">num_weights</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">reward</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="ConditionalSkip"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ConditionalSkip.html#torchrl.envs.transforms.ConditionalSkip">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ConditionalSkip</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform that skips steps in the env if certain conditions are met.</span>

<span class="sd">    This transform writes the result of `cond(tensordict)` in the `&quot;_step&quot;` entry of the</span>
<span class="sd">    tensordict passed as input to the `TransformedEnv.base_env._step` method.</span>
<span class="sd">    If the `base_env` is not batch-locked (generally speaking, it is stateless), the tensordict is</span>
<span class="sd">    reduced to its element that need to go through the step.</span>
<span class="sd">    If it is batch-locked (generally speaking, it is stateful), the step is skipped altogether if no</span>
<span class="sd">    value in `&quot;_step&quot;` is ``True``. Otherwise, it is trusted that the environment will account for the</span>
<span class="sd">    `&quot;_step&quot;` signal accordingly.</span>

<span class="sd">    .. note:: The skip will affect transforms that modify the environment output too, i.e., any transform</span>
<span class="sd">        that is to be exectued on the tensordict returned by :meth:`~torchrl.envs.EnvBase.step` will be</span>
<span class="sd">        skipped if the condition is met. To palliate this effect if it is not desirable, one can wrap</span>
<span class="sd">        the transformed env in another transformed env, since the skip only affects the first-degree parent</span>
<span class="sd">        of the ``ConditionalSkip`` transform. See example below.</span>

<span class="sd">    Args:</span>
<span class="sd">        cond (Callable[[TensorDictBase], bool | torch.Tensor]): a callable for the tensordict input</span>
<span class="sd">            that checks whether the next env step must be skipped (`True` = skipped, `False` = execute</span>
<span class="sd">            env.step).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.transforms.transforms import ConditionalSkip, StepCounter, TransformedEnv, Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; base_env = TransformedEnv(</span>
<span class="sd">        ...     GymEnv(&quot;Pendulum-v1&quot;),</span>
<span class="sd">        ...     StepCounter(step_count_key=&quot;inner_count&quot;),</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; middle_env = TransformedEnv(</span>
<span class="sd">        ...     base_env,</span>
<span class="sd">        ...     Compose(</span>
<span class="sd">        ...         StepCounter(step_count_key=&quot;middle_count&quot;),</span>
<span class="sd">        ...         ConditionalSkip(cond=lambda td: td[&quot;step_count&quot;] % 2 == 1),</span>
<span class="sd">        ...     ),</span>
<span class="sd">        ...     auto_unwrap=False)  # makes sure that transformed envs are properly wrapped</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     middle_env,</span>
<span class="sd">        ...     StepCounter(step_count_key=&quot;step_count&quot;),</span>
<span class="sd">        ...     auto_unwrap=False)</span>
<span class="sd">        &gt;&gt;&gt; env.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(10)</span>
<span class="sd">        &gt;&gt;&gt; print(r[&quot;observation&quot;])</span>
<span class="sd">        tensor([[-0.9670, -0.2546, -0.9669],</span>
<span class="sd">                [-0.9802, -0.1981, -1.1601],</span>
<span class="sd">                [-0.9802, -0.1981, -1.1601],</span>
<span class="sd">                [-0.9926, -0.1214, -1.5556],</span>
<span class="sd">                [-0.9926, -0.1214, -1.5556],</span>
<span class="sd">                [-0.9994, -0.0335, -1.7622],</span>
<span class="sd">                [-0.9994, -0.0335, -1.7622],</span>
<span class="sd">                [-0.9984,  0.0561, -1.7933],</span>
<span class="sd">                [-0.9984,  0.0561, -1.7933],</span>
<span class="sd">                [-0.9895,  0.1445, -1.7779]])</span>
<span class="sd">        &gt;&gt;&gt; print(r[&quot;inner_count&quot;])</span>
<span class="sd">        tensor([[0],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2],</span>
<span class="sd">                [3],</span>
<span class="sd">                [3],</span>
<span class="sd">                [4],</span>
<span class="sd">                [4],</span>
<span class="sd">                [5]])</span>
<span class="sd">        &gt;&gt;&gt; print(r[&quot;middle_count&quot;])</span>
<span class="sd">        tensor([[0],</span>
<span class="sd">                [1],</span>
<span class="sd">                [1],</span>
<span class="sd">                [2],</span>
<span class="sd">                [2],</span>
<span class="sd">                [3],</span>
<span class="sd">                [3],</span>
<span class="sd">                [4],</span>
<span class="sd">                [4],</span>
<span class="sd">                [5]])</span>
<span class="sd">        &gt;&gt;&gt; print(r[&quot;step_count&quot;])</span>
<span class="sd">        tensor([[0],</span>
<span class="sd">                [1],</span>
<span class="sd">                [2],</span>
<span class="sd">                [3],</span>
<span class="sd">                [4],</span>
<span class="sd">                [5],</span>
<span class="sd">                [6],</span>
<span class="sd">                [7],</span>
<span class="sd">                [8],</span>
<span class="sd">                [9]])</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cond</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDict</span><span class="p">],</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cond</span> <span class="o">=</span> <span class="n">cond</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># Run cond</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="c1"># Write result in step</span>
        <span class="n">tensordict</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">cond</span>
        <span class="k">if</span> <span class="n">tensordict</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="n">tensordict</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

<div class="viewcode-block" id="ConditionalSkip.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ConditionalSkip.html#torchrl.envs.transforms.ConditionalSkip.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="MultiAction"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.MultiAction.html#torchrl.envs.transforms.MultiAction">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">MultiAction</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform to execute multiple actions in the parent environment.</span>

<span class="sd">    This transform unbinds the actions along a specific dimension and passes each action independently.</span>
<span class="sd">    The returned transform can be either a stack of the observations gathered during the steps or only the</span>
<span class="sd">    last observation (and similarly for the rewards, see args below).</span>

<span class="sd">    By default, the actions must be stacked along the first dimension after the root tensordict batch-dims, i.e.</span>

<span class="sd">        &gt;&gt;&gt; td = policy(td)</span>
<span class="sd">        &gt;&gt;&gt; actions = td.select(*env.action_keys)</span>
<span class="sd">        &gt;&gt;&gt; # Adapt the batch-size</span>
<span class="sd">        &gt;&gt;&gt; actions = actions.auto_batch_size_(td.ndim + 1)</span>
<span class="sd">        &gt;&gt;&gt; # Step-wise actions</span>
<span class="sd">        &gt;&gt;&gt; actions = actions.unbind(-1)</span>

<span class="sd">    If a `&quot;done&quot;` entry is encountered, the next steps are skipped for the env that has reached that state.</span>

<span class="sd">    .. note:: If a transform is appended before the MultiAction, it will be called multiple times. If it is appended</span>
<span class="sd">        after, it will be called once per macro-step.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        dim (int, optional): the stack dimension with respect to the tensordict ``ndim`` attribute.</span>
<span class="sd">            Must be greater than 0. Defaults to ``1`` (the first dimension after the batch-dims).</span>
<span class="sd">        stack_rewards (bool, optional): if ``True``, each step&#39;s reward will be stack in the output tensordict.</span>
<span class="sd">            If ``False``, only the last reward will be returned. The reward spec is adapted accordingly. The</span>
<span class="sd">            stack dimension is the same as the action stack dimension. Defaults to ``True``.</span>
<span class="sd">        stack_observations (bool, optional): if ``True``, each step&#39;s observation will be stack in the output tensordict.</span>
<span class="sd">            If ``False``, only the last observation will be returned. The observation spec is adapted accordingly. The</span>
<span class="sd">            stack dimension is the same as the action stack dimension. Defaults to ``False``.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">stack_rewards</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">stack_observations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span> <span class="o">=</span> <span class="n">stack_rewards</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span> <span class="o">=</span> <span class="n">stack_observations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_stack_tds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">td_list</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">td_list</span> <span class="o">+</span> <span class="p">[</span><span class="n">next_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">td</span><span class="o">.</span><span class="n">auto_batch_size_</span><span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">td</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># Collect the stacks if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span><span class="p">:</span>
            <span class="n">reward_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span>
            <span class="n">reward_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stack_tds</span><span class="p">(</span>
                <span class="n">reward_td</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span>
            <span class="p">)</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">reward_td</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">:</span>
            <span class="n">obs_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs</span>
            <span class="n">obs_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stack_tds</span><span class="p">(</span>
                <span class="n">obs_td</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">observation_keys</span>
            <span class="p">)</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obs_td</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="c1"># Get the actions</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="n">action_keys</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">action_keys</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">action_keys</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span><span class="o">.</span><span class="n">auto_batch_size_</span><span class="p">(</span><span class="n">batch_dims</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">tensordict</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">global_idx</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">reset</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">global_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">global_idx</span><span class="p">]</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>

            <span class="c1"># Save rewards and done states</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span><span class="p">:</span>
                <span class="n">reward_td</span> <span class="o">=</span> <span class="n">td</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">global_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">reward_td_expand</span> <span class="o">=</span> <span class="n">reward_td</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span>
                        <span class="n">global_idx</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="n">reward_td</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">global_idx</span><span class="o">.</span><span class="n">ndim</span> <span class="p">:]</span>
                    <span class="p">)</span>
                    <span class="n">reward_td_expand</span><span class="p">[</span><span class="n">global_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_td</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">reward_td_expand</span> <span class="o">=</span> <span class="n">reward_td</span>

                <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward_td_expand</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">:</span>
                <span class="n">obs_td</span> <span class="o">=</span> <span class="n">td</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">observation_keys</span><span class="p">)</span>
                <span class="c1"># obs_td = td.select(&quot;next&quot;, *self.parent.observation_keys).set(&quot;next&quot;, obs_td)</span>
                <span class="k">if</span> <span class="n">global_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">obs_td</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">global_idx</span><span class="p">,</span> <span class="n">obs_td</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="n">obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs_td</span><span class="p">)</span>

            <span class="n">td</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">step_mdp</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span><span class="p">:</span>
                <span class="n">td</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">reward_td</span><span class="p">)</span>

            <span class="n">any_done</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">any_done</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">any_done</span><span class="p">:</span>
                <span class="c1"># Intersect the resets to avoid making any step after reset has been called</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span> <span class="o">|</span> <span class="n">td</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_reset&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">reset</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="c1"># Skip step for all</span>
                    <span class="n">td</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">~</span><span class="n">reset</span>
                    <span class="k">break</span>
                <span class="k">elif</span> <span class="n">parent</span><span class="o">.</span><span class="n">batch_locked</span><span class="p">:</span>
                    <span class="n">td</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">~</span><span class="n">reset</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># we can simply index the tensordict</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="o">~</span><span class="n">reset</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">global_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">global_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                        <span class="n">td_out</span> <span class="o">=</span> <span class="n">td</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td_out</span><span class="p">[</span><span class="n">global_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                        <span class="n">global_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">(</span><span class="n">global_idx</span><span class="p">,</span> <span class="n">global_idx</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
                    <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                    <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># Should be all False</span>

        <span class="k">if</span> <span class="n">global_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">td_out</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">td_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">td_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">td_out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">td_out</span><span class="p">[</span><span class="n">global_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">global_idx</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">:</span>
                <span class="n">td_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">td_out</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">global_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">global_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">td_out</span><span class="p">[</span><span class="s2">&quot;_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">global_idx</span>

        <span class="k">return</span> <span class="n">td_out</span>

<div class="viewcode-block" id="MultiAction.transform_input_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.MultiAction.html#torchrl.envs.transforms.MultiAction.transform_input_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">action_spec</span> <span class="o">=</span> <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> requires an action spec to be present.&quot;</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">):</span>
            <span class="n">action_spec</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">input_spec</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
        <span class="c1"># Make the dim dynamic</span>
        <span class="n">action_spec</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">d</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="p">(</span><span class="n">input_spec</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">action_spec</span>
        <span class="k">return</span> <span class="n">input_spec</span></div>

<div class="viewcode-block" id="MultiAction.transform_output_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.MultiAction.html#torchrl.envs.transforms.MultiAction.transform_output_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;full_reward_spec&quot;</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_reward_spec</span><span class="p">(</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">],</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">ndim</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;full_observation_spec&quot;</span> <span class="ow">in</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_observation_spec</span><span class="p">(</span>
                <span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">],</span> <span class="n">output_spec</span><span class="o">.</span><span class="n">ndim</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">output_spec</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_rewards</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">reward_spec</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">):</span>
            <span class="n">reward_spec</span> <span class="o">=</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span>
        <span class="c1"># Make the dim dynamic</span>
        <span class="n">reward_spec</span> <span class="o">=</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">d</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="p">(</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reward_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">reward_spec</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_observation_spec</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">ndim</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_observations</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">observation_spec</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">):</span>
            <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span>
        <span class="c1"># Make the dim dynamic</span>
        <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">d</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="p">(</span><span class="n">ndim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>


<div class="viewcode-block" id="Timer"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Timer.html#torchrl.envs.transforms.Timer">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Timer</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform that measures the time intervals between `inv` and `call` operations in an environment.</span>

<span class="sd">    The `Timer` transform is used to track the time elapsed between the `inv` call and the `call`,</span>
<span class="sd">    and between the `call` and the `inv` call. This is useful for performance monitoring and debugging</span>
<span class="sd">    within an environment. The time is measured in seconds and stored as a tensor with the default</span>
<span class="sd">    dtype from PyTorch. If the tensordict has a batch size (e.g., in batched environments), the time will be expended</span>
<span class="sd">    to the size of the input tensordict.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        out_keys: The keys of the output tensordict for the inverse transform. Defaults to</span>
<span class="sd">            `out_keys = [f&quot;{time_key}_step&quot;, f&quot;{time_key}_policy&quot;, f&quot;{time_key}_reset&quot;]`, where the first key represents</span>
<span class="sd">            the time it takes to make a step in the environment, and the second key represents the</span>
<span class="sd">            time it takes to execute the policy, the third the time for the call to `reset`.</span>
<span class="sd">        time_key: A prefix for the keys where the time intervals will be stored in the tensordict.</span>
<span class="sd">            Defaults to `&quot;time&quot;`.</span>

<span class="sd">    .. note:: During a succession of rollouts, the time marks of the reset are written at the root (the `&quot;time_reset&quot;`</span>
<span class="sd">        entry or equivalent key is always 0 in the `&quot;next&quot;` tensordict). At the root, the `&quot;time_policy&quot;` and `&quot;time_step&quot;`</span>
<span class="sd">        entries will be 0 when there is a reset. they will never be `0` in the `&quot;next&quot;`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import Timer, GymEnv</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; env = GymEnv(&quot;Pendulum-v1&quot;).append_transform(Timer())</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(10)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;time for policy&quot;, r[&quot;time_policy&quot;])</span>
<span class="sd">        time for policy tensor([0.0000, 0.0882, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,</span>
<span class="sd">                0.0002])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;time for step&quot;, r[&quot;time_step&quot;])</span>
<span class="sd">        time for step tensor([9.5797e-04, 1.6289e-03, 9.7990e-05, 8.0824e-05, 9.0837e-05, 7.6056e-05,</span>
<span class="sd">                8.2016e-05, 7.6056e-05, 8.1062e-05, 7.7009e-05])</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">time_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;time&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_key</span><span class="si">}</span><span class="s2">_step&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_key</span><span class="si">}</span><span class="s2">_policy&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_key</span><span class="si">}</span><span class="s2">_reset&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected three out_keys. Got out_keys=</span><span class="si">{</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">([],</span> <span class="n">out_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_key</span> <span class="o">=</span> <span class="n">time_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_inv_time</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_call_time</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_reset_time</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_step_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_policy_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_reset_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset_env_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_reset_time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_inv_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_expand_and_set</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">time_elapsed</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">parent_td</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parent_td</span> <span class="o">=</span> <span class="n">tensordict</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">parent_td</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="c1"># Get the parent shape</span>
            <span class="n">time_elapsed_expand</span> <span class="o">=</span> <span class="n">time_elapsed</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">parent_td</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">time_elapsed_expand</span> <span class="o">=</span> <span class="n">time_elapsed</span>
        <span class="n">parent_td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">time_elapsed_expand</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">current_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_reset_time</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">current_time</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_reset_time</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_expand_and_set</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_reset_key</span><span class="p">,</span> <span class="n">time_elapsed</span><span class="p">,</span> <span class="n">tensordict_reset</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_expand_and_set</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_step_key</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">*</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tensordict_reset</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_call_time</span> <span class="o">=</span> <span class="n">current_time</span>
        <span class="c1"># Placeholder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_expand_and_set</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">time_policy_key</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">*</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tensordict_reset</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_reset</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">current_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_call_time</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">current_time</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_call_time</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_expand_and_set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_policy_key</span><span class="p">,</span> <span class="n">time_elapsed</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_inv_time</span> <span class="o">=</span> <span class="n">current_time</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">current_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_inv_time</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">current_time</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_inv_time</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_expand_and_set</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_step_key</span><span class="p">,</span> <span class="n">time_elapsed</span><span class="p">,</span> <span class="n">next_tensordict</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_expand_and_set</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_reset_key</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">*</span> <span class="mi">0</span><span class="p">,</span> <span class="n">next_tensordict</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_call_time</span> <span class="o">=</span> <span class="n">current_time</span>
        <span class="c1"># presumbly no need to worry about batch size incongruencies here</span>
        <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_policy_key</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_policy_key</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

<div class="viewcode-block" id="Timer.transform_observation_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Timer.html#torchrl.envs.transforms.Timer.transform_observation_spec">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
        <span class="n">observation_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_step_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Unbounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">observation_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_policy_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Unbounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">observation_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_reset_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Unbounded</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">observation_spec</span></div>

<div class="viewcode-block" id="Timer.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.Timer.html#torchrl.envs.transforms.Timer.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">FORWARD_NOT_IMPLEMENTED</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ConditionalPolicySwitch"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.html#torchrl.envs.transforms.ConditionalPolicySwitch">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ConditionalPolicySwitch</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform that conditionally switches between policies based on a specified condition.</span>

<span class="sd">    This transform evaluates a condition on the data returned by the environment&#39;s `step` method.</span>
<span class="sd">    If the condition is met, it applies a specified policy to the data. Otherwise, the data is</span>
<span class="sd">    returned unaltered. This is useful for scenarios where different policies need to be applied</span>
<span class="sd">    based on certain criteria, such as alternating turns in a game.</span>

<span class="sd">    Args:</span>
<span class="sd">        policy (Callable[[TensorDictBase], TensorDictBase]):</span>
<span class="sd">            The policy to be applied when the condition is met. This should be a callable that</span>
<span class="sd">            takes a `TensorDictBase` and returns a `TensorDictBase`.</span>
<span class="sd">        condition (Callable[[TensorDictBase], bool]):</span>
<span class="sd">            A callable that takes a `TensorDictBase` and returns a boolean or a tensor indicating</span>
<span class="sd">            whether the policy should be applied.</span>

<span class="sd">    .. warning:: This transform must have a parent environment.</span>

<span class="sd">    .. note:: Ideally, it should be the last transform  in the stack. If the policy requires transformed</span>
<span class="sd">        data (e.g., images), and this transform  is applied before those transformations, the policy will</span>
<span class="sd">        not receive the transformed data.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule as Mod</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv, ConditionalPolicySwitch, Compose, StepCounter</span>
<span class="sd">        &gt;&gt;&gt; # Create a CartPole environment. We&#39;ll be looking at the obs: if the first element of the obs is greater than</span>
<span class="sd">        &gt;&gt;&gt; # 0 (left position) we do a right action (action=0) using the switch policy. Otherwise, we use our main</span>
<span class="sd">        &gt;&gt;&gt; # policy which does a left action.</span>
<span class="sd">        &gt;&gt;&gt; base_env = GymEnv(&quot;CartPole-v1&quot;, categorical_action_encoding=True)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; policy = Mod(lambda: torch.ones((), dtype=torch.int64), in_keys=[], out_keys=[&quot;action&quot;])</span>
<span class="sd">        &gt;&gt;&gt; policy_switch = Mod(lambda: torch.zeros((), dtype=torch.int64), in_keys=[], out_keys=[&quot;action&quot;])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; cond = lambda td: td.get(&quot;observation&quot;)[..., 0] &gt;= 0</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; env = base_env.append_transform(</span>
<span class="sd">        ...     Compose(</span>
<span class="sd">        ...         # We use two step counters to show that one counts the global steps, whereas the other</span>
<span class="sd">        ...         # only counts the steps where the main policy is executed</span>
<span class="sd">        ...         StepCounter(step_count_key=&quot;step_count_total&quot;),</span>
<span class="sd">        ...         ConditionalPolicySwitch(condition=cond, policy=policy_switch),</span>
<span class="sd">        ...         StepCounter(step_count_key=&quot;step_count_main&quot;),</span>
<span class="sd">        ...     )</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; env.set_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; r = env.rollout(100, policy=policy)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;action&quot;, r[&quot;action&quot;])</span>
<span class="sd">        action tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;obs&quot;, r[&quot;observation&quot;])</span>
<span class="sd">        obs tensor([[ 0.0322, -0.1540,  0.0111,  0.3190],</span>
<span class="sd">                [ 0.0299, -0.1544,  0.0181,  0.3280],</span>
<span class="sd">                [ 0.0276, -0.1550,  0.0255,  0.3414],</span>
<span class="sd">                [ 0.0253, -0.1558,  0.0334,  0.3596],</span>
<span class="sd">                [ 0.0230, -0.1569,  0.0422,  0.3828],</span>
<span class="sd">                [ 0.0206, -0.1582,  0.0519,  0.4117],</span>
<span class="sd">                [ 0.0181, -0.1598,  0.0629,  0.4469],</span>
<span class="sd">                [ 0.0156, -0.1617,  0.0753,  0.4891],</span>
<span class="sd">                [ 0.0130, -0.1639,  0.0895,  0.5394],</span>
<span class="sd">                [ 0.0104, -0.1665,  0.1058,  0.5987],</span>
<span class="sd">                [ 0.0076, -0.1696,  0.1246,  0.6685],</span>
<span class="sd">                [ 0.0047, -0.1732,  0.1463,  0.7504],</span>
<span class="sd">                [ 0.0016, -0.1774,  0.1715,  0.8459],</span>
<span class="sd">                [-0.0020,  0.0150,  0.1884,  0.6117],</span>
<span class="sd">                [-0.0017,  0.2071,  0.2006,  0.3838]])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;obs&#39;&quot;, r[&quot;next&quot;, &quot;observation&quot;])</span>
<span class="sd">        obs&#39; tensor([[ 0.0299, -0.1544,  0.0181,  0.3280],</span>
<span class="sd">                [ 0.0276, -0.1550,  0.0255,  0.3414],</span>
<span class="sd">                [ 0.0253, -0.1558,  0.0334,  0.3596],</span>
<span class="sd">                [ 0.0230, -0.1569,  0.0422,  0.3828],</span>
<span class="sd">                [ 0.0206, -0.1582,  0.0519,  0.4117],</span>
<span class="sd">                [ 0.0181, -0.1598,  0.0629,  0.4469],</span>
<span class="sd">                [ 0.0156, -0.1617,  0.0753,  0.4891],</span>
<span class="sd">                [ 0.0130, -0.1639,  0.0895,  0.5394],</span>
<span class="sd">                [ 0.0104, -0.1665,  0.1058,  0.5987],</span>
<span class="sd">                [ 0.0076, -0.1696,  0.1246,  0.6685],</span>
<span class="sd">                [ 0.0047, -0.1732,  0.1463,  0.7504],</span>
<span class="sd">                [ 0.0016, -0.1774,  0.1715,  0.8459],</span>
<span class="sd">                [-0.0020,  0.0150,  0.1884,  0.6117],</span>
<span class="sd">                [-0.0017,  0.2071,  0.2006,  0.3838],</span>
<span class="sd">                [ 0.0105,  0.2015,  0.2115,  0.5110]])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;total step count&quot;, r[&quot;step_count_total&quot;].squeeze())</span>
<span class="sd">        total step count tensor([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 26, 27])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;total step with main policy&quot;, r[&quot;step_count_main&quot;].squeeze())</span>
<span class="sd">        total step with main policy tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">condition</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="nb">bool</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">([],</span> <span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;policy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">condition</span> <span class="o">=</span> <span class="n">condition</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">condition</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Calling the condition function should return a boolean or a tensor.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,)):</span>
            <span class="k">if</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">cond</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Tensor outputs must have the shape of the tensordict, or contain a single element.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cond</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cond</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">step</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">cond</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">step</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
            <span class="n">cond</span> <span class="o">=</span> <span class="n">cond</span> <span class="o">&amp;</span> <span class="n">step</span>

            <span class="n">parent</span><span class="p">:</span> <span class="n">TransformedEnv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="n">any_done</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_done</span><span class="p">(</span><span class="n">next_tensordict</span><span class="p">)</span>
            <span class="n">next_td_save</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">any_done</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">done</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="k">return</span> <span class="n">next_tensordict</span>
                <span class="k">if</span> <span class="n">parent</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">batch_locked</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot run partial steps in a batched locked environment. &quot;</span>
                        <span class="s2">&quot;Hint: Parallel and Serial envs can be unlocked through a keyword argument in &quot;</span>
                        <span class="s2">&quot;the constructor.&quot;</span>
                    <span class="p">)</span>
                <span class="n">done</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">next_tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">cond</span> <span class="o">=</span> <span class="n">cond</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">done</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">cond</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">parent</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">batch_locked</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot run partial steps in a batched locked environment. &quot;</span>
                        <span class="s2">&quot;Hint: Parallel and Serial envs can be unlocked through a keyword argument in &quot;</span>
                        <span class="s2">&quot;the constructor.&quot;</span>
                    <span class="p">)</span>
                <span class="n">next_td_save</span> <span class="o">=</span> <span class="n">next_tensordict</span>
                <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span>

            <span class="c1"># policy may be expensive or raise an exception when executed with unadequate data so</span>
            <span class="c1"># we index the td first</span>
            <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span>
                <span class="n">parent</span><span class="o">.</span><span class="n">step_mdp</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="c1"># Mark the partial steps if needed</span>
            <span class="k">if</span> <span class="n">next_td_save</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">td_new</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">cond</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="c1"># TODO: swap with masked_scatter when avail</span>
                <span class="n">td_new</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">td_new</span>
                <span class="n">td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
            <span class="n">next_tensordict</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_td_save</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">next_tensordict</span><span class="p">,</span> <span class="n">next_td_save</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">next_tensordict</span>
        <span class="k">return</span> <span class="n">next_tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_done</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="n">env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="k">if</span> <span class="n">env</span><span class="o">.</span><span class="n">_simple_done</span><span class="p">:</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">_get_str</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">any_done</span> <span class="o">=</span> <span class="n">done</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">any_done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">any_done</span> <span class="o">=</span> <span class="n">_terminated_or_truncated</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span>
                <span class="n">full_done_spec</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">],</span>
                <span class="n">key</span><span class="o">=</span><span class="s2">&quot;_reset&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_reset&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">any_done</span><span class="p">,</span> <span class="n">done</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">condition</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
        <span class="c1"># TODO: move to validate</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Calling the condition function should return a boolean or a tensor.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,)):</span>
            <span class="k">if</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">cond</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Tensor outputs must have the shape of the tensordict, or contain a single element.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cond</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cond</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_reset&quot;</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">reset</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">cond</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
            <span class="n">cond</span> <span class="o">=</span> <span class="n">cond</span> <span class="o">&amp;</span> <span class="n">reset</span>

            <span class="n">parent</span><span class="p">:</span> <span class="n">TransformedEnv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
            <span class="n">reset_td_save</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">cond</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                <span class="n">reset_td_save</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span>
                <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span>

            <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
            <span class="c1"># Mark the partial steps if needed</span>
            <span class="k">if</span> <span class="n">reset_td_save</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">td_new</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">cond</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="c1"># TODO: swap with masked_scatter when avail</span>
                <span class="n">td_new</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">td_new</span>
                <span class="n">td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;_step&quot;</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
            <span class="n">tensordict_reset</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">td</span><span class="p">)</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">parent</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">reset_td_save</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">,</span> <span class="n">reset_td_save</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensordict_reset</span>

        <span class="k">return</span> <span class="n">tensordict_reset</span>

<div class="viewcode-block" id="ConditionalPolicySwitch.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.html#torchrl.envs.transforms.ConditionalPolicySwitch.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;ConditionalPolicySwitch cannot be called independently, only its step and reset methods are functional.&quot;</span>
        <span class="p">)</span></div></div>


<span class="k">class</span><span class="w"> </span><span class="nc">FlattenTensorDict</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Flattens TensorDict batch dimensions during inverse pass for replay buffer usage.</span>

<span class="sd">    This transform is specifically designed for replay buffers where data needs</span>
<span class="sd">    to be flattened before being stored. It performs an identity operation during</span>
<span class="sd">    the forward pass and flattens the batch dimensions during the inverse pass.</span>

<span class="sd">    This is useful when collecting batched data that needs to be stored as</span>
<span class="sd">    individual experiences in a replay buffer.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This transform is NOT intended for use with environments. If you try to use</span>
<span class="sd">        it as an environment transform, it will raise an exception. For reshaping</span>
<span class="sd">        environment batch dimensions, use :class:`~torchrl.envs.BatchSizeTransform`</span>
<span class="sd">        instead.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This transform should be applied to replay buffers, not to environments.</span>
<span class="sd">        It is designed to be used with :meth:`~torchrl.data.ReplayBuffer.append_transform`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Using with a replay buffer:</span>

<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.transforms import FlattenTensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDictReplayBuffer, LazyTensorStorage</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create a replay buffer with the transform</span>
<span class="sd">        &gt;&gt;&gt; transform = FlattenTensorDict()</span>
<span class="sd">        &gt;&gt;&gt; rb = TensorDictReplayBuffer(</span>
<span class="sd">        ...     storage=LazyTensorStorage(1000),</span>
<span class="sd">        ...     transform=transform,</span>
<span class="sd">        ...     batch_size=32</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create batched data (e.g., from multiple environments)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({</span>
<span class="sd">        ...     &quot;observation&quot;: torch.randn(4, 2, 3),</span>
<span class="sd">        ...     &quot;action&quot;: torch.randn(4, 2, 1),</span>
<span class="sd">        ...     &quot;reward&quot;: torch.randn(4, 2, 1),</span>
<span class="sd">        ... }, batch_size=[4, 2])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # When extending the buffer, data gets flattened automatically</span>
<span class="sd">        &gt;&gt;&gt; rb.extend(td)  # Data is flattened from [4, 2] to [8] before storage</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # When sampling, data comes out in the requested batch size</span>
<span class="sd">        &gt;&gt;&gt; sample = rb.sample(4)  # Shape will be [4, ...]</span>

<span class="sd">        Direct usage (for testing):</span>

<span class="sd">        &gt;&gt;&gt; # Forward pass (identity)</span>
<span class="sd">        &gt;&gt;&gt; td_forward = transform(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td_forward.batch_size)  # [4, 2]</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Inverse pass (flatten)</span>
<span class="sd">        &gt;&gt;&gt; td_inverse = transform.inv(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td_inverse.batch_size)  # [8]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_ENV_ERROR_MSG</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;FlattenTensorDict is designed for replay buffers and should not be used &quot;</span>
        <span class="s2">&quot;as an environment transform. For reshaping environment batch dimensions, &quot;</span>
        <span class="s2">&quot;use BatchSizeTransform instead.&quot;</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">inverse</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass - identity operation.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverse pass - flatten the tensordict.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass - identity operation.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverse pass - flatten the tensordict.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_call</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset pass - identity operation.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform input spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_output_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform output spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_observation_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform observation spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform action spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_state_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform state spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform reward spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_done_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform done spec - not supported for environments.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ENV_ERROR_MSG</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
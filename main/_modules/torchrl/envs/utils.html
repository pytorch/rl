


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.envs.utils &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../versions.html"><span style="font-size:110%">main (0.7.0+4c55b65) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-1.html">Get started with TorchRLâ€™s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/export.html">Exporting TorchRL modules</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.envs.utils</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.envs.utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.util</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">is_tensor_collection</span><span class="p">,</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">NonTensorData</span><span class="p">,</span>
    <span class="n">NonTensorStack</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
    <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">unravel_key</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">_default_is_leaf</span><span class="p">,</span> <span class="n">_is_leaf_nontensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDictModule</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn.probabilistic</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>  <span class="c1"># noqa</span>
    <span class="n">interaction_type</span> <span class="k">as</span> <span class="n">exploration_type</span><span class="p">,</span>
    <span class="n">InteractionType</span> <span class="k">as</span> <span class="n">ExplorationType</span><span class="p">,</span>
    <span class="n">set_interaction_type</span> <span class="k">as</span> <span class="n">set_exploration_type</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_non_tensor</span><span class="p">,</span> <span class="n">NestedKey</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils._pytree</span><span class="w"> </span><span class="kn">import</span> <span class="n">tree_map</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_replace_last</span><span class="p">,</span> <span class="n">_rng_decorator</span><span class="p">,</span> <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.tensor_specs</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Composite</span><span class="p">,</span>
    <span class="n">NO_DEFAULT_RL</span> <span class="k">as</span> <span class="n">NO_DEFAULT</span><span class="p">,</span>
    <span class="n">NonTensor</span><span class="p">,</span>
    <span class="n">TensorSpec</span><span class="p">,</span>
    <span class="n">Unbounded</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_no_exclusive_keys</span><span class="p">,</span> <span class="n">CloudpickleWrapper</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;exploration_type&quot;</span><span class="p">,</span>
    <span class="s2">&quot;set_exploration_type&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ExplorationType&quot;</span><span class="p">,</span>
    <span class="s2">&quot;check_env_specs&quot;</span><span class="p">,</span>
    <span class="s2">&quot;step_mdp&quot;</span><span class="p">,</span>
    <span class="s2">&quot;make_composite_from_td&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MarlGroupMapType&quot;</span><span class="p">,</span>
    <span class="s2">&quot;check_marl_grouping&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="n">ACTION_MASK_ERROR</span> <span class="o">=</span> <span class="ne">RuntimeError</span><span class="p">(</span>
    <span class="s2">&quot;An out-of-bounds actions has been provided to an env with an &#39;action_mask&#39; output. &quot;</span>
    <span class="s2">&quot;If you are using a custom policy, make sure to take the action mask into account when computing the output. &quot;</span>
    <span class="s2">&quot;If you are using a default policy, please add the torchrl.envs.transforms.ActionMask transform to your environment. &quot;</span>
    <span class="s2">&quot;If you are using a ParallelEnv or another batched inventor, &quot;</span>
    <span class="s2">&quot;make sure to add the transform to the ParallelEnv (and not to the sub-environments). &quot;</span>
    <span class="s2">&quot;For more info on using action masks, see the docs at: &quot;</span>
    <span class="s2">&quot;https://pytorch.org/rl/main/reference/envs.html#environments-with-masked-actions&quot;</span>
<span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_classproperty</span><span class="p">(</span><span class="nb">property</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__get__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">owner</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">classmethod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fget</span><span class="p">)</span><span class="o">.</span><span class="fm">__get__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">owner</span><span class="p">)()</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_StepMDP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stateful version of :func:`~torchrl.envs.step_mdp`.</span>

<span class="sd">    Precomputes the list of keys to include and exclude during a call to step_mdp</span>
<span class="sd">    to reduce runtime.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">env</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">keep_other</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">exclude_reward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">exclude_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">exclude_action</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">action_keys</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_keys</span>
        <span class="n">done_keys</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">done_keys</span>
        <span class="n">reward_keys</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reward_keys</span>
        <span class="n">observation_keys</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">full_observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">state_keys</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">full_state_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">action_keys</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">done_keys</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">observation_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">state_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">reward_keys</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_keys_filt</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_keys</span><span class="p">))</span>

        <span class="n">excluded</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">exclude_reward</span><span class="p">:</span>
            <span class="c1"># If a reward is also a state, it must be in the input</span>
            <span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_keys_filt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exclude_done</span><span class="p">:</span>
            <span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exclude_action</span><span class="p">:</span>
            <span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">excluded</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">excluded</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">keep_other</span> <span class="o">=</span> <span class="n">keep_other</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_action</span> <span class="o">=</span> <span class="n">exclude_action</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">exclude_reward</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_keys</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">reward_key</span>
                <span class="k">for</span> <span class="n">reward_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_keys</span>
                <span class="k">if</span> <span class="n">reward_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_keys</span>
            <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">exclude_done</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_root</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">exclude_action</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_root</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span>
        <span class="k">if</span> <span class="n">keep_other</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_root</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_keys</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_keys</span>

        <span class="n">reset_keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">_replace_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">reset_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_keys_filt</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repr_key_list_as_tree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repr_key_list_as_tree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys_from_root</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repr_key_list_as_tree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validated</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Model based envs can have missing keys</span>
        <span class="c1"># TODO: do we want to always allow this? check_env_specs should catch these or downstream ops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_allow_absent_keys</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="c1"># Deprecated - leaving dormant</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">validated</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">validated</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># check that the key set of the tensordict matches what is expected</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_keys</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_keys</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_keys</span><span class="p">]</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">]</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">((</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_keys</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">_is_reset</span><span class="p">(</span><span class="n">key</span><span class="p">:</span> <span class="n">NestedKey</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;_reset&quot;</span>
                <span class="k">return</span> <span class="n">key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;_reset&quot;</span>

            <span class="n">actual</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">_is_leaf_nontensor</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_reset</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="p">}</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span>
            <span class="c1"># Actual (the input td) can have more keys, like loc and scale etc</span>
            <span class="c1"># But we cannot have keys missing: if there&#39;s a key in expected that is not in actual</span>
            <span class="c1"># it is a problem.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validated</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">validated</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;The expected key set and actual key set differ (all expected keys must be present, &quot;</span>
                    <span class="s2">&quot;extra keys can be present in the input TensorDict). &quot;</span>
                    <span class="s2">&quot;As a result, step_mdp will need to run extra key checks at each iteration. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">Expected keys</span><span class="se">}}</span><span class="s2">-</span><span class="se">{{</span><span class="s2">Actual keys</span><span class="se">}}</span><span class="s2">=</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">actual</span><span class="si">}</span><span class="s2"> (&lt;= this set should be empty), </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">Actual keys</span><span class="se">}}</span><span class="s2">-</span><span class="se">{{</span><span class="s2">Expected keys</span><span class="se">}}</span><span class="s2">=</span><span class="si">{</span><span class="n">actual</span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">validated</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_repr_key_list_as_tree</span><span class="p">(</span><span class="n">key_list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Represents the keys as a tree to facilitate iteration.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">key_list</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>
        <span class="n">key_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(())</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">key_list</span><span class="p">}</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">key_dict</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([]))</span>
        <span class="k">return</span> <span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="n">td</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_grab_and_place</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">nested_key_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">data_in</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">data_out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">_allow_absent_keys</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">subdict</span> <span class="ow">in</span> <span class="n">nested_key_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">data_in</span><span class="o">.</span><span class="n">_get_str</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">NO_DEFAULT</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">subdict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">val_out</span> <span class="o">=</span> <span class="n">data_out</span><span class="o">.</span><span class="n">_get_str</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">val_out</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">val_out</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">val</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
                    <span class="n">val_out</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">val</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>

                    <span class="n">val</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="o">.</span><span class="n">lazy_stack</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="bp">cls</span><span class="o">.</span><span class="n">_grab_and_place</span><span class="p">(</span>
                                <span class="n">subdict</span><span class="p">,</span>
                                <span class="n">_val</span><span class="p">,</span>
                                <span class="n">_val_out</span><span class="p">,</span>
                                <span class="n">_allow_absent_keys</span><span class="o">=</span><span class="n">_allow_absent_keys</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="k">for</span> <span class="p">(</span><span class="n">_val</span><span class="p">,</span> <span class="n">_val_out</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                                <span class="n">val</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">),</span>
                                <span class="n">val_out</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">val_out</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">),</span>
                            <span class="p">)</span>
                        <span class="p">],</span>
                        <span class="n">dim</span><span class="o">=</span><span class="n">val</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_grab_and_place</span><span class="p">(</span>
                        <span class="n">subdict</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">val_out</span><span class="p">,</span> <span class="n">_allow_absent_keys</span><span class="o">=</span><span class="n">_allow_absent_keys</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="n">NO_DEFAULT</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">_allow_absent_keys</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> not found.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">is_non_tensor</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">data_out</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">data_out</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_exclude</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">nested_key_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">data_in</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Copies the entries if they&#39;re not part of the list of keys to exclude.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_in</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">data_in</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">td</span><span class="p">,</span> <span class="n">td_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data_in</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_exclude</span><span class="p">(</span><span class="n">nested_key_dict</span><span class="p">,</span> <span class="n">td</span><span class="p">,</span> <span class="n">td_out</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="n">has_set</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data_in</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="n">is_leaf</span><span class="o">=</span><span class="n">_is_leaf_nontensor</span><span class="p">):</span>
            <span class="n">subdict</span> <span class="o">=</span> <span class="n">nested_key_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">NO_DEFAULT</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">subdict</span> <span class="ow">is</span> <span class="n">NO_DEFAULT</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">else</span> <span class="n">value</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">has_set</span> <span class="ow">and</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">data_in</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                <span class="n">out</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">has_set</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="n">subdict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_exclude</span><span class="p">(</span><span class="n">subdict</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_set</span> <span class="ow">and</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">out</span> <span class="o">=</span> <span class="n">data_in</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">has_set</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">has_set</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="o">.</span><span class="n">lazy_stack</span><span class="p">(</span>
                <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">td</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="n">next_td</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">_get_str</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_other</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exclude_from_root</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">next_td</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_grab_and_place</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_root</span><span class="p">,</span>
                <span class="n">tensordict</span><span class="p">,</span>
                <span class="n">out</span><span class="p">,</span>
                <span class="n">_allow_absent_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_allow_absent_keys</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">next_td</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="o">.</span><span class="n">lazy_stack</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">next_td</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="n">next_td</span><span class="o">.</span><span class="n">stack_dim</span>
                <span class="p">)</span>
            <span class="k">for</span> <span class="n">_next_td</span><span class="p">,</span> <span class="n">_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">next_td</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_grab_and_place</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span><span class="p">,</span>
                    <span class="n">_next_td</span><span class="p">,</span>
                    <span class="n">_out</span><span class="p">,</span>
                    <span class="n">_allow_absent_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_allow_absent_keys</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_grab_and_place</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keys_from_next</span><span class="p">,</span>
                <span class="n">next_td</span><span class="p">,</span>
                <span class="n">out</span><span class="p">,</span>
                <span class="n">_allow_absent_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_allow_absent_keys</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<div class="viewcode-block" id="step_mdp"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.step_mdp.html#torchrl.envs.step_mdp">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">step_mdp</span><span class="p">(</span>
    <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">next_tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_other</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">exclude_reward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">exclude_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_action</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">reward_keys</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;reward&quot;</span><span class="p">,</span>
    <span class="n">done_keys</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;done&quot;</span><span class="p">,</span>
    <span class="n">action_keys</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a new tensordict that reflects a step in time of the input tensordict.</span>

<span class="sd">    Given a tensordict retrieved after a step, returns the :obj:`&quot;next&quot;` indexed-tensordict.</span>
<span class="sd">    The arguments allow for precise control over what should be kept and what</span>
<span class="sd">    should be copied from the ``&quot;next&quot;`` entry. The default behavior is:</span>
<span class="sd">    move the observation entries, reward, and done states to the root, exclude</span>
<span class="sd">    the current action, and keep all extra keys (non-action, non-done, non-reward).</span>

<span class="sd">    Args:</span>
<span class="sd">        tensordict (TensorDictBase): The tensordict with keys to be renamed.</span>
<span class="sd">        next_tensordict (TensorDictBase, optional): The destination tensordict. If `None`, a new tensordict is created.</span>
<span class="sd">        keep_other (bool, optional): If ``True``, all keys that do not start with :obj:`&#39;next_&#39;` will be kept.</span>
<span class="sd">            Default is ``True``.</span>
<span class="sd">        exclude_reward (bool, optional): If ``True``, the :obj:`&quot;reward&quot;` key will be discarded</span>
<span class="sd">            from the resulting tensordict. If ``False``, it will be copied (and replaced)</span>
<span class="sd">            from the ``&quot;next&quot;`` entry (if present). Default is ``True``.</span>
<span class="sd">        exclude_done (bool, optional): If ``True``, the :obj:`&quot;done&quot;` key will be discarded</span>
<span class="sd">            from the resulting tensordict. If ``False``, it will be copied (and replaced)</span>
<span class="sd">            from the ``&quot;next&quot;`` entry (if present). Default is ``False``.</span>
<span class="sd">        exclude_action (bool, optional): If ``True``, the :obj:`&quot;action&quot;` key will</span>
<span class="sd">            be discarded from the resulting tensordict. If ``False``, it will</span>
<span class="sd">            be kept in the root tensordict (since it should not be present in</span>
<span class="sd">            the ``&quot;next&quot;`` entry). Default is ``True``.</span>
<span class="sd">        reward_keys (NestedKey or list of NestedKey, optional): The keys where the reward is written. Defaults</span>
<span class="sd">            to &quot;reward&quot;.</span>
<span class="sd">        done_keys (NestedKey or list of NestedKey, optional): The keys where the done is written. Defaults</span>
<span class="sd">            to &quot;done&quot;.</span>
<span class="sd">        action_keys (NestedKey or list of NestedKey, optional): The keys where the action is written. Defaults</span>
<span class="sd">            to &quot;action&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        TensorDictBase: A new tensordict (or `next_tensordict` if provided) containing the tensors of the t+1 step.</span>

<span class="sd">    .. seealso:: :meth:`EnvBase.step_mdp` is the class-based version of this free function. It will attempt to cache the</span>
<span class="sd">        key values to reduce the overhead of making a step in the MDP.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({</span>
<span class="sd">        ...     &quot;done&quot;: torch.zeros((), dtype=torch.bool),</span>
<span class="sd">        ...     &quot;reward&quot;: torch.zeros(()),</span>
<span class="sd">        ...     &quot;extra&quot;: torch.zeros(()),</span>
<span class="sd">        ...     &quot;next&quot;: TensorDict({</span>
<span class="sd">        ...         &quot;done&quot;: torch.zeros((), dtype=torch.bool),</span>
<span class="sd">        ...         &quot;reward&quot;: torch.zeros(()),</span>
<span class="sd">        ...         &quot;obs&quot;: torch.zeros(()),</span>
<span class="sd">        ...     }, []),</span>
<span class="sd">        ...     &quot;obs&quot;: torch.zeros(()),</span>
<span class="sd">        ...     &quot;action&quot;: torch.zeros(()),</span>
<span class="sd">        ... }, [])</span>
<span class="sd">        &gt;&gt;&gt; print(step_mdp(td))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                done: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                extra: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(step_mdp(td, exclude_done=True))  # &quot;done&quot; is dropped</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                extra: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(step_mdp(td, exclude_reward=False))  # &quot;reward&quot; is kept</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                done: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                extra: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                reward: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(step_mdp(td, exclude_action=False))  # &quot;action&quot; persists at the root</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                extra: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(step_mdp(td, keep_other=False))  # &quot;extra&quot; is missing</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                done: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    .. warning:: This function will not work properly if the reward key is also part of the input key when</span>
<span class="sd">        the reward keys are excluded. This is why the :class:`~torchrl.envs.RewardSum` transform registers</span>
<span class="sd">        the episode reward in the observation and not the reward spec by default.</span>
<span class="sd">        When using the fast, cached version of this function (``_StepMDP``), this issue should not</span>
<span class="sd">        be observed.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">next_tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_tensordicts</span> <span class="o">=</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">next_tensordicts</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="o">.</span><span class="n">lazy_stack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">step_mdp</span><span class="p">(</span>
                    <span class="n">td</span><span class="p">,</span>
                    <span class="n">next_tensordict</span><span class="o">=</span><span class="n">ntd</span><span class="p">,</span>
                    <span class="n">keep_other</span><span class="o">=</span><span class="n">keep_other</span><span class="p">,</span>
                    <span class="n">exclude_reward</span><span class="o">=</span><span class="n">exclude_reward</span><span class="p">,</span>
                    <span class="n">exclude_done</span><span class="o">=</span><span class="n">exclude_done</span><span class="p">,</span>
                    <span class="n">exclude_action</span><span class="o">=</span><span class="n">exclude_action</span><span class="p">,</span>
                    <span class="n">reward_keys</span><span class="o">=</span><span class="n">reward_keys</span><span class="p">,</span>
                    <span class="n">done_keys</span><span class="o">=</span><span class="n">done_keys</span><span class="p">,</span>
                    <span class="n">action_keys</span><span class="o">=</span><span class="n">action_keys</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">td</span><span class="p">,</span> <span class="n">ntd</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">next_tensordicts</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">next_tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">next_tensordict</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_keys</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">action_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">action_keys</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">done_keys</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">done_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">done_keys</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_keys</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">reward_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">reward_keys</span><span class="p">]</span>

    <span class="n">excluded</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">exclude_reward</span><span class="p">:</span>
        <span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">reward_keys</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">exclude_done</span><span class="p">:</span>
        <span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">done_keys</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">exclude_action</span><span class="p">:</span>
        <span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">action_keys</span><span class="p">)</span>
    <span class="n">next_td</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">next_td</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>

    <span class="n">total_key</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">if</span> <span class="n">keep_other</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">!=</span> <span class="s2">&quot;next&quot;</span><span class="p">:</span>
                <span class="n">_set</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">total_key</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">exclude_action</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="n">action_keys</span><span class="p">:</span>
            <span class="n">_set_single_key</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">action_key</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">next_td</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">_set</span><span class="p">(</span><span class="n">next_td</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">total_key</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">next_tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">next_tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">out</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_set_single_key</span><span class="p">(</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">dest</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">,</span>
    <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># key should be already unraveled</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span><span class="p">,)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">_get_str</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                <span class="n">new_val</span> <span class="o">=</span> <span class="n">dest</span><span class="o">.</span><span class="n">_get_str</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">new_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                    <span class="n">dest</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span>
                        <span class="n">k</span><span class="p">,</span> <span class="n">new_val</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
                <span class="n">source</span> <span class="o">=</span> <span class="n">val</span>
                <span class="n">dest</span> <span class="o">=</span> <span class="n">new_val</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">device</span><span class="p">:</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">clone</span><span class="p">:</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">dest</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># This is a temporary solution to understand if a key is heterogeneous</span>
        <span class="c1"># while not having performance impact when the exception is not raised</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Found more than one unique shape in the tensors&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">)):</span>
                <span class="c1"># this is a het key</span>
                <span class="k">for</span> <span class="n">s_td</span><span class="p">,</span> <span class="n">d_td</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">dest</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
                    <span class="n">_set_single_key</span><span class="p">(</span><span class="n">s_td</span><span class="p">,</span> <span class="n">d_td</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">clone</span><span class="o">=</span><span class="n">clone</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">err</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_set</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">total_key</span><span class="p">,</span> <span class="n">excluded</span><span class="p">):</span>
    <span class="n">total_key</span> <span class="o">=</span> <span class="n">total_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">key</span><span class="p">,)</span>
    <span class="n">non_empty</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">total_key</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">excluded</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">NonTensorData</span><span class="p">,</span> <span class="n">NonTensorStack</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># if val is a tensordict we need to copy the structure</span>
                <span class="n">new_val</span> <span class="o">=</span> <span class="n">dest</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">new_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                <span class="n">non_empty_local</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">subkey</span> <span class="ow">in</span> <span class="n">val</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">non_empty_local</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">_set</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">new_val</span><span class="p">,</span> <span class="n">subkey</span><span class="p">,</span> <span class="n">total_key</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)</span>
                        <span class="ow">or</span> <span class="n">non_empty_local</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">non_empty_local</span><span class="p">:</span>
                    <span class="c1"># dest.set(key, new_val)</span>
                    <span class="n">dest</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span> <span class="n">new_val</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
                <span class="n">non_empty</span> <span class="o">=</span> <span class="n">non_empty_local</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">non_empty</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="c1"># dest.set(key, val)</span>
                <span class="n">dest</span><span class="o">.</span><span class="n">_set_str</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
        <span class="c1"># This is a temporary solution to understand if a key is heterogeneous</span>
        <span class="c1"># while not having performance impact when the exception is not raised</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Found more than one unique shape in the tensors&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">)):</span>
                <span class="c1"># this is a het key</span>
                <span class="n">non_empty_local</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">s_td</span><span class="p">,</span> <span class="n">d_td</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">dest</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
                    <span class="n">non_empty_local</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">_set</span><span class="p">(</span><span class="n">s_td</span><span class="p">,</span> <span class="n">d_td</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">total_key</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)</span> <span class="ow">or</span> <span class="n">non_empty_local</span>
                    <span class="p">)</span>
                <span class="n">non_empty</span> <span class="o">=</span> <span class="n">non_empty_local</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">err</span>

    <span class="k">return</span> <span class="n">non_empty</span>


<div class="viewcode-block" id="get_available_libraries"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.get_available_libraries.html#torchrl.envs.get_available_libraries">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">get_available_libraries</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns all the supported libraries.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">SUPPORTED_LIBRARIES</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_gym</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns True if the gym library is installed.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;gym&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_gym_atari</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns True if the gym library is installed and atari envs can be found.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_gym</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;atari-py&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_mario</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns True if the &quot;gym-super-mario-bros&quot; library is installed.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;gym-super-mario-bros&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_dmcontrol</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns True if the &quot;dm-control&quot; library is installed.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;dm_control&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_dmlab</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns True if the &quot;deepmind-lab&quot; library is installed.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;deepmind_lab&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="n">SUPPORTED_LIBRARIES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;gym&quot;</span><span class="p">:</span> <span class="n">_check_gym</span><span class="p">(),</span>  <span class="c1"># OpenAI</span>
    <span class="s2">&quot;gym[atari]&quot;</span><span class="p">:</span> <span class="n">_check_gym_atari</span><span class="p">(),</span>  <span class="c1">#</span>
    <span class="s2">&quot;dm_control&quot;</span><span class="p">:</span> <span class="n">_check_dmcontrol</span><span class="p">(),</span>
    <span class="s2">&quot;habitat&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">&quot;gym-super-mario-bros&quot;</span><span class="p">:</span> <span class="n">_check_mario</span><span class="p">(),</span>
    <span class="c1"># &quot;vizdoom&quot;: None,  # gym based, https://github.com/mwydmuch/ViZDoom</span>
    <span class="c1"># &quot;openspiel&quot;: None,  # DM, https://github.com/deepmind/open_spiel</span>
    <span class="c1"># &quot;pysc2&quot;: None,  # DM, https://github.com/deepmind/pysc2</span>
    <span class="c1"># &quot;deepmind_lab&quot;: _check_dmlab(),</span>
    <span class="c1"># DM, https://github.com/deepmind/lab, https://github.com/deepmind/lab/tree/master/python/pip_package</span>
    <span class="c1"># &quot;serpent.ai&quot;: None,  # https://github.com/SerpentAI/SerpentAI</span>
    <span class="c1"># &quot;gfootball&quot;: None,  # 2.8k G, https://github.com/google-research/football</span>
    <span class="c1"># DM, https://github.com/deepmind/dm_control</span>
    <span class="c1"># FB, https://github.com/facebookresearch/habitat-sim</span>
    <span class="c1"># &quot;meta-world&quot;: None,  # https://github.com/rlworkgroup/metaworld</span>
    <span class="c1"># &quot;minerl&quot;: None,  # https://github.com/minerllabs/minerl</span>
    <span class="c1"># &quot;multi-agent-emergence-environments&quot;: None,</span>
    <span class="c1"># OpenAI, https://github.com/openai/multi-agent-emergence-environments</span>
    <span class="c1"># &quot;procgen&quot;: None,  # OpenAI, https://github.com/openai/procgen</span>
    <span class="c1"># &quot;pybullet&quot;: None,  # https://github.com/benelot/pybullet-gym</span>
    <span class="c1"># &quot;realworld_rl_suite&quot;: None,</span>
    <span class="c1"># G, https://github.com/google-research/realworldrl_suite</span>
    <span class="c1"># &quot;rlcard&quot;: None,  # https://github.com/datamllab/rlcard</span>
    <span class="c1"># &quot;screeps&quot;: None,  # https://github.com/screeps/screeps</span>
    <span class="c1"># &quot;ml-agents&quot;: None,</span>
<span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_per_level_env_check</span><span class="p">(</span><span class="n">data0</span><span class="p">,</span> <span class="n">data1</span><span class="p">,</span> <span class="n">check_dtype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Checks shape and dtype of two tensordicts, accounting for lazy stacks.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data0</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_data0</span><span class="p">,</span> <span class="n">_data1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data0</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">data1</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">data0</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)):</span>
            <span class="n">_per_level_env_check</span><span class="p">(</span><span class="n">_data0</span><span class="p">,</span> <span class="n">_data1</span><span class="p">,</span> <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span><span class="p">)</span>
        <span class="k">return</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_data0</span><span class="p">,</span> <span class="n">_data1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data0</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">data1</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">),</span> <span class="n">data1</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
            <span class="n">_per_level_env_check</span><span class="p">(</span><span class="n">_data0</span><span class="p">,</span> <span class="n">_data1</span><span class="p">,</span> <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span><span class="p">)</span>
        <span class="k">return</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">keys0</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">data0</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">keys1</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">data1</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">keys0</span> <span class="o">!=</span> <span class="n">keys1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Keys mismatch: </span><span class="si">{</span><span class="n">keys0</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="n">keys1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys0</span><span class="p">:</span>
            <span class="n">_data0</span> <span class="o">=</span> <span class="n">data0</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">_data1</span> <span class="o">=</span> <span class="n">data1</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">_data0</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">_data1</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The shapes of the real and fake tensordict don&#39;t match for key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got fake=</span><span class="si">{</span><span class="n">_data0</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and real=</span><span class="si">{</span><span class="n">_data1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_data0</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                <span class="n">_per_level_env_check</span><span class="p">(</span><span class="n">_data0</span><span class="p">,</span> <span class="n">_data1</span><span class="p">,</span> <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">check_dtype</span> <span class="ow">and</span> <span class="p">(</span><span class="n">_data0</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">_data1</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The dtypes of the real and fake tensordict don&#39;t match for key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Got fake=</span><span class="si">{</span><span class="n">_data0</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and real=</span><span class="si">{</span><span class="n">_data1</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>


<div class="viewcode-block" id="check_env_specs"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.check_env_specs.html#torchrl.envs.check_env_specs">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">check_env_specs</span><span class="p">(</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">torchrl</span><span class="o">.</span><span class="n">envs</span><span class="o">.</span><span class="n">EnvBase</span><span class="p">,</span>  <span class="c1"># noqa</span>
    <span class="n">return_contiguous</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">check_dtype</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">break_when_any_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tests an environment specs against the results of short rollout.</span>

<span class="sd">    This test function should be used as a sanity check for an env wrapped with</span>
<span class="sd">    torchrl&#39;s EnvBase subclasses: any discrepancy between the expected data and</span>
<span class="sd">    the data collected should raise an assertion error.</span>

<span class="sd">    A broken environment spec will likely make it impossible to use parallel</span>
<span class="sd">    environments.</span>

<span class="sd">    Args:</span>
<span class="sd">        env (EnvBase): the env for which the specs have to be checked against data.</span>
<span class="sd">        return_contiguous (bool, optional): if ``True``, the random rollout will be called with</span>
<span class="sd">            return_contiguous=True. This will fail in some cases (e.g. heterogeneous shapes</span>
<span class="sd">            of inputs/outputs). Defaults to ``None`` (determined by the presence of dynamic specs).</span>
<span class="sd">        check_dtype (bool, optional): if False, dtype checks will be skipped.</span>
<span class="sd">            Defaults to True.</span>
<span class="sd">        seed (int, optional): for reproducibility, a seed can be set.</span>
<span class="sd">            The seed will be set in pytorch temporarily, then the RNG state will</span>
<span class="sd">            be reverted to what it was before. For the env, we set the seed but since</span>
<span class="sd">            setting the rng state back to what is was isn&#39;t a feature of most environment,</span>
<span class="sd">            we leave it to the user to accomplish that.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        tensordict (TensorDict, optional): an optional tensordict instance to use for reset.</span>
<span class="sd">        break_when_any_done (bool or str, optional): value for ``break_when_any_done`` in :meth:`~torchrl.envs.EnvBase.rollout`.</span>
<span class="sd">            If ``&quot;both&quot;``, the test is run on both `True` and `False`.</span>

<span class="sd">    Caution: this function resets the env seed. It should be used &quot;offline&quot; to</span>
<span class="sd">    check that an env is adequately constructed, but it may affect the seeding</span>
<span class="sd">    of an experiment and as such should be kept out of training scripts.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">return_contiguous</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">return_contiguous</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">env</span><span class="o">.</span><span class="n">_has_dynamic_specs</span>
    <span class="k">if</span> <span class="n">break_when_any_done</span> <span class="o">==</span> <span class="s2">&quot;both&quot;</span><span class="p">:</span>
        <span class="n">check_env_specs</span><span class="p">(</span>
            <span class="n">env</span><span class="p">,</span>
            <span class="n">return_contiguous</span><span class="o">=</span><span class="n">return_contiguous</span><span class="p">,</span>
            <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">tensordict</span><span class="o">=</span><span class="n">tensordict</span><span class="p">,</span>
            <span class="n">break_when_any_done</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">check_env_specs</span><span class="p">(</span>
            <span class="n">env</span><span class="p">,</span>
            <span class="n">return_contiguous</span><span class="o">=</span><span class="n">return_contiguous</span><span class="p">,</span>
            <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">tensordict</span><span class="o">=</span><span class="n">tensordict</span><span class="p">,</span>
            <span class="n">break_when_any_done</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">env</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">env</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">env</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">_rng_decorator</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">):</span>
            <span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">check_env_specs</span><span class="p">(</span>
                <span class="n">env</span><span class="p">,</span> <span class="n">return_contiguous</span><span class="o">=</span><span class="n">return_contiguous</span><span class="p">,</span> <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span>
            <span class="p">)</span>

    <span class="n">fake_tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">env</span><span class="o">.</span><span class="n">batch_locked</span> <span class="ow">and</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">fake_tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">fake_tensordict</span> <span class="o">=</span> <span class="n">fake_tensordict</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">real_tensordict</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="n">return_contiguous</span><span class="o">=</span><span class="n">return_contiguous</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="o">=</span><span class="n">tensordict</span><span class="p">,</span>
        <span class="n">auto_reset</span><span class="o">=</span><span class="n">tensordict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">break_when_any_done</span><span class="o">=</span><span class="n">break_when_any_done</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">return_contiguous</span><span class="p">:</span>
        <span class="n">fake_tensordict</span> <span class="o">=</span> <span class="n">fake_tensordict</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">real_tensordict</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">fake_tensordict</span> <span class="o">=</span> <span class="n">fake_tensordict</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">real_tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fake_tensordict</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="o">.</span><span class="n">lazy_stack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">fake_tensordict</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">)</span>
    <span class="c1"># eliminate empty containers</span>
    <span class="n">fake_tensordict_select</span> <span class="o">=</span> <span class="n">fake_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
        <span class="o">*</span><span class="n">fake_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">_default_is_leaf</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">real_tensordict_select</span> <span class="o">=</span> <span class="n">real_tensordict</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
        <span class="o">*</span><span class="n">real_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">_default_is_leaf</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># check keys</span>
    <span class="n">fake_tensordict_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span>
        <span class="n">fake_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">_is_leaf_nontensor</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">real_tensordict_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span>
        <span class="n">real_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">is_leaf</span><span class="o">=</span><span class="n">_is_leaf_nontensor</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">fake_tensordict_keys</span> <span class="o">!=</span> <span class="n">real_tensordict_keys</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&quot;&quot;The keys of the specs and data do not match:</span>
<span class="s2">    - List of keys present in real but not in fake: </span><span class="si">{</span><span class="n">real_tensordict_keys</span><span class="o">-</span><span class="n">fake_tensordict_keys</span><span class="si">}</span><span class="s2">,</span>
<span class="s2">    - List of keys present in fake but not in real: </span><span class="si">{</span><span class="n">fake_tensordict_keys</span><span class="o">-</span><span class="n">real_tensordict_keys</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">&quot;&quot;&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">zeroing_err_msg</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="s2">&quot;zeroing the two tensordicts did not make them identical. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Check for discrepancies:</span><span class="se">\n</span><span class="s2">Fake=</span><span class="se">\n</span><span class="si">{</span><span class="n">fake_tensordict</span><span class="si">}</span><span class="se">\n</span><span class="s2">Real=</span><span class="se">\n</span><span class="si">{</span><span class="n">real_tensordict</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">_has_dynamic_specs</span>

    <span class="k">if</span> <span class="n">_has_dynamic_specs</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">specs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">fake</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">real_tensordict_select</span><span class="o">.</span><span class="n">filter_non_tensor_data</span><span class="p">()</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">fake_tensordict_select</span><span class="o">.</span><span class="n">filter_non_tensor_data</span><span class="p">()</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">):</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="n">fake</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">real</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">real</span><span class="p">)</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake</span><span class="p">))</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="n">zeroing_err_msg</span><span class="p">())</span>

            <span class="c1"># Checks shapes and eventually dtypes of keys at all nesting levels</span>
            <span class="n">_per_level_env_check</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_tensordict_select</span><span class="p">)</span>
            <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">real_tensordict_select</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="n">zeroing_err_msg</span><span class="p">())</span>

        <span class="c1"># Checks shapes and eventually dtypes of keys at all nesting levels</span>
        <span class="n">_per_level_env_check</span><span class="p">(</span>
            <span class="n">fake_tensordict_select</span><span class="p">,</span> <span class="n">real_tensordict_select</span><span class="p">,</span> <span class="n">check_dtype</span><span class="o">=</span><span class="n">check_dtype</span>
        <span class="p">)</span>

    <span class="c1"># Check specs</span>
    <span class="n">last_td</span> <span class="o">=</span> <span class="n">real_tensordict</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">last_td</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rand_action</span><span class="p">(</span><span class="n">last_td</span><span class="p">)</span>
    <span class="n">full_action_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
    <span class="n">full_state_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_state_spec&quot;</span><span class="p">]</span>
    <span class="n">full_observation_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">]</span>
    <span class="n">full_reward_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]</span>
    <span class="n">full_done_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="s2">&quot;full_done_spec&quot;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="p">(</span>
        <span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">full_action_spec</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">,</span> <span class="n">full_state_spec</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">full_observation_spec</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">check_no_exclusive_keys</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="s2">&quot;It appears you are using some LazyStackedCompositeSpecs with exclusive keys &quot;</span>
                <span class="s2">&quot;(keys present in some but not all of the stacked specs). To use such heterogeneous specs, &quot;</span>
                <span class="s2">&quot;you will need to first pass your stack through `torchrl.data.consolidate_spec`.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">last_td</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">spec</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">td</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;spec check failed at root for spec </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">spec</span><span class="si">}</span><span class="s2"> and data </span><span class="si">{</span><span class="n">td</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="p">(</span>
        <span class="p">(</span><span class="s2">&quot;reward&quot;</span><span class="p">,</span> <span class="n">full_reward_spec</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">full_observation_spec</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">last_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">spec</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">td</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;spec check failed at root for spec </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">spec</span><span class="si">}</span><span class="s2"> and data </span><span class="si">{</span><span class="n">td</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;check_env_specs succeeded!&quot;</span><span class="p">)</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_selective_unsqueeze</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">shape_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">shape_len</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Tensor has less dims than batch_size. shape:</span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, batch_size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Tensor does not have given batch_size. shape:</span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, batch_size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">shape_len</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_sort_keys</span><span class="p">(</span><span class="n">element</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">element</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">element</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;_-|-_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">element</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">element</span>


<div class="viewcode-block" id="make_composite_from_td"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.make_composite_from_td.html#torchrl.envs.make_composite_from_td">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">make_composite_from_td</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">unsqueeze_null_shapes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dynamic_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a Composite instance from a tensordict, assuming all values are unbounded.</span>

<span class="sd">    Args:</span>
<span class="sd">        data (tensordict.TensorDict): a tensordict to be mapped onto a Composite.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        unsqueeze_null_shapes (bool, optional): if ``True``, every empty shape will be</span>
<span class="sd">            unsqueezed to (1,). Defaults to ``True``.</span>
<span class="sd">        dynamic_shape (bool, optional): if ``True``, all tensors will be assumed to have a dynamic shape</span>
<span class="sd">            along the last dimension. Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({</span>
<span class="sd">        ...     &quot;obs&quot;: torch.randn(3),</span>
<span class="sd">        ...     &quot;action&quot;: torch.zeros(2, dtype=torch.int),</span>
<span class="sd">        ...     &quot;next&quot;: {&quot;obs&quot;: torch.randn(3), &quot;reward&quot;: torch.randn(1)}</span>
<span class="sd">        ... }, [])</span>
<span class="sd">        &gt;&gt;&gt; spec = make_composite_from_td(data)</span>
<span class="sd">        &gt;&gt;&gt; print(spec)</span>
<span class="sd">        Composite(</span>
<span class="sd">            obs: UnboundedContinuous(</span>
<span class="sd">                 shape=torch.Size([3]), space=None, device=cpu, dtype=torch.float32, domain=continuous),</span>
<span class="sd">            action: UnboundedContinuous(</span>
<span class="sd">                 shape=torch.Size([2]), space=None, device=cpu, dtype=torch.int32, domain=continuous),</span>
<span class="sd">            next: Composite(</span>
<span class="sd">                obs: UnboundedContinuous(</span>
<span class="sd">                     shape=torch.Size([3]), space=None, device=cpu, dtype=torch.float32, domain=continuous),</span>
<span class="sd">                reward: UnboundedContinuous(</span>
<span class="sd">                     shape=torch.Size([1]), space=ContinuousBox(low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True), high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)), device=cpu, dtype=torch.float32, domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))</span>
<span class="sd">        &gt;&gt;&gt; assert (spec.zero() == data.zero_()).all()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># custom function to convert a tensordict in a similar spec structure</span>
    <span class="c1"># of unbounded values.</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">unsqueeze_null_shapes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dynamic_shape</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">shape</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">composite</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">make_composite_from_td</span><span class="p">(</span>
                <span class="n">tensor</span><span class="p">,</span>
                <span class="n">unsqueeze_null_shapes</span><span class="o">=</span><span class="n">unsqueeze_null_shapes</span><span class="p">,</span>
                <span class="n">dynamic_shape</span><span class="o">=</span><span class="n">dynamic_shape</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_non_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">NonTensor</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">example_data</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">is_non_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">Unbounded</span><span class="p">(</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">make_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">},</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">data_cls</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">composite</span></div>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">clear_mpi_env_vars</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Clears the MPI of environment variables.</span>

<span class="sd">    `from mpi4py import MPI` will call `MPI_Init` by default.</span>
<span class="sd">    If the child process has MPI environment variables, MPI will think that the child process</span>
<span class="sd">    is an MPI process just like the parent and do bad things such as hang.</span>

<span class="sd">    This context manager is a hacky way to clear those environment variables</span>
<span class="sd">    temporarily such as when we are starting multiprocessing Processes.</span>

<span class="sd">    Yields:</span>
<span class="sd">        Yields for the context manager</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">removed_environment</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">for</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;OMPI_&quot;</span><span class="p">,</span> <span class="s2">&quot;PMI_&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">prefix</span><span class="p">):</span>
                <span class="n">removed_environment</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                <span class="k">del</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">removed_environment</span><span class="p">)</span>


<div class="viewcode-block" id="MarlGroupMapType"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.MarlGroupMapType.html#torchrl.envs.MarlGroupMapType">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">MarlGroupMapType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Marl Group Map Type.</span>

<span class="sd">    As a feature of torchrl multiagent, you are able to control the grouping of agents in your environment.</span>
<span class="sd">    You can group agents together (stacking their tensors) to leverage vectorization when passing them through the same</span>
<span class="sd">    neural network. You can split agents in different groups where they are heterogenous or should be processed by</span>
<span class="sd">    different neural networks. To group, you just need to pass a ``group_map`` at env constructiuon time.</span>

<span class="sd">    Otherwise, you can choose one of the premade grouping strategies from this class.</span>

<span class="sd">    - With ``group_map=MarlGroupMapType.ALL_IN_ONE_GROUP`` and</span>
<span class="sd">      agents ``[&quot;agent_0&quot;, &quot;agent_1&quot;, &quot;agent_2&quot;, &quot;agent_3&quot;]``,</span>
<span class="sd">      the tensordicts coming and going from your environment will look</span>
<span class="sd">      something like:</span>

<span class="sd">        &gt;&gt;&gt; print(env.rand_action(env.reset()))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                agents: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        action: Tensor(shape=torch.Size([4, 9]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        done: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([4, 3, 3, 2]), device=cpu, dtype=torch.int8, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([4]))},</span>
<span class="sd">            batch_size=torch.Size([]))</span>
<span class="sd">        &gt;&gt;&gt; print(env.group_map)</span>
<span class="sd">        {&quot;agents&quot;: [&quot;agent_0&quot;, &quot;agent_1&quot;, &quot;agent_2&quot;, &quot;agent_3]}</span>

<span class="sd">    - With ``group_map=MarlGroupMapType.ONE_GROUP_PER_AGENT`` and</span>
<span class="sd">      agents ``[&quot;agent_0&quot;, &quot;agent_1&quot;, &quot;agent_2&quot;, &quot;agent_3&quot;]``,</span>
<span class="sd">      the tensordicts coming and going from your environment will look</span>
<span class="sd">      something like:</span>

<span class="sd">        &gt;&gt;&gt; print(env.rand_action(env.reset()))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                agent_0: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        action: Tensor(shape=torch.Size([9]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3, 2]), device=cpu, dtype=torch.int8, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]))},</span>
<span class="sd">                agent_1: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        action: Tensor(shape=torch.Size([9]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3, 2]), device=cpu, dtype=torch.int8, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]))},</span>
<span class="sd">                agent_2: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        action: Tensor(shape=torch.Size([9]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3, 2]), device=cpu, dtype=torch.int8, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]))},</span>
<span class="sd">                agent_3: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        action: Tensor(shape=torch.Size([9]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([3, 3, 2]), device=cpu, dtype=torch.int8, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]))},</span>
<span class="sd">            batch_size=torch.Size([]))</span>
<span class="sd">        &gt;&gt;&gt; print(env.group_map)</span>
<span class="sd">        {&quot;agent_0&quot;: [&quot;agent_0&quot;], &quot;agent_1&quot;: [&quot;agent_1&quot;], &quot;agent_2&quot;: [&quot;agent_2&quot;], &quot;agent_3&quot;: [&quot;agent_3&quot;]}</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ALL_IN_ONE_GROUP</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ONE_GROUP_PER_AGENT</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_group_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="k">if</span> <span class="bp">self</span> <span class="o">==</span> <span class="n">MarlGroupMapType</span><span class="o">.</span><span class="n">ALL_IN_ONE_GROUP</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;agents&quot;</span><span class="p">:</span> <span class="n">agent_names</span><span class="p">}</span>
        <span class="k">elif</span> <span class="bp">self</span> <span class="o">==</span> <span class="n">MarlGroupMapType</span><span class="o">.</span><span class="n">ONE_GROUP_PER_AGENT</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">agent_name</span><span class="p">:</span> <span class="p">[</span><span class="n">agent_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">agent_name</span> <span class="ow">in</span> <span class="n">agent_names</span><span class="p">}</span></div>


<div class="viewcode-block" id="check_marl_grouping"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.check_marl_grouping.html#torchrl.envs.check_marl_grouping">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">check_marl_grouping</span><span class="p">(</span><span class="n">group_map</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">agent_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check MARL group map.</span>

<span class="sd">    Performs checks on the group map of a marl environment to assess its validity.</span>
<span class="sd">    Raises an error in cas of an invalid group_map.</span>

<span class="sd">    Args:</span>
<span class="sd">        group_map (Dict[str, List[str]]): the group map mapping group names to list of agent names in the group</span>
<span class="sd">        agent_names (List[str]): a list of all the agent names in the environment4</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.utils import MarlGroupMapType, check_marl_grouping</span>
<span class="sd">        &gt;&gt;&gt; agent_names = [&quot;agent_0&quot;, &quot;agent_1&quot;, &quot;agent_2&quot;]</span>
<span class="sd">        &gt;&gt;&gt; check_marl_grouping(MarlGroupMapType.ALL_IN_ONE_GROUP.get_group_map(agent_names), agent_names)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_agents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">agent_names</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_agents</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No agents passed&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">agent_names</span><span class="p">))</span> <span class="o">!=</span> <span class="n">n_agents</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;There are agents with the same name&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">group_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&gt;</span> <span class="n">n_agents</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Number of groups </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">group_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> greater than number of agents </span><span class="si">{</span><span class="n">n_agents</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">found_agents</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent_name</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">agent_name</span> <span class="ow">in</span> <span class="n">agent_names</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">group_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is empty&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">agent_name</span> <span class="ow">in</span> <span class="n">group</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">agent_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">found_agents</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Agent </span><span class="si">{</span><span class="n">agent_name</span><span class="si">}</span><span class="s2"> not present in environment&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">found_agents</span><span class="p">[</span><span class="n">agent_name</span><span class="p">]:</span>
                <span class="n">found_agents</span><span class="p">[</span><span class="n">agent_name</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Agent </span><span class="si">{</span><span class="n">agent_name</span><span class="si">}</span><span class="s2"> present more than once&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">agent_name</span><span class="p">,</span> <span class="n">found</span> <span class="ow">in</span> <span class="n">found_agents</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Agent </span><span class="si">{</span><span class="n">agent_name</span><span class="si">}</span><span class="s2"> not found in any group&quot;</span><span class="p">)</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_terminated_or_truncated</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">full_done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;_reset&quot;</span><span class="p">,</span>
    <span class="n">write_full_false</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reads the done / terminated / truncated keys within a tensordict, and writes a new tensor where the values of both signals are aggregated.</span>

<span class="sd">    The modification occurs in-place within the TensorDict instance provided.</span>
<span class="sd">    This function can be used to compute the `&quot;_reset&quot;` signals in batched</span>
<span class="sd">    or multiagent settings, hence the default name of the output key.</span>

<span class="sd">    Args:</span>
<span class="sd">        data (TensorDictBase): the input data, generally resulting from a call</span>
<span class="sd">            to :meth:`~torchrl.envs.EnvBase.step`.</span>
<span class="sd">        full_done_spec (TensorSpec, optional): the done_spec from the env,</span>
<span class="sd">            indicating where the done leaves have to be found.</span>
<span class="sd">            If not provided, the default</span>
<span class="sd">            ``&quot;done&quot;``, ``&quot;terminated&quot;`` and ``&quot;truncated&quot;`` entries will be</span>
<span class="sd">            searched for in the data.</span>
<span class="sd">        key (NestedKey, optional): where the aggregated result should be written.</span>
<span class="sd">            If ``None``, then the function will not write any key but just output</span>
<span class="sd">            whether any of the done values was true.</span>
<span class="sd">            .. note:: if a value is already present for the ``key`` entry,</span>
<span class="sd">                the previous value will prevail and no update will be achieved.</span>
<span class="sd">        write_full_false (bool, optional): if ``True``, the reset keys will be</span>
<span class="sd">            written even if the output is ``False`` (ie, no done is ``True``</span>
<span class="sd">            in the provided data structure).</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Returns: a boolean value indicating whether any of the done states found in the data</span>
<span class="sd">        contained a ``True``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.tensor_specs import Categorical</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; spec = Composite(</span>
<span class="sd">        ...     done=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...     truncated=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...     nested=Composite(</span>
<span class="sd">        ...         done=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...         truncated=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...     )</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({</span>
<span class="sd">        ...     &quot;done&quot;: True, &quot;truncated&quot;: False,</span>
<span class="sd">        ...     &quot;nested&quot;: {&quot;done&quot;: False, &quot;truncated&quot;: True}},</span>
<span class="sd">        ...     batch_size=[]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = _terminated_or_truncated(data, spec)</span>
<span class="sd">        &gt;&gt;&gt; print(data[&quot;_reset&quot;])</span>
<span class="sd">        tensor(True)</span>
<span class="sd">        &gt;&gt;&gt; print(data[&quot;nested&quot;, &quot;_reset&quot;])</span>
<span class="sd">        tensor(True)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">list_of_keys</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">inner_terminated_or_truncated</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">curr_done_key</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">any_eot</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">aggregate</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">full_done_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tds</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">found_leaf</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">eot_key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">eot_key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;terminated&quot;</span><span class="p">,</span> <span class="s2">&quot;truncated&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">):</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">item</span>
                    <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">aggregate</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">aggregate</span> <span class="o">=</span> <span class="n">aggregate</span> <span class="o">|</span> <span class="n">done</span>
                    <span class="n">found_leaf</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                    <span class="n">tds</span><span class="p">[</span><span class="n">eot_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">item</span>
            <span class="c1"># The done signals in a root td prevail over done in the leaves</span>
            <span class="k">if</span> <span class="n">tds</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">eot_key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">tds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">any_eot_td</span> <span class="o">=</span> <span class="n">inner_terminated_or_truncated</span><span class="p">(</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">item</span><span class="p">,</span>
                        <span class="n">full_done_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
                        <span class="n">curr_done_key</span><span class="o">=</span><span class="n">curr_done_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">eot_key</span><span class="p">,),</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">found_leaf</span><span class="p">:</span>
                        <span class="n">any_eot</span> <span class="o">=</span> <span class="n">any_eot</span> <span class="o">|</span> <span class="n">any_eot_td</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">composite_spec</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">found_leaf</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">eot_key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">full_done_spec</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
                    <span class="n">composite_spec</span><span class="p">[</span><span class="n">eot_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">item</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">found_leaf</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">stop</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">eot_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">stop</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">aggregate</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">aggregate</span> <span class="o">=</span> <span class="n">aggregate</span> <span class="o">|</span> <span class="n">stop</span>
            <span class="c1"># The done signals in a root td prevail over done in the leaves</span>
            <span class="k">if</span> <span class="n">composite_spec</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">eot_key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">composite_spec</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">any_eot_td</span> <span class="o">=</span> <span class="n">inner_terminated_or_truncated</span><span class="p">(</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">eot_key</span><span class="p">),</span>
                        <span class="n">full_done_spec</span><span class="o">=</span><span class="n">item</span><span class="p">,</span>
                        <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
                        <span class="n">curr_done_key</span><span class="o">=</span><span class="n">curr_done_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">eot_key</span><span class="p">,),</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">found_leaf</span><span class="p">:</span>
                        <span class="n">any_eot</span> <span class="o">=</span> <span class="n">any_eot_td</span> <span class="o">|</span> <span class="n">any_eot</span>

        <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">aggregate</span><span class="p">)</span>
                <span class="n">list_of_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_done_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">key</span><span class="p">,))</span>
            <span class="n">any_eot</span> <span class="o">=</span> <span class="n">any_eot</span> <span class="o">|</span> <span class="n">aggregate</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">any_eot</span>

    <span class="n">any_eot</span> <span class="o">=</span> <span class="n">inner_terminated_or_truncated</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">any_eot</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">write_full_false</span><span class="p">:</span>
        <span class="c1"># remove the list of reset keys</span>
        <span class="n">data</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">list_of_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">any_eot</span>


<div class="viewcode-block" id="terminated_or_truncated"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.terminated_or_truncated.html#torchrl.envs.terminated_or_truncated">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">terminated_or_truncated</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">full_done_spec</span><span class="p">:</span> <span class="n">TensorSpec</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_reset&quot;</span><span class="p">,</span>
    <span class="n">write_full_false</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reads the done / terminated / truncated keys within a tensordict, and writes a new tensor where the values of both signals are aggregated.</span>

<span class="sd">    The modification occurs in-place within the TensorDict instance provided.</span>
<span class="sd">    This function can be used to compute the `&quot;_reset&quot;` signals in batched</span>
<span class="sd">    or multiagent settings, hence the default name of the output key.</span>

<span class="sd">    Args:</span>
<span class="sd">        data (TensorDictBase): the input data, generally resulting from a call</span>
<span class="sd">            to :meth:`~torchrl.envs.EnvBase.step`.</span>
<span class="sd">        full_done_spec (TensorSpec, optional): the done_spec from the env,</span>
<span class="sd">            indicating where the done leaves have to be found.</span>
<span class="sd">            If not provided, the default</span>
<span class="sd">            ``&quot;done&quot;``, ``&quot;terminated&quot;`` and ``&quot;truncated&quot;`` entries will be</span>
<span class="sd">            searched for in the data.</span>
<span class="sd">        key (NestedKey, optional): where the aggregated result should be written.</span>
<span class="sd">            If ``None``, then the function will not write any key but just output</span>
<span class="sd">            whether any of the done values was true.</span>
<span class="sd">            .. note:: if a value is already present for the ``key`` entry,</span>
<span class="sd">                the previous value will prevail and no update will be achieved.</span>
<span class="sd">        write_full_false (bool, optional): if ``True``, the reset keys will be</span>
<span class="sd">            written even if the output is ``False`` (ie, no done is ``True``</span>
<span class="sd">            in the provided data structure).</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Returns: a boolean value indicating whether any of the done states found in the data</span>
<span class="sd">        contained a ``True``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.tensor_specs import Categorical</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; spec = Composite(</span>
<span class="sd">        ...     done=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...     truncated=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...     nested=Composite(</span>
<span class="sd">        ...         done=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...         truncated=Categorical(2, dtype=torch.bool),</span>
<span class="sd">        ...     )</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({</span>
<span class="sd">        ...     &quot;done&quot;: True, &quot;truncated&quot;: False,</span>
<span class="sd">        ...     &quot;nested&quot;: {&quot;done&quot;: False, &quot;truncated&quot;: True}},</span>
<span class="sd">        ...     batch_size=[]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = _terminated_or_truncated(data, spec)</span>
<span class="sd">        &gt;&gt;&gt; print(data[&quot;_reset&quot;])</span>
<span class="sd">        tensor(True)</span>
<span class="sd">        &gt;&gt;&gt; print(data[&quot;nested&quot;, &quot;_reset&quot;])</span>
<span class="sd">        tensor(True)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">list_of_keys</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">inner_terminated_or_truncated</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">curr_done_key</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">any_eot</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">aggregate</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">full_done_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">eot_key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">eot_key</span> <span class="o">==</span> <span class="s2">&quot;done&quot;</span><span class="p">:</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">eot_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">aggregate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">done</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">aggregate</span> <span class="o">=</span> <span class="n">aggregate</span> <span class="o">|</span> <span class="n">done</span>
                <span class="k">elif</span> <span class="n">eot_key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;terminated&quot;</span><span class="p">,</span> <span class="s2">&quot;truncated&quot;</span><span class="p">):</span>
                    <span class="n">done</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">eot_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">done</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">aggregate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">done</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">aggregate</span> <span class="o">=</span> <span class="n">aggregate</span> <span class="o">|</span> <span class="n">done</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                    <span class="n">any_eot</span> <span class="o">=</span> <span class="n">any_eot</span> <span class="o">|</span> <span class="n">inner_terminated_or_truncated</span><span class="p">(</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">item</span><span class="p">,</span>
                        <span class="n">full_done_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
                        <span class="n">curr_done_key</span><span class="o">=</span><span class="n">curr_done_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">eot_key</span><span class="p">,),</span>
                    <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">eot_key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">full_done_spec</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
                    <span class="n">any_eot</span> <span class="o">=</span> <span class="n">any_eot</span> <span class="o">|</span> <span class="n">inner_terminated_or_truncated</span><span class="p">(</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">eot_key</span><span class="p">),</span>
                        <span class="n">full_done_spec</span><span class="o">=</span><span class="n">item</span><span class="p">,</span>
                        <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
                        <span class="n">curr_done_key</span><span class="o">=</span><span class="n">curr_done_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">eot_key</span><span class="p">,),</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">sop</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">eot_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">sop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">sop</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">aggregate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sop</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">aggregate</span> <span class="o">=</span> <span class="n">aggregate</span> <span class="o">|</span> <span class="n">sop</span>
        <span class="k">if</span> <span class="n">aggregate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">aggregate</span><span class="p">)</span>
                <span class="n">list_of_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_done_key</span> <span class="o">+</span> <span class="p">(</span><span class="n">key</span><span class="p">,))</span>
            <span class="n">any_eot</span> <span class="o">=</span> <span class="n">any_eot</span> <span class="o">|</span> <span class="n">aggregate</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">any_eot</span>

    <span class="n">any_eot</span> <span class="o">=</span> <span class="n">inner_terminated_or_truncated</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">full_done_spec</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">any_eot</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">write_full_false</span><span class="p">:</span>
        <span class="c1"># remove the list of reset keys</span>
        <span class="n">data</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">list_of_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">any_eot</span></div>


<span class="n">PARTIAL_MISSING_ERR</span> <span class="o">=</span> <span class="s2">&quot;Some reset keys were present but not all. Either all the `&#39;_reset&#39;` entries must be present, or none.&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_aggregate_end_of_traj</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">reset_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">done_keys</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="c1"># goes through the tensordict and brings the _reset information to</span>
    <span class="c1"># a boolean tensor of the shape of the tensordict.</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">done_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">reset_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">reset_keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">_replace_last</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">done_keys</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">reset_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">reset</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">has_missing</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">reset_keys</span><span class="p">:</span>
            <span class="n">local_reset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">local_reset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">has_missing</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">PARTIAL_MISSING_ERR</span><span class="p">)</span>
                <span class="n">has_missing</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">continue</span>
            <span class="k">elif</span> <span class="n">has_missing</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">PARTIAL_MISSING_ERR</span><span class="p">)</span>
            <span class="n">has_missing</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span>
                <span class="n">local_reset</span> <span class="o">=</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">local_reset</span> <span class="o">=</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span> <span class="o">|</span> <span class="n">local_reset</span>
        <span class="k">if</span> <span class="n">has_missing</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reset</span>

    <span class="n">reset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">skim_through</span><span class="p">(</span><span class="n">td</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="n">reset</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;_reset&quot;</span><span class="p">:</span>
                <span class="n">local_reset</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span>
                    <span class="n">local_reset</span> <span class="o">=</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">local_reset</span> <span class="o">=</span> <span class="n">local_reset</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span> <span class="o">|</span> <span class="n">local_reset</span>
            <span class="c1"># we need to check the entry class without getting the value,</span>
            <span class="c1"># because some lazy tensordicts may prevent calls to items().</span>
            <span class="c1"># This introduces some slight overhead as when we encounter a</span>
            <span class="c1"># tensordict item, we&#39;ll need to get it twice.</span>
            <span class="k">elif</span> <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">entry_class</span><span class="p">(</span><span class="n">key</span><span class="p">)):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">skim_through</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="n">reset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reset</span>

    <span class="n">reset</span> <span class="o">=</span> <span class="n">skim_through</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">reset</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_update_during_reset</span><span class="p">(</span>
    <span class="n">tensordict_reset</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">reset_keys</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">],</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates the input tensordict with the reset data, based on the reset keys.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">reset_keys</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tensordict_reset</span><span class="p">)</span>
    <span class="n">roots</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">reset_key</span> <span class="ow">in</span> <span class="n">reset_keys</span><span class="p">:</span>
        <span class="c1"># get the node of the reset key</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="c1"># the reset key *must* have gone through unravel_key</span>
            <span class="c1"># we don&#39;t test it to avoid induced overhead</span>
            <span class="n">node_key</span> <span class="o">=</span> <span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">node_reset</span> <span class="o">=</span> <span class="n">tensordict_reset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">node_key</span><span class="p">)</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">node_key</span><span class="p">)</span>
            <span class="n">reset_key_tuple</span> <span class="o">=</span> <span class="n">reset_key</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">node_reset</span> <span class="o">=</span> <span class="n">tensordict_reset</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">tensordict</span>
            <span class="n">reset_key_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="n">reset_key</span><span class="p">,)</span>
        <span class="c1"># get the reset signal</span>
        <span class="n">reset</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># check if this reset should be ignored -- this happens whenever the</span>
        <span class="c1"># root node has already been updated</span>
        <span class="n">root</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">reset_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">processed</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">reset_key_tuple</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span> <span class="o">==</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">roots</span><span class="p">)</span>
        <span class="n">roots</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">processed</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">reset</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">reset</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="c1"># perform simple update, at a single level.</span>
            <span class="c1"># by contract, a reset signal at one level cannot</span>
            <span class="c1"># be followed by other resets at nested levels, so it&#39;s safe to</span>
            <span class="c1"># simply update</span>
            <span class="n">node</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">node_reset</span><span class="p">,</span> <span class="n">update_batch_size</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># there can be two cases: (1) the key is present in both tds,</span>
            <span class="c1"># in which case we use the reset mask to update</span>
            <span class="c1"># (2) the key is not present in the input tensordict, in which</span>
            <span class="c1"># case we just return the data</span>

            <span class="c1"># empty tensordicts won&#39;t be returned</span>
            <span class="k">if</span> <span class="n">reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="n">node</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">reset</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">reset</span> <span class="o">=</span> <span class="n">reset</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="c1"># node.update(node.where(~reset, other=node_reset, pad=0))</span>
            <span class="n">node</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">reset</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="n">node_reset</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">node</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># node = node.clone()</span>
            <span class="c1"># idx = reset.nonzero(as_tuple=True)[0]</span>
            <span class="c1"># node[idx].update(node_reset[idx])</span>
            <span class="c1"># node[&quot;done&quot;] = torch.zeros((*node.shape, 1), dtype=torch.bool)</span>

    <span class="k">return</span> <span class="n">tensordict</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_repr_by_depth</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used to sort keys based on nesting level.&quot;&quot;&quot;</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_make_compatible_policy</span><span class="p">(</span>
    <span class="n">policy</span><span class="p">,</span>
    <span class="n">observation_spec</span><span class="p">,</span>
    <span class="n">env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">fast_wrap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">trust_policy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">env_maker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">env_maker_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">if</span> <span class="n">trust_policy</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">eval_frame</span><span class="o">.</span><span class="n">OptimizedModule</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">policy</span>
    <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_spec</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">env_maker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvBase</span><span class="p">,</span> <span class="n">EnvCreator</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_maker</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
                <span class="n">env</span> <span class="o">=</span> <span class="n">env_maker</span>
                <span class="n">input_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_maker</span><span class="p">,</span> <span class="n">EnvCreator</span><span class="p">):</span>
                <span class="n">input_spec</span> <span class="o">=</span> <span class="n">env_maker</span><span class="o">.</span><span class="n">_meta_data</span><span class="o">.</span><span class="n">specs</span><span class="p">[</span>
                    <span class="s2">&quot;input_spec&quot;</span><span class="p">,</span> <span class="s2">&quot;full_action_spec&quot;</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">env</span> <span class="o">=</span> <span class="n">env_maker</span><span class="p">(</span><span class="o">**</span><span class="n">env_maker_kwargs</span><span class="p">)</span>
                <span class="n">input_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">full_action_spec</span>
        <span class="k">if</span> <span class="n">input_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">env</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">input_spec</span><span class="p">[</span><span class="s2">&quot;full_action_spec&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;env must be provided to _get_policy_and_device if policy is None&quot;</span>
                <span class="p">)</span>

        <span class="n">policy</span> <span class="o">=</span> <span class="n">RandomPolicy</span><span class="p">(</span><span class="n">input_spec</span><span class="p">)</span>

    <span class="c1"># make sure policy is an nn.Module - this will return the same policy if conditions are met</span>
    <span class="c1"># policy = CloudpickleWrapper(policy)</span>

    <span class="n">caller</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_policy_is_tensordict_compatible</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">observation_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">env</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_spec</span>
            <span class="k">elif</span> <span class="n">env_maker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvBase</span><span class="p">,</span> <span class="n">EnvCreator</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_maker</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
                    <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">env_maker</span><span class="o">.</span><span class="n">observation_spec</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_maker</span><span class="p">,</span> <span class="n">EnvCreator</span><span class="p">):</span>
                    <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">env_maker</span><span class="o">.</span><span class="n">_meta_data</span><span class="o">.</span><span class="n">specs</span><span class="p">[</span>
                        <span class="s2">&quot;output_spec&quot;</span><span class="p">,</span> <span class="s2">&quot;full_observation_spec&quot;</span>
                    <span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">observation_spec</span> <span class="o">=</span> <span class="n">env_maker</span><span class="p">(</span><span class="o">**</span><span class="n">env_maker_kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">observation_spec</span>

        <span class="c1"># policy is a nn.Module that doesn&#39;t operate on tensordicts directly</span>
        <span class="c1"># so we attempt to auto-wrap policy with TensorDictModule</span>
        <span class="k">if</span> <span class="n">observation_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unable to read observation_spec from the environment. This is &quot;</span>
                <span class="s2">&quot;required to check compatibility of the environment and policy &quot;</span>
                <span class="s2">&quot;since the policy is a nn.Module that operates on tensors &quot;</span>
                <span class="s2">&quot;rather than a TensorDictModule or a nn.Module that accepts a &quot;</span>
                <span class="s2">&quot;TensorDict as input and defines in_keys and out_keys. &quot;</span>
                <span class="s2">&quot;If your policy is compatible with the environment, you can solve this warning by setting &quot;</span>
                <span class="s2">&quot;trust_policy=True in the constructor.&quot;</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="n">caller</span><span class="o">.</span><span class="n">__signature__</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">caller</span><span class="p">)</span>
        <span class="c1"># we check if all the mandatory params are there</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;tensordict&quot;</span><span class="p">}</span>
            <span class="ow">or</span> <span class="nb">set</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;td&quot;</span><span class="p">}</span>
            <span class="ow">or</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="ow">and</span> <span class="n">is_tensor_collection</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">annotation</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">policy</span>
        <span class="k">if</span> <span class="n">fast_wrap</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">observation_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_keys</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">TensorDictModule</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>

        <span class="n">required_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="n">inspect</span><span class="o">.</span><span class="n">_empty</span>
        <span class="p">}</span>
        <span class="n">next_observation</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">observation_spec</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">required_kwargs</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">next_observation</span><span class="p">)):</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">next_observation</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">env</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_keys</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">)():</span>
                <span class="n">policy_device</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">policy_device</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">policy_device</span><span class="p">:</span>
                <span class="n">next_observation</span> <span class="o">=</span> <span class="n">tree_map</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">policy_device</span><span class="p">),</span> <span class="n">next_observation</span>
                <span class="p">)</span>

            <span class="n">output</span> <span class="o">=</span> <span class="n">policy</span><span class="p">(</span><span class="o">**</span><span class="n">next_observation</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">out_keys</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

            <span class="n">policy</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Arguments to policy.forward are incompatible with entries in</span>
<span class="s2">    env.observation_spec (got incongruent signatures: fun signature is </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span><span class="si">}</span><span class="s2"> vs specs </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">next_observation</span><span class="p">)</span><span class="si">}</span><span class="s2">).</span>
<span class="s2">    If you want TorchRL to automatically wrap your policy with a TensorDictModule</span>
<span class="s2">    then the arguments to policy.forward must correspond one-to-one with entries</span>
<span class="s2">    in env.observation_spec.</span>
<span class="s2">    For more complex behavior and more control you can consider writing your</span>
<span class="s2">    own TensorDictModule.</span>
<span class="s2">    Check the collector documentation to know more about accepted policies.</span>
<span class="s2">    &quot;&quot;&quot;</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">policy</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_policy_is_tensordict_compatible</span><span class="p">(</span><span class="n">policy</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_compatible</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="p">(</span><span class="n">RandomPolicy</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="n">is_compatible</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
        <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">_NonParametricPolicyWrapper</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">is_compatible</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">policy</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">CloudpickleWrapper</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_compatible</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">fn</span><span class="p">))</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">,</span> <span class="n">policy</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;in_keys&quot;</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;out_keys&quot;</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Passing a policy that is not a tensordict.nn.TensorDictModuleBase subclass but has in_keys and out_keys &quot;</span>
            <span class="s2">&quot;is deprecated. Users should inherit from this class (which &quot;</span>
            <span class="s2">&quot;has very few restrictions) to make the experience smoother. &quot;</span>
            <span class="s2">&quot;Simply change your policy from `class Policy(nn.Module)` to `Policy(tensordict.nn.TensorDictModuleBase)` &quot;</span>
            <span class="s2">&quot;and this error should disappear.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;in_keys&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;out_keys&quot;</span><span class="p">):</span>
        <span class="c1"># if it&#39;s not a TensorDictModule, and in_keys and out_keys are not defined then</span>
        <span class="c1"># we assume no TensorDict compatibility and will try to wrap it.</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># if in_keys or out_keys were defined but policy is not a TensorDictModule or</span>
    <span class="c1"># accepts multiple arguments then it&#39;s likely the user is trying to do something</span>
    <span class="c1"># that will have undetermined behavior, we raise an error</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Received a policy that defines in_keys or out_keys and also expects multiple &quot;</span>
        <span class="s2">&quot;arguments to policy.forward. If the policy is compatible with TensorDict, it &quot;</span>
        <span class="s2">&quot;should take a single argument of type TensorDict to policy.forward and define &quot;</span>
        <span class="s2">&quot;both in_keys and out_keys. Alternatively, policy.forward can accept &quot;</span>
        <span class="s2">&quot;arbitrarily many tensor inputs and leave in_keys and out_keys undefined and &quot;</span>
        <span class="s2">&quot;TorchRL will attempt to automatically wrap the policy with a TensorDictModule.&quot;</span>
    <span class="p">)</span>


<div class="viewcode-block" id="RandomPolicy"><a class="viewcode-back" href="../../../reference/generated/torchrl.envs.RandomPolicy.html#torchrl.envs.RandomPolicy">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RandomPolicy</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A random policy for data collectors.</span>

<span class="sd">    This is a wrapper around the action_spec.rand method.</span>

<span class="sd">    Args:</span>
<span class="sd">        action_spec: TensorSpec object describing the action specs</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.tensor_specs import Bounded</span>
<span class="sd">        &gt;&gt;&gt; action_spec = Bounded(-torch.ones(3), torch.ones(3))</span>
<span class="sd">        &gt;&gt;&gt; actor = RandomPolicy(action_spec=action_spec)</span>
<span class="sd">        &gt;&gt;&gt; td = actor(TensorDict()) # selects a random action in the cube [-1; 1]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">,</span> <span class="n">action_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">action_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="o">=</span> <span class="n">action_key</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_PolicyMetaClass</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># no kwargs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_NonParametricPolicyWrapper</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">_PolicyMetaClass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A wrapper for non-parametric policies.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">functools</span><span class="o">.</span><span class="n">update_wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">CloudpickleWrapper</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">forward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">forward</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span>
                <span class="n">attr</span>
            <span class="p">)</span>  <span class="c1"># make sure that appropriate exceptions are raised</span>

        <span class="k">elif</span> <span class="n">attr</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;passing built-in private methods is &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;not permitted with type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got attribute </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;policy&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">():</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;policy&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;policy not set in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, cannot access </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-tutorials/"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
in_keys: ["observation_vector"]
in_keys_qvalue: ["action", "observation_vector"]
in_keys_policy_module: ["observation_vector"]

activation_class: elu
num_cells: [400, 300]

policy_network:
  _target_: torchrl.modules.partial_probabilisticactor
  _partial_: True
  dist_param_keys: ${model.policy_out_keys}
  default_interaction_mode: ${model.default_interaction_mode}
  distribution_class: ${model.distribution_class}
  distribution_kwargs: ${model.distribution_kwargs}
  return_log_prob: True
  partial_tensordictmodule:
    _target_: torchrl.modules.partial_tensordictmodule
    _partial_: True
    in_keys: ${network.in_keys_policy_module}
    out_keys: ${model.policy_out_keys}
    wrapper: ${model.policy_wrapper}
    partial_module:
      _target_: torchrl.modules.MLP
      _partial_: True  # misses out_features
      activation_class: ${network.activation_class}
      num_cells: ${network.num_cells}

qvalue_network:
  _target_: torchrl.modules.ValueOperator
  in_keys: ${network.in_keys_qvalue}
  module:
    _target_: torchrl.modules.MLP
    out_features: 1
    activation_class: ${network.activation_class}
    num_cells: ${network.num_cells}

value_network:
  _target_: torchrl.modules.ValueOperator
  in_keys: ${network.in_keys}
  module:
    _target_: torchrl.modules.MLP
    out_features: 1
    activation_class: ${network.activation_class}
    num_cells: ${network.num_cells}

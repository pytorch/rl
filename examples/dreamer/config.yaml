env_name: cheetah
env_task: run
env_library: dm_control
catframes: 1
async_collection: True
record_video: 0
frame_skip: 2
batch_size: 50
batch_length: 50
total_frames: 5000000
world_model_lr: 6e-4
actor_value_lr: 8e-5
from_pixels: True
# we want 50 frames / traj in the replay buffer. Given the frame_skip=2 this makes each traj 100 steps long
env_per_collector: 8
num_workers: 8
# collector_devices: [cuda:1]
collector_devices: cuda:1  # [cpu,cpu,cpu,cpu,cpu,cpu,cpu,cpu]
frames_per_batch: 800
optim_steps_per_batch: 80
record_interval: 30
max_frames_per_traj: 1000
record_frames: 1000
batch_transform: 1
state_dim: 30
rssm_hidden_dim: 200
grad_clip: 100
grayscale: False
image_size : 64
buffer_size: 20000
init_env_steps: 1000
init_random_frames: 5000
logger: csv
offline_logging: False
normalize_rewards_online: True
normalize_rewards_online_scale: 5.0
normalize_rewards_online_decay: 0.99999
reward_scaling: 1.0

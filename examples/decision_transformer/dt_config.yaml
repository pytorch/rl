# environment and task
env:
  name: HalfCheetah-v3
  task: ""
  library: gym
  stacked_frames: 20
  inference_context: 5
  n_samples_stats: 2000
  frame_skip: 1
  num_train_envs: 1
  num_eval_envs: 10
  reward_scaling: 0.001 # for r2g
  noop: 1
  seed: 1
  target_return_mode: reduce
  eval_target_return: 6000 
  collect_target_return: 12000

# logger
logger:
  backend: wandb
  model_name: DT
  exp_name: DT-HalfCheetah-medium-v2
  pretrain_log_interval: 500 # record interval in frames
  fintune_log_interval: 1
  eval_steps: 1000

# replay buffer
replay_buffer:
  dataset: halfcheetah-medium-v2
  batch_size: 64
  prb: 0
  stacked_frames: 20
  buffer_prefetch: 64
  capacity: 1_000_000
  buffer_scratch_dir: "/tmp/"
  device: cpu
  prefetch: 3

# optimization
optim:
  device: cuda:0
  lr: 1.0e-4
  weight_decay: 5.0e-4
  batch_size: 64
  pretrain_gradient_steps: 55000
  updates_per_episode: 300
  warmup_steps: 10000
  clip_grad: 0.25

# loss
loss: 
  loss_function: "l2"
  
# transformer model
transformer:
  n_embd: 128
  n_layer: 3 
  n_head: 1
  n_inner: 512 # 4*128
  activation: relu
  n_positions: 1024
  resid_pdrop: 0.1
  attn_pdrop: 0.1

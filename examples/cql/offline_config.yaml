# env and task
env:
  name: Hopper-v2
  task: ""
  library: gym
  exp_name: cql_${replay_buffer.dataset}
  n_samples_stats: 1000
  seed: 0
  backend: gym  # D4RL uses gym so we make sure gymnasium is hidden

# logger
logger:
  backend: wandb
  eval_iter: 5000
  eval_steps: 1000
  mode: online
  eval_envs: 5

# replay buffer
replay_buffer:
  dataset: hopper-medium-v2
  batch_size: 256

# optimization
optim:
  device: cuda:0
  actor_lr: 3e-4
  critic_lr: 3e-4
  weight_decay: 0.0
  gradient_steps: 1_000_000
  policy_eval_start: 40_000

# policy and model
model:
  hidden_sizes: [256, 256]
  activation: relu
  default_policy_scale: 1.0
  scale_lb: 0.1

# loss
loss: 
  loss_function: l2
  gamma: 0.99
  tau: 0.005
# CQL specific hyperparameter
  temperature: 1.0
  min_q_weight: 1.0
  max_q_backup: False
  deterministic_backup: False
  num_random: 10
  with_lagrange: True
  lagrange_thresh: 5.0 # tau

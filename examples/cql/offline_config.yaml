# env and task
env:
  name: HalfCheetah-v2
  task: ""
  library: gym
  exp_name: cql_halfcheetah-medium-v2
  n_samples_stats: 1000
  frame_skip: 1
  reward_scaling: 1.0
  seed: 0

# logger
logger:
  backend: wandb
  eval_iter: 5000
  eval_steps: 1000
  mode: online
  eval_envs: 5

# replay buffer
replay_buffer:
  dataset: halfcheetah-medium-v2
  batch_size: 256

# optimization
optim:
  device: cuda:0
  lr: 3e-4
  weight_decay: 0.0
  gradient_steps: 100000

# Policy and model
model:
  hidden_sizes: [256, 256]
  activation: relu
  default_policy_scale: 1.0
  scale_lb: 0.1

# loss
loss: 
  loss_function: l2
  gamma: 0.99
  tau: 0.005
# CQL specific hyperparameter
  temperature: 1.0
  min_q_weight: 1.0
  max_q_backup: False
  deterministic_backup: False
  num_random: 10
  with_lagrange: True
  lagrange_thresh: 10.0

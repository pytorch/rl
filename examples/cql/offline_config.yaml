# Task and env
env:
  name: HalfCheetah-v2
  task: ""
  library: gym
  exp_name: cql_halfcheetah-medium-v2
  n_samples_stats: 1000
  frame_skip: 1
  reward_scaling: 1.0
  noop: 1
  seed: 0

# logger
logger:
  backend: wandb
  eval_iter: 500
  eval_steps: 1000
  mode: online
  eval_envs: 5

# Buffer
replay_buffer:
  dataset: halfcheetah-medium-v2
  batch_size: 256

# Optimization
optim:
  device: cuda:0
  lr: 3e-4
  weight_decay: 0.0
  batch_size: 256
  gradient_steps: 100000

# Policy and model
model:
  hidden_sizes: [256, 256]
  activation: relu
  default_policy_scale: 1.0
  scale_lb: 0.1

# loss
loss: 
  loss_function: smooth_l1
  gamma: 0.99
  tau: 0.005
  # CQL hyperparameter
  temperature: 1.0
  min_q_weight: 1.0
  max_q_backup: False
  deterministic_backup: True
  num_random: 10
  with_lagrange: False
  lagrange_thresh: 0.0

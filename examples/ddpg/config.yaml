# task and env
env:
  env_name: HalfCheetah-v4
  env_task: ""
  env_library: gym
  normalize_rewards_online: 1
  normalize_rewards_online_scale: 5
  frame_skip: 1
  norm_stats: 1
  num_envs: 4
  n_samples_stats: 1000
  noop: 1
  reward_scaling:
  from_pixels: False

# collector
collector:
  async_collection: 1
  frames_per_batch: 1024
  total_frames: 1000000
  multi_step: 3  # 0 to disable
  init_random_frames: 25000
  collector_devices: cpu  # [cpu,cpu,cpu,cpu]
  num_collectors: 4
  max_frames_per_traj: -1

# eval
recorder:
  video: True
  interval: 10000  # record interval in frames
  frames: 10000

# logger
logger:
  logger_class: wandb
  exp_name: ddpg_cheetah_gym

# Buffer
replay_buffer:
  prb: 1
  buffer_prefetch: 64
  capacity: 1_000_000

# Optim
optim:
  device: cpu
  lr: 3e-4
  weight_decay: 0.0
  batch_size: 256
  lr_scheduler: ""
  value_network_update_interval: 200
  optim_steps_per_batch: 8

# Policy and model
model:
  ou_exploration: 1
  annealing_frames: 1000000
  noisy: False
  activation: elu

# loss
loss:
  loss_function: smooth_l1
  gamma: 0.99
  tau: 0.05

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca6d4aa-399b-431a-a57a-1552fac46364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vmoens/venv/rl2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-07 14:07:43,673\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import TransformedEnv, InitTracker\n",
    "from torchrl.envs import GymEnv, SerialEnv\n",
    "from torchrl.modules import MLP, LSTMModule, set_recurrent_mode\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "import torch\n",
    "from tensordict.nn import TensorDictSequential as Seq, TensorDictModule as Mod\n",
    "# torch.set_default_dtype(torch.double)\n",
    "env = SerialEnv(2, [partial(TransformedEnv, GymEnv(\"Pendulum-v1\"), InitTracker()) for _ in range(2)])\n",
    "lstm_module = LSTMModule(\n",
    "    input_size=env.observation_spec[\"observation\"].shape[-1],\n",
    "    hidden_size=64,\n",
    "    in_keys=[\"observation\", \"rs_h\", \"rs_c\"],\n",
    "    out_keys=[\"intermediate\", (\"next\", \"rs_h\"), (\"next\", \"rs_c\")],\n",
    "    python_based=True,\n",
    ")\n",
    "for p in lstm_module.parameters():\n",
    "    p.data *= (1+torch.randn_like(p.data)/10)\n",
    "mlp_value = MLP(num_cells=[64], out_features=1)\n",
    "value_net = Seq(lstm_module, Mod(mlp_value, in_keys=[\"intermediate\"], out_keys=[\"state_value\"]))\n",
    "mlp_policy = MLP(num_cells=[64], out_features=1)\n",
    "policy_net = Seq(lstm_module, Mod(mlp_policy, in_keys=[\"intermediate\"], out_keys=[\"action\"]))\n",
    "# value_net.select_out_keys(\"state_value\")\n",
    "env = env.append_transform(lstm_module.make_tensordict_primer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1380a826-f862-4c44-a25b-c0892daafa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.objectives.value import GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b102d-9838-48ae-a376-dee151642431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa734f6-3e50-4400-8b50-dec4bb3b20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 14:07:44,241 [torchrl][INFO] transform container out of scope. Returning None for parent.\n",
      "2025-05-07 14:07:44,242 [torchrl][INFO] transform container out of scope. Returning None for parent.\n"
     ]
    }
   ],
   "source": [
    "vals = env.rollout(1000, policy_net, break_when_any_done=False)\n",
    "vals[\"next\", \"is_init\"] = vals[\"is_init\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d01605-9008-4f40-be57-6acaf0aa04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net(vals.copy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4612d3c7-81b2-48d9-a3e2-5aef4f8b1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_in tensor([[   0,    0],\n",
      "        [ 201,    0],\n",
      "        [ 402,    0],\n",
      "        [ 603,    0],\n",
      "        [ 804,    0],\n",
      "        [1005,    0],\n",
      "        [1206,    0],\n",
      "        [1407,    0],\n",
      "        [1608,    0],\n",
      "        [1809,    0]])\n",
      "tensordict_shaped TensorDict(\n",
      "    fields={\n",
      "        is_init: Tensor(shape=torch.Size([10, 201, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 201, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_c: Tensor(shape=torch.Size([10, 201, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_h: Tensor(shape=torch.Size([10, 201, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10, 201]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "gae = GAE(\n",
    "    gamma=0.9,\n",
    "    lmbda=0.99,\n",
    "    value_network=value_net,\n",
    "    shifted=True,\n",
    ")\n",
    "with set_recurrent_mode(True):\n",
    "    r0 = gae(vals.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0748c7e2-3490-4e9b-92c5-f12ed3f11660",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = r0[\"advantage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc3f89-b9ab-454c-a1f3-a03aa8be1c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b329009-a9ab-4815-90b0-95c3dab3cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_next TensorDict(\n",
      "    fields={\n",
      "        is_init: Tensor(shape=torch.Size([2, 1000, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([2, 1000, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_c: Tensor(shape=torch.Size([2, 1000, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_h: Tensor(shape=torch.Size([2, 1000, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([2, 1000]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "tensordict_shaped TensorDict(\n",
      "    fields={\n",
      "        is_init: Tensor(shape=torch.Size([10, 200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_c: Tensor(shape=torch.Size([10, 200, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_h: Tensor(shape=torch.Size([10, 200, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10, 200]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "tensordict_shaped TensorDict(\n",
      "    fields={\n",
      "        is_init: Tensor(shape=torch.Size([10, 200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_c: Tensor(shape=torch.Size([10, 200, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        rs_h: Tensor(shape=torch.Size([10, 200, 1, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10, 200]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "gae = GAE(\n",
    "    gamma=0.9,\n",
    "    lmbda=0.99,\n",
    "    value_network=value_net,\n",
    "    shifted=False,\n",
    "    deactivate_vmap=True,\n",
    ")\n",
    "with set_recurrent_mode(True):\n",
    "    r1 = gae(vals.copy())\n",
    "a1 = r1[\"advantage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e23506e-ad30-445d-960c-d86ebe8f339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9999],\n",
       "         [0.9999],\n",
       "         [1.0000],\n",
       "         ...,\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]],\n",
       "\n",
       "        [[1.0002],\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         ...,\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1/a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e6a69b-b6df-4ef2-aae5-784b6b285880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0001, 1.0001, 1.0000,  ..., 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a0/a1).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f5614a-83e4-4d06-a7ca-1969208cb5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0001],\n",
       "         [1.0001],\n",
       "         [1.0000],\n",
       "         ...,\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]],\n",
       "\n",
       "        [[0.9998],\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         ...,\n",
       "         [1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a0/a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48cb0129-d983-4777-bb24-f85681dfae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = r0[\"next\", \"done\"]\n",
    "d1 = r1[\"next\", \"done\"]\n",
    "\n",
    "(d0).view(-1)[190:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61efef96-9b18-448e-808b-167590cfb8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0086)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(a0-a1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8483233a-8370-464e-b3a3-0093da1fe55e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 85 / 2000 (4.2%)\nGreatest absolute difference: 0.008636474609375 at index (1, 400, 0) (up to 1e-05 allowed)\nGreatest relative difference: 0.0001738967257551849 at index (1, 0, 0) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/rl2/lib/python3.10/site-packages/torch/testing/_comparison.py:1587\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1565\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1566\u001b[0m     actual,\n\u001b[1;32m   1567\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1582\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1583\u001b[0m )\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 85 / 2000 (4.2%)\nGreatest absolute difference: 0.008636474609375 at index (1, 400, 0) (up to 1e-05 allowed)\nGreatest relative difference: 0.0001738967257551849 at index (1, 0, 0) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.testing.assert_close(a0, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a9b94-f4d7-4e1d-b9ab-03843828efca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2168f-b7a2-49ed-9b7b-b10551847dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62035b5f-b664-4a6d-adb1-43d02583b0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715617e5-7ad3-4815-8e6e-7c30d1161231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# TorchRL Release Workflow
#
# This workflow automates the release process for TorchRL:
# 1. Sanity checks (version matching, branch/tag validation, tensordict compatibility)
# 2. Triggers wheel builds across all platforms (sequentially to avoid test-infra conflicts)
# 3. Collects wheels into a single artifact
# 4. Updates gh-pages docs (stable symlink)
# 5. Creates draft GitHub release with wheels attached
# 6. Publishes to PyPI using OIDC trusted publishing
#
# Triggers:
# - Manual workflow_dispatch only (no automatic triggers)
#
# TensorDict Installation:
# - release/* branches and release tags: install from PyPI (stable)
# - main, nightly, PRs: install from git (latest dev)
# - Can be overridden with tensordict_source input
#
# Wheel Variants:
# - cpu (default): Recommended for torchrl - avoids duplicate filename conflicts
# - gpu: Only CUDA builds
# - all: All variants (with deduplication to prevent corruption)
#
# NOTE: This workflow is NOT automatically triggered on tag push to avoid
# race conditions with wheel builds. Use workflow_dispatch to trigger releases.

name: Release

on:
  workflow_dispatch:
    inputs:
      tag:
        description: 'Release tag (e.g., v0.11.0)'
        required: true
        type: string
      pytorch_release:
        description: 'PyTorch release branch (e.g., release/2.8)'
        required: false
        type: string
        default: 'main'
      skip_sanity_checks:
        description: 'Skip sanity checks'
        required: false
        type: boolean
        default: false
      dry_run:
        description: 'Dry run (skip docs push, GitHub release, PyPI publish)'
        required: false
        type: boolean
        default: false
      tensordict_source:
        description: 'TensorDict source: stable (PyPI) or git (latest dev). Auto-detected from branch if not specified.'
        required: false
        type: choice
        options:
          - 'auto'
          - 'stable'
          - 'git'
        default: 'auto'
      wheel_variants:
        description: 'Which wheel variants to collect (cpu recommended for torchrl)'
        required: false
        type: choice
        options:
          - 'cpu'
          - 'gpu'
          - 'all'
        default: 'cpu'

# Ensure only one release workflow runs at a time
# cancel-in-progress: true means new runs cancel previous ones
concurrency:
  group: release-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write
  id-token: write

env:
  # Release tag from manual input
  RELEASE_TAG: ${{ inputs.tag }}
  # Determine the test-infra ref: from manual input or default to main
  TEST_INFRA_REF: ${{ inputs.pytorch_release || 'main' }}
  # Dry run mode from input
  DRY_RUN: ${{ inputs.dry_run }}
  # TensorDict source: stable (PyPI), git, or auto (branch-based detection)
  # Note: This env var is for documentation. The actual detection happens in build scripts
  # using GITHUB_REF_NAME/GITHUB_REF_TYPE since env vars don't propagate to called workflows.
  TENSORDICT_SOURCE: ${{ inputs.tensordict_source || 'auto' }}

jobs:
  # =============================================================================
  # SANITY CHECKS
  # =============================================================================
  sanity-checks:
    name: Sanity Checks
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_sanity_checks }}
    outputs:
      version: ${{ steps.parse-version.outputs.version }}
      version_major_minor: ${{ steps.parse-version.outputs.version_major_minor }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Parse version from tag
        id: parse-version
        run: |
          TAG="${{ env.RELEASE_TAG }}"
          echo "Processing tag: $TAG"

          # Validate tag format
          if [[ ! "$TAG" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "::error::Invalid tag format: $TAG. Expected format: v0.11.0"
            exit 1
          fi

          # Extract version without 'v' prefix
          VERSION="${TAG#v}"
          echo "version=$VERSION" >> $GITHUB_OUTPUT

          # Extract major.minor for docs folder
          VERSION_MAJOR_MINOR=$(echo "$VERSION" | sed 's/\([0-9]\+\)\.\([0-9]\+\)\.[0-9]\+/\1.\2/')
          echo "version_major_minor=$VERSION_MAJOR_MINOR" >> $GITHUB_OUTPUT

          echo "Parsed version: $VERSION"
          echo "Major.minor: $VERSION_MAJOR_MINOR"

      - name: Check branch name matches tag
        run: |
          TAG="${{ env.RELEASE_TAG }}"
          VERSION="${{ steps.parse-version.outputs.version }}"

          # Get the branch that contains this tag
          BRANCHES=$(git branch -r --contains "$TAG" 2>/dev/null || echo "")

          if [[ -z "$BRANCHES" ]]; then
            echo "::warning::Tag $TAG is not on any remote branch yet (may be a new tag)"
          else
            echo "Tag $TAG is on branches: $BRANCHES"

            # Check if it's on a release branch matching the version
            EXPECTED_BRANCH="release/${VERSION%.*}"
            if echo "$BRANCHES" | grep -q "origin/$EXPECTED_BRANCH"; then
              echo "Tag is on expected release branch: $EXPECTED_BRANCH"
            else
              echo "::warning::Tag $TAG is not on expected branch $EXPECTED_BRANCH"
            fi
          fi

      - name: Check all version files match tag
        run: |
          VERSION="${{ steps.parse-version.outputs.version }}"

          echo "=============================================="
          echo "Checking all 3 version files match tag: $VERSION"
          echo "=============================================="

          # Read all 3 version files
          ROOT_VERSION=$(cat version.txt | tr -d '[:space:]')
          SCRIPT_SH_VERSION=$(grep -E '^export TORCHRL_BUILD_VERSION=' .github/scripts/td_script.sh | cut -d'=' -f2)
          SCRIPT_BAT_VERSION=$(grep -E '^set TORCHRL_BUILD_VERSION=' .github/scripts/version_script.bat | cut -d'=' -f2)

          echo ""
          echo "Version file contents:"
          echo "  Tag version:                              $VERSION"
          echo "  version.txt:                              $ROOT_VERSION"
          echo "  .github/scripts/td_script.sh:             $SCRIPT_SH_VERSION"
          echo "  .github/scripts/version_script.bat:       $SCRIPT_BAT_VERSION"
          echo ""

          # Check all files match each other first
          MISMATCH=0

          if [[ "$ROOT_VERSION" != "$SCRIPT_SH_VERSION" ]]; then
            echo "::error::version.txt ($ROOT_VERSION) != td_script.sh ($SCRIPT_SH_VERSION)"
            MISMATCH=1
          fi

          if [[ "$ROOT_VERSION" != "$SCRIPT_BAT_VERSION" ]]; then
            echo "::error::version.txt ($ROOT_VERSION) != version_script.bat ($SCRIPT_BAT_VERSION)"
            echo "::error::Windows wheels will be built with wrong version!"
            MISMATCH=1
          fi

          if [[ "$MISMATCH" == "1" ]]; then
            echo ""
            echo "::error::Version files are inconsistent! All 3 files must have the same version."
            echo "::error::Please update all files listed in RELEASE_AGENT_PROMPT.md"
            exit 1
          fi

          echo "✓ All version files are consistent with each other"

          # Now check they match the tag
          if [[ "$ROOT_VERSION" != "$VERSION" ]]; then
            echo ""
            echo "::error::Version files ($ROOT_VERSION) do not match tag version ($VERSION)"
            echo "::error::Either the tag is wrong or the version files need to be updated."
            exit 1
          fi

          echo "✓ All version files match the tag version ($VERSION)"
          echo ""
          echo "Version check passed!"

      - name: Validate tensordict version compatibility
        run: |
          VERSION="${{ steps.parse-version.outputs.version }}"
          # Extract major.minor from version (0.11.0 -> 0.11)
          MAJOR_MINOR=$(echo "$VERSION" | sed 's/\.[0-9]*$//')

          # Parse tensordict requirement from pyproject.toml
          TD_REQ=$(grep -E '"tensordict[^"]*"' pyproject.toml | head -1)
          echo "TensorDict requirement: $TD_REQ"

          # Check that the requirement includes the same major.minor version
          if ! echo "$TD_REQ" | grep -q "$MAJOR_MINOR"; then
            echo "::error::TensorDict version in pyproject.toml should match major version $MAJOR_MINOR"
            echo "Found: $TD_REQ"
            exit 1
          fi
          echo "TensorDict version constraint is compatible"

      - name: Check stable docs version
        run: |
          VERSION_MAJOR_MINOR="${{ steps.parse-version.outputs.version_major_minor }}"

          # Fetch the stable docs index page
          DOCS_URL="https://pytorch.org/rl/stable/index.html"

          # Try to check if the page exists and contains version info
          HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$DOCS_URL" || echo "000")

          if [[ "$HTTP_STATUS" == "200" ]]; then
            echo "Stable docs are accessible at $DOCS_URL"
            echo "::notice::Docs will be updated to point to version $VERSION_MAJOR_MINOR"
          elif [[ "$HTTP_STATUS" == "404" ]]; then
            echo "::notice::Stable docs not found at $DOCS_URL (may be a first release)"
          else
            echo "::warning::Could not check stable docs (HTTP $HTTP_STATUS)"
          fi

  # =============================================================================
  # BUILD WHEELS - All Platforms (Sequential to avoid concurrency conflicts)
  # =============================================================================
  # NOTE: Builds run sequentially because pytorch/test-infra workflows use a
  # shared concurrency group that causes parallel builds to cancel each other.

  build-linux:
    name: Build Linux Wheels
    needs: [sanity-checks]
    if: always() && (needs.sanity-checks.result == 'success' || needs.sanity-checks.result == 'skipped')
    uses: ./.github/workflows/build-wheels-linux.yml
    with:
      test-infra-ref: ${{ inputs.pytorch_release || 'main' }}
      tensordict-source: ${{ inputs.tensordict_source || 'auto' }}
      channel: release
    secrets: inherit

  build-windows:
    name: Build Windows Wheels
    needs: [sanity-checks, build-linux]
    # Run after Linux build completes (success or failure) to avoid concurrency conflicts
    if: always() && (needs.sanity-checks.result == 'success' || needs.sanity-checks.result == 'skipped')
    uses: ./.github/workflows/build-wheels-windows.yml
    with:
      test-infra-ref: ${{ inputs.pytorch_release || 'main' }}
      tensordict-source: ${{ inputs.tensordict_source || 'auto' }}
      channel: release
    secrets: inherit

  build-macos:
    name: Build macOS Wheels
    needs: [sanity-checks, build-windows]
    # Run after Windows build completes (success or failure) to avoid concurrency conflicts
    if: always() && (needs.sanity-checks.result == 'success' || needs.sanity-checks.result == 'skipped')
    uses: ./.github/workflows/build-wheels-m1.yml
    with:
      test-infra-ref: ${{ inputs.pytorch_release || 'main' }}
      tensordict-source: ${{ inputs.tensordict_source || 'auto' }}
      channel: release
    secrets: inherit

  build-aarch64:
    name: Build Aarch64 Linux Wheels
    needs: [sanity-checks, build-macos]
    # Run after macOS build completes (success or failure) to avoid concurrency conflicts
    if: always() && (needs.sanity-checks.result == 'success' || needs.sanity-checks.result == 'skipped')
    uses: ./.github/workflows/build-wheels-aarch64-linux.yml
    with:
      test-infra-ref: ${{ inputs.pytorch_release || 'main' }}
      tensordict-source: ${{ inputs.tensordict_source || 'auto' }}
      channel: release
    secrets: inherit

  # =============================================================================
  # COLLECT WHEELS
  # =============================================================================
  collect-wheels:
    name: Collect Wheels
    needs: [sanity-checks, build-linux, build-windows, build-macos, build-aarch64]
    # Only run when ALL build jobs succeed. This ensures:
    # 1. Incomplete wheel sets are never collected
    # 2. If a build fails, this job is "skipped" (not "failed")
    # 3. Re-running the failed build job will also trigger this job
    if: |
      always() && !cancelled() &&
      needs.build-linux.result == 'success' &&
      needs.build-windows.result == 'success' &&
      needs.build-macos.result == 'success' &&
      needs.build-aarch64.result == 'success' &&
      (needs.sanity-checks.result == 'success' || needs.sanity-checks.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Check build results
        run: |
          echo "Build results:"
          echo "  Linux: ${{ needs.build-linux.result }}"
          echo "  Windows: ${{ needs.build-windows.result }}"
          echo "  macOS: ${{ needs.build-macos.result }}"
          echo "  Aarch64: ${{ needs.build-aarch64.result }}"
          echo ""
          echo "All builds succeeded - proceeding with wheel collection"

      - name: Download wheel artifacts
        uses: actions/download-artifact@v4
        with:
          path: wheels-raw
          # Pattern based on wheel_variants input:
          # - cpu: Only CPU builds (recommended - avoids duplicate wheel conflicts)
          # - gpu: Only CUDA builds
          # - all: All variants (requires deduplication)
          # pytorch/test-infra uploads artifacts named like: pytorch_rl__3.11_cpu_x86_64
          pattern: ${{ inputs.wheel_variants == 'gpu' && 'pytorch_rl__*_cu*' || inputs.wheel_variants == 'all' && 'pytorch_rl*' || 'pytorch_rl__*_cpu_*' }}
          merge-multiple: true

      - name: Deduplicate and verify wheels
        run: |
          # When downloading gpu/all variants, multiple artifacts may contain
          # wheels with the same filename (e.g., CUDA 12.6 and CUDA 12.8 both
          # produce torchrl-X.Y.Z-cpXX-cpXX-manylinux_x86_64.whl).
          # merge-multiple can cause corruption when this happens.
          # We deduplicate by keeping only unique wheel filenames.
          mkdir -p wheels
          echo "Processing wheels..."
          
          # Find all wheels and copy unique ones (first occurrence wins)
          for wheel in $(find wheels-raw -name "*.whl" -type f | sort); do
            basename=$(basename "$wheel")
            if [[ ! -f "wheels/$basename" ]]; then
              cp "$wheel" "wheels/$basename"
              echo "  Kept: $basename"
            else
              echo "  Skip duplicate: $basename"
            fi
          done
          
          # Verify all wheels are valid zip files
          echo ""
          echo "Verifying wheel integrity..."
          CORRUPTED=0
          for wheel in wheels/*.whl; do
            if python3 -c "import zipfile; zipfile.ZipFile('$wheel')" 2>/dev/null; then
              echo "  OK: $(basename $wheel)"
            else
              echo "  CORRUPTED: $(basename $wheel)"
              CORRUPTED=1
            fi
          done
          
          if [[ $CORRUPTED -eq 1 ]]; then
            echo ""
            echo "ERROR: One or more wheels are corrupted!"
            exit 1
          fi

      - name: List collected wheels
        run: |
          echo "Collected wheels:"
          ls -la wheels/*.whl | sort
          echo ""
          echo "Total wheels: $(ls wheels/*.whl 2>/dev/null | wc -l)"

      - name: Upload combined wheels artifact
        uses: actions/upload-artifact@v4
        with:
          name: release-wheels
          path: wheels/*.whl
          if-no-files-found: error

  # =============================================================================
  # UPDATE GH-PAGES DOCS
  # =============================================================================
  update-docs:
    name: Update Stable Docs
    needs: [sanity-checks, collect-wheels]
    if: always() && needs.collect-wheels.result == 'success' && needs.sanity-checks.result != 'failure'
    runs-on: ubuntu-latest
    steps:
      - name: Get version info
        id: version
        run: |
          TAG="${{ env.RELEASE_TAG }}"
          VERSION="${TAG#v}"
          VERSION_MAJOR_MINOR=$(echo "$VERSION" | sed 's/\([0-9]\+\)\.\([0-9]\+\)\.[0-9]\+/\1.\2/')
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "version_major_minor=$VERSION_MAJOR_MINOR" >> $GITHUB_OUTPUT

      - name: Checkout gh-pages branch
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          fetch-depth: 0

      - name: Update stable symlink and versions.html
        if: ${{ env.DRY_RUN != 'true' }}
        run: |
          VERSION_MAJOR_MINOR="${{ steps.version.outputs.version_major_minor }}"

          echo "Updating stable docs to version $VERSION_MAJOR_MINOR"

          # Check if the version folder exists
          if [[ ! -d "$VERSION_MAJOR_MINOR" ]]; then
            echo "::error::Docs folder for $VERSION_MAJOR_MINOR does not exist. Run docs workflow first."
            exit 1
          fi

          # Update stable symlink
          rm -f stable
          ln -sf "$VERSION_MAJOR_MINOR" stable
          echo "Updated stable symlink -> $VERSION_MAJOR_MINOR"

          # Update versions.html if it exists
          if [[ -f "versions.html" ]]; then
            # Update the "(stable release)" marker
            # Remove old stable marker
            sed -i 's/ (stable release)//g' versions.html

            # Add new stable marker to the current version
            sed -i "s|href=\"$VERSION_MAJOR_MINOR/\">v$VERSION_MAJOR_MINOR|href=\"$VERSION_MAJOR_MINOR/\">v$VERSION_MAJOR_MINOR (stable release)|g" versions.html

            # Check if this version is in versions.html
            if ! grep -q "\"$VERSION_MAJOR_MINOR\"" versions.html; then
              echo "::notice::Version $VERSION_MAJOR_MINOR not in versions.html, may need manual update"
            fi
          fi

          # Check if changes were made
          if git diff --quiet; then
            echo "::notice::Stable docs already point to $VERSION_MAJOR_MINOR. No changes needed."
            exit 0
          fi

          # Commit and push
          git config user.name 'pytorchbot'
          git config user.email 'soumith+bot@pytorch.org'
          git add stable versions.html 2>/dev/null || git add stable
          git commit -m "Update stable docs to $VERSION_MAJOR_MINOR"
          git push

          echo "Successfully updated stable docs"

      - name: Dry run - show what would be changed
        if: ${{ env.DRY_RUN == 'true' }}
        run: |
          VERSION_MAJOR_MINOR="${{ steps.version.outputs.version_major_minor }}"
          echo "DRY RUN: Would update stable symlink to point to $VERSION_MAJOR_MINOR"

          if [[ -L "stable" ]]; then
            CURRENT=$(readlink stable)
            echo "Current stable points to: $CURRENT"
          else
            echo "stable is not a symlink (or doesn't exist)"
          fi

  # =============================================================================
  # CREATE GITHUB RELEASE
  # =============================================================================
  create-release:
    name: Create GitHub Release
    needs: [sanity-checks, collect-wheels, update-docs]
    if: always() && needs.collect-wheels.result == 'success' && needs.sanity-checks.result != 'failure'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download wheels
        uses: actions/download-artifact@v4
        with:
          name: release-wheels
          path: wheels

      - name: List wheels to attach
        run: |
          echo "Wheels to attach to release:"
          find wheels -name "*.whl" -type f | sort

      - name: Flatten wheel directory
        run: |
          # Move all wheels to wheels/ root for release upload
          find wheels -name "*.whl" -exec mv {} wheels/ \;
          find wheels -type d -empty -delete
          echo "Wheels prepared for upload:"
          ls -la wheels/

      - name: Create draft release
        if: ${{ env.DRY_RUN != 'true' }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          TAG="${{ env.RELEASE_TAG }}"

          # Check if release already exists
          if gh release view "$TAG" &>/dev/null; then
            echo "Release $TAG already exists. Updating..."
            # Upload wheels to existing release
            find wheels -name "*.whl" -type f -exec gh release upload "$TAG" {} --clobber \;
          else
            echo "Creating draft release for $TAG"
            # Create draft release without auto-generated notes
            gh release create "$TAG" \
              --draft \
              --title "TorchRL $TAG" \
              --notes "Release notes for TorchRL $TAG

          ## Highlights

          <!-- Add release highlights here -->

          ## What's Changed

          <!-- Release notes will be written manually -->

          ## Installation

          \`\`\`bash
          pip install torchrl==${TAG#v}
          \`\`\`
          " \
              wheels/*.whl
          fi

          echo "Draft release created/updated: $TAG"
          echo "Please review and publish the release manually."

      - name: Dry run - show release info
        if: ${{ env.DRY_RUN == 'true' }}
        run: |
          TAG="${{ env.RELEASE_TAG }}"
          WHEEL_COUNT=$(find wheels -name "*.whl" -type f | wc -l)
          echo "DRY RUN: Would create draft release for $TAG"
          echo "Would attach $WHEEL_COUNT wheel files"

  # =============================================================================
  # PUBLISH TO PYPI
  # =============================================================================
  publish-pypi:
    name: Publish to PyPI
    needs: [sanity-checks, collect-wheels, create-release]
    if: always() && needs.collect-wheels.result == 'success' && needs.sanity-checks.result != 'failure'
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/project/torchrl/
    permissions:
      id-token: write
    steps:
      - name: Download wheels
        uses: actions/download-artifact@v4
        with:
          name: release-wheels
          path: dist

      - name: Flatten wheel directory
        run: |
          # Move all wheels to dist/ root for PyPI upload
          find dist -name "*.whl" -exec mv {} dist/ \;
          find dist -type d -empty -delete
          echo "Wheels prepared for upload:"
          ls -la dist/

      - name: Publish to PyPI (OIDC)
        if: ${{ env.DRY_RUN != 'true' }}
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          # Using OIDC trusted publishing - no token needed
          # Repository must be configured in PyPI to trust this workflow
          verbose: true
          print-hash: true

      - name: Dry run - show what would be published
        if: ${{ env.DRY_RUN == 'true' }}
        run: |
          echo "DRY RUN: Would publish the following wheels to PyPI:"
          ls -la dist/
          echo ""
          echo "Total: $(ls dist/*.whl | wc -l) wheels"

  # =============================================================================
  # SUMMARY
  # =============================================================================
  release-summary:
    name: Release Summary
    needs: [sanity-checks, build-linux, build-windows, build-macos, build-aarch64, collect-wheels, update-docs, create-release, publish-pypi]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Print summary
        run: |
          echo "## Release Summary for ${{ env.RELEASE_TAG }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Step | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Sanity Checks | ${{ needs.sanity-checks.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build Linux | ${{ needs.build-linux.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build Windows | ${{ needs.build-windows.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build macOS | ${{ needs.build-macos.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build Aarch64 | ${{ needs.build-aarch64.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Collect Wheels | ${{ needs.collect-wheels.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Update Docs | ${{ needs.update-docs.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Create Release | ${{ needs.create-release.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Publish PyPI | ${{ needs.publish-pypi.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ "${{ env.DRY_RUN }}" == "true" ]]; then
            echo "**Note: This was a dry run. No changes were pushed.**" >> $GITHUB_STEP_SUMMARY
          fi

          # Determine overall status
          if [[ "${{ needs.publish-pypi.result }}" == "success" ]]; then
            echo "### Release completed successfully!" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ needs.collect-wheels.result }}" == "success" ]]; then
            echo "### Wheels built successfully. Check individual steps for issues." >> $GITHUB_STEP_SUMMARY
          else
            echo "### Release encountered issues. Please review the logs." >> $GITHUB_STEP_SUMMARY
          fi

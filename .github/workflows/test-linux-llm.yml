name: LLM Tests on Linux

on:
  pull_request:
  push:
    branches:
      - nightly
      - main
      - release/*
  workflow_dispatch:

concurrency:
  # Documentation suggests ${{ github.head_ref }}, but that's only available on pull_request/pull_request_target triggers, so using ${{ github.ref }}.
  # On master, we want all builds to complete even if merging happens faster to make it easier to discover at which point something broke.
  group: ${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && format('ci-master-{0}', github.sha) || format('ci-{0}', github.ref) }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

jobs:
  unittests:
    strategy:
      matrix:
        python_version: ["3.9"]
        cuda_arch_version: ["12.8"]
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      repository: pytorch/rl
      runner: "linux.g5.4xlarge.nvidia.gpu"
      # gpu-arch-type: cuda
      # gpu-arch-version: "11.7"
      docker-image: "nvidia/cudagl:11.4.0-base"
      timeout: 120
      script: |
        if [[ "${{ github.ref }}" =~ release/* ]]; then
          export RELEASE=1
          export TORCH_VERSION=stable
        else
          export RELEASE=0
          export TORCH_VERSION=nightly
        fi

        set -euo pipefail
        export PYTHON_VERSION="3.9"
        export CU_VERSION="cu117"
        export TAR_OPTIONS="--no-same-owner"
        export UPLOAD_CHANNEL="nightly"
        export TF_CPP_MIN_LOG_LEVEL=0
        export TD_GET_DEFAULTS_TO_NONE=1

        bash .github/unittest/linux_libs/scripts_llm/setup_env.sh
        bash .github/unittest/linux_libs/scripts_llm/install.sh
        bash .github/unittest/linux_libs/scripts_llm/run_test.sh
        bash .github/unittest/linux_libs/scripts_llm/post_process.sh
